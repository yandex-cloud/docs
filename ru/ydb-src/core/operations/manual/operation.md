# Обслуживание дисковой подсистемы кластера

## Расширение кластера статическими нодами {#expand_cluster}

1) Добавить в конфиг NameserviceConfig в файл names.txt информацию о новых нодах

    ```
    Node {
        NodeId: 1
        Port: <ик-порт>
        Host: "<старый-хост>"
        InterconnectHost: "<старый-хост>"
        Location {
            DataCenter: "DC1"
            Module: "M1"
            Rack: "R1"
            Unit: "U1"
        }
    }
    Node {
        NodeId: 2
        Port: <ик-порт>
        Host: "<новый-хост>"
        InterconnectHost: "<новый-хост>"
        Location {
            DataCenter: "DC1"
            Module: "M2"
            Rack: "R2"
            Unit: "U2"
        }
    }
    ClusterUUID: "<UUID-кластера>"
    AcceptUUID: "<UUID-кластера>"
    ```

2) Обновить конфиг NameserviceConfig через CMS

3) Добавить новые ноды в DefineBox

    Пример протофайла для DefineBox

    ```
    Command {
        DefineHostConfig {
            HostConfigId: 1
            Drive {
                Path: "<путь-до-устройства>"
                Type: SSD
                PDiskConfig {
                    ExpectedSlotCount: 2
                }
            }
        }
    }
    Command {
        DefineBox {
            BoxId: 1
            Host {
                Key {
                    Fqdn: "<старый-хост>"
                    IcPort: <ик-порт>
                }
                HostConfigId: 1
            }
            Host {
                Key {
                    Fqdn: "<новый-хост>"
                    IcPort: <ик-порт>
                }
                HostConfigId: 1
            }
        }
    }
    ```

    Применение команды

    ```
    kikimr -s <ендпоинт> admin bs config invoke --proto-file DefineBox.txt
    ```

## Декоммиссия нод и дисков

**WILL BE SOON**

## SelfHeal {#selfheal}

В процессе работы кластеров могут выходить из строя отдельные блочные устройства, на которых работает ydb, либо узлы целиком. Для сохранения работоспособности и отказоустойчивости кластера в условиях, когда оперативная починка вышедших из строя узлов или устройств невозможна, используется механизм SelfHeal.

Механизм SelfHeal состоит из двух частей. Детектирование неисправных дисков и перевоз их в щадящем режиме не допуская потери данных и развала групп хранения.

По умолчанию SelfHeal включен.  
Ниже инструкция по включению в случае если он выключен, аналогично SelfHeal можно выключить.

1. Включение детектирования

    Открыть сртраницу

    ```http://localhost:8765/cms#show=config-items-25```

    Можно включить через viewer -> Cluster Management System -> CmsConfigItems

    Поле Status: Enable

    Или через cli

    * Зайти на любой узел

    * Составить файл с измененными конфигами

        Пример файла config.txt

        ```
        Actions {
            AddConfigItem {
                ConfigItem {
                    Config {
                        CmsConfig {
                            SentinelConfig {
                                Enable: true
                            }
                        }
                    }
                }
            }
        }
        ```

    * Обновить конфиг на кластере

        ```bash
        kikimr admin console configs update config.txt
        ```

2. Включение перевоза

    ```bash
    kikimr -s <ендпоинт> admin bs config invoke --proto 'Command{EnableSelfHeal{Enable: true}}'
    ```

### Настройки SelfHeal

viewer -> Cluster Management System -> CmsConfigItems
Если настроек еще нет, то нажать на кнопку Create, если есть, то на кнопку "карандашик" в углу.

* **Status** - Включение-выключение Self Heal в CMS.
* **Dry run** - Включение-выключение режима, в котором CMS не изменяет настройку BSC.
* **Config update interval (sec.)** - Период обновления конфига из BSC.
* **Retry interval (sec.)** - Период ретраев обновления конфига.
* **State update interval (sec.)** - Период обновления Состояний PDisk-ов, Состояние - это то что мы наблюдаем (через whiteboard, например)
* **Timeout (sec.)** - таймаут обновления Состояний PDisk-ов
* **Change status retries** - количество ретраев на изменение Статуса PDisk в BSC, Статус - это то, что хранится в BSC (ACTIVE, FAULTY, BROKEN, etc).
* **Change status retry interval (sec.)** - задержка между попытками на изменение Статуса PDisk в BSC
    CMS наблюдает Состояние диска с интервалом **State update interval**. Если диск пребывает в одном состояний несколько циклов **Status update interval**, то CMS меняет его Статус в BSC.
    Дальше идут настройки количества циклов обновления, через которое CMS будет изменять Статус диска. Если Состояние диска Normal, то диск переводится в Статус ACTIVE, в остальных состояниях диск переводится в статус FAULTY. Значение 0 выключает изменение Статуса для состояния (так сделано для Unknown по умолчанию).
    Например, при настройках по умолчанию, если CMS наблюдает состояние диска Initial на протяжении 5 циклов Status update interval по 60 с каждый, Статус диска будет изменен на FAULTY.
* **Default state limit** - Для Состояний, для которых нет указана настройка, может использоваться это значение "по умолчанию". Для неизвестных Состояний PDisk, для которых нет настройки, тоже используется это значение. Это значение используется если значение не задано для Состояний Initial, InitialFormatRead, InitialSysLogRead, InitialCommonLogRead, Normal.
* **Initail** - PDisk начинает инициализацию. Переход в FAULTY.
* **InitialFormatRead** - PDisk читает свою запись формата. Переход в FAULTY.
* **InitialFormatReadError** - PDisk получил ошибку при чтении своей записи формата. Переход в FAULTY.
* **InitialSysLogRead** - PDisk читает системный лог. Переход в FAULTY.
* **InitialSysLogReadError** - PDisk получил ошибку при чтении системного лога. Переход в FAULTY.
* **InitialSysLogParseError** - PDisk получил ошибку при парсинге или проверке консистентности системного лога. Переход в FAULTY.
* **InitialCommonnLogRead** - PDisk читает общий лог вдисков. Переход в FAULTY.
* **InitialCommonnLogReadError** - PDisk получил ошибку при чтении общего лога вдисков. Переход в FAULTY.
* **InitialCommonnLogParseError** - PDisk получил ошибку при парсинге или проверке консистентности общего лога. Переход в FAULTY.
* **CommonLoggerInitError** - PDisk получил ошибку при инициализации внутренних структур предназначенных для записи в общий лог. Переход в FAULTY.
* **Normal** - PDisk завершил иницализацию и работает нормально. Переход в ACTIVE произойдет через это количество Циклов (т.е. по умолчанию если Normal держится 5 минут, переводим диск в ACTIVE)
* **OpenFileError** - PDisk получил ошибку при открытии файла диска. Переход в FAULTY.
* **Missing** - Нода отвечает, но в её списке нет данного PDisk. Переход в FAULTY.
* **Timeout** - Нода не ответила за отведенный таймаут. Переход в FAULTY.
* **NodeDisconnected** - Дисконнект ноды. Переход в FAULTY.
* **Unknown** - Что-то неожиданное, например ответ TEvUndelivered на запрос состояния. Переход в FAULTY.

## Включение/выключение дисков-доноров

При выключенных дисках донорах, при перевозе вдиска, его данные теряются, и их приходится восстанавливать согласно выбранному erasure.

Операция восстановления дороже, чем обычный перевоз данных. Так же происходит потеря данных, что може повлечь за собой потерю данных при выходе за рамки модели отказа.

Для предотвращения выше перечисленных проблем, существуют диски доноры.

При перевозе дисков с включенными дисками донорами, старый вдиск остается жить до тех пор пока новый не перенесет все данные из него к себе.

Диск донор, это старый вдиск после перевоза, который продолжает хранить свои данные и отвечает только на запросы чтения от нового вдиска.

При получении запроса на чтения на данные, которые новый вдиск еще не успел перенести, он перенаправляет запрос к диску донору.

Для включения дисков-доноров, требуется выполнить следующую команду:

`$ kikimr admin bs config invoke --proto 'Command { UpdateSettings { EnableDonorMode: true } }'`

Аналогично при изменение настройки на `false`, команда выключить режим.

## Scrubbing

### Включение/Отключение

**WILL BE SOON**

### Настройки Scrubbing

Настройки Scrub позволяют регулировать интервал времени, который проходит от начала предыдущего цикла скраббинга диска до начала следующего, а также максимальное число дисков, которые могут скрабиться одновременно. Значение по умолчанию — 1 месяц.
`$ kikimr admin bs config invoke --proto 'Command { UpdateSettings { ScrubPeriodicitySeconds: 86400 MaxScrubbedDisksAtOnce: 1 } }'`

**WILL BE SOON**

## Увезти один вдиск с блочного устройтства {#moving_vdisk}

Для того чтобы перевезти диск с блочного устройства, надо зайти на ноду по ssh и выполнить следующую команду.

```bash
kikimr admin bs config invoke --proto 'Command { ReassignGroupDisk { GroupId: <ID группы хранения> GroupGeneration: <Поколение группы хранения> FailRealmIdx: <FailRealm> FailDomainIdx: <FailDomain> VDiskIdx: <Номер слота> } }'
```

Нужную информацию для выполнения команды можно посмотреть во вьювере (ссылка).

## Перевезти вдиски со сломанного/отсутствующего устройства {#removal_from_a_broken_device}

В случае если SelfHeal выключен или не перевозит вдиски, данную операцию придется выполнить вручную.

1. Убедиться в мониторинге, что диск действительно в нерабочем состоянии.  

    Записать fqdn узла, ic-port, путь до диска, pdiskId

2. Зайти на любой узел кластера

3. Выполнить перевоз диска

    ```bash
    kikimr admin bs config invoke --proto 'Command { UpdateDriveStatus { HostKey: { Fqdn: "<Xост>" IcPort: <IC Порт>} Path: "<Путь до партлейбла устройства>" PDiskId: <ID ПДиска> Status: BROKEN } }'
    ```

## Вернуть диск после развоза  {#return_a_device_to_work}

1. Убедиться в мониторинге, что диск в рабочем состоянии  

    Записать fqdn узла, ic-port, путь до диска, pdiskId

2. Зайти на любой узел кластера

3. Вернуть диск

    ```bash
    kikimr admin bs config invoke --proto 'Command { UpdateDriveStatus { HostKey: { Fqdn: "<Xост>" IcPort: <IC Порт>} Path: "<Путь до партлейбла устройства>" PDiskId: <ID ПДиска> Status: ACTIVE } }'
    ```

## Остановка/рестарт процесса ydb на узле {#restart_process}

Чтобы убедиться, что процесс можно остановить, надо выполнить следуюшие шаги.

1. Перейти на ноду по ssh.

1. Выполнить команду

    ```bash
    kikimr cms request restart host {node_id} --user {user} --duration 60 --dry --reason 'some-reason'
    ```

    При разрешение выведет `ALLOW`.

1. Остановить процесс

    ```bash
    sudo service kikimr stop
    ```

1. Если потребуется, запустить процесс

   ```bash
    sudo service kikimr start
    ```

## Замена оборудования {#replace_hardware}

Перед заменой нужно убедиться, что процесс ydb можно [остановить](#restart_process).  
При длительном отсутствии стоит перед этим перевезти все вдиски с данного узла и дождаться окончания репликации.  
После окончания репликации ноду можно безопасно выключать.

Для отключения динамической ноды так же може потребоваться провести дрейн таблеток, дабы избежать эффекта на работающие запросы.

Стоит перейти на страницу web-мониторинга хайва или тенантного хайва.
После нажатия на кнопку "View Nodes" отобразится список всех нод под руководством данного хайва.

В нем представлена различиная информация о запущенных таблетках и используемых ресурсов.
В правой части списка находятся кнопки со следующими действиями для каждой ноды:

* **Active** - включение/отключение ноды для перевоза таблеток на данную ноду
* **Freeze** - запрет для таблеткок подниматься на других нодах
* **Kick** - перевоз всех таблеток разом с ноды
* **Drain** - плавный перевоз всех таблеток с ноды

Перед отключением ноды, сначала требуется отключить перевоз таблеток через кнопку Active, после чего нажать Drain и дождаться увоза всех таблеток.

## Добавление групп хранения

Для добавления групп хранения требуется переопределить конфиг пула в котором требуется расширить.

Перед этим требуется получить конфиг интересуемого пула, это можно сделать следующей командой:

```proto
Command {
  ReadStoragePool{
    BoxId: <box-id>
    // StoragePoolId: <storage-pool-id>
    Name: <имя пула>
  }
}
```
    
```
kikimr -s <ендпоинт> admin bs config invoke --proto-file ReadStoragePool.txt
```

Требуется вставить полученный конфиг пула в протобуф ниже и поменять в нем поле **NumGroups**.

```proto
Command {
  DefineStoragePool {
    <конфиг пула>
  }
}
```
    
```
kikimr -s <ендпоинт> admin bs config invoke --proto-file DefineStoragePool.txt
```

## Изменение количество слотов для вдисков на пдиске

Для добавления групп хранения требуется переопределить конфиг хоста, увеличив для него количество слотов на дисках.

Перед этим требуется получить изменяемые конфиг, это можно сделать следующей командой:

```proto
Command {
  TReadHostConfig{
    HostConfigId: <host-config-id>
  }
}
```
    
```
kikimr -s <ендпоинт> admin bs config invoke --proto-file ReadHostConfig.txt
```

Требуется вставить полученный конфиг в протобуф ниже и поменять в нем поле **PDiskConfig/ExpectedSlotCount**.

```proto
Command {
  TDefineHostConfig {
    <хост конфиг>
  }
}
```
    
```
kikimr -s <ендпоинт> admin bs config invoke --proto-file DefineHostConfig.txt
```

## Проблемы работоспособности кластера {#cluster_liveness_issues}

### Отказало не более 2 дисков входящих в группу хранения block-4-2{#storage_group_lost_two_disk}

При таком отказе потери данных не происходит, система сохраняет работоспособность, успешно выполняются запросы на чтение и запись. Возможно падение производительности вызванное переносом нагрузки обрабатываемой отказавшими дисками на оставшиеся в строю.

При одновременной недоступности 2 дисков по возможности рекомендуется восстановить работоспособность хотя бы одного из них, либо заменить один диск для начала процесса репликации. Это сохранит пространство для маневра в случае отказа третьего диска до завершения репликации.

### Отказало более 2 дисков входящих в группу хранения block-4-2{#exceeded_the_failure_modele}

Доступность и работоспособность системы может быть нарушена. Необходимо восстановить работоспособность хотя бы одного из дисков без потери хранившихся на нем данных.

## Проблемы с дисковой подсистемой {#storage_issues}

При исчерпании места на дисках база данных может отвечать ошибками на все запросы. Для сохранения работоспособности рекомендуется удалить часть данных или расширить кластер блочными устройствами.

Ниже приведены инструкции которые могут помочь добавить или освободить место на дисках.

### Дефрагменировать вдиск

В ходе эксплуатации возникает внутренняя фрагментация вдиска. Узнать степень фрагментации можно на странице мониторинга вдиска. Дефрагментация дисков, фрагментированных на 20 и менее процентов не рекомендуется.

По модели отказа кластер переживает потерю двух вдисков одной группы без потери данных. Если в группе все вдиски работоспособны, нет вдисков в состоянии ошибки или репликации, удаление данных с одного из вдисков приведет к восстановлению вдиском данных в компактном виде. Следует понимать, что избыточность хранения данных будет снижена до завершения автоматической репликации данных.

В процессе репликации данных нагрузка на все вдиски группы будет увеличена, возможно ухудшение времени отклика.

1. Посмотреть коэффициент фрагментации на странице вдиска во вьювере (ссылка).

   Если значение превышает 20%, то дефрагментация позволит освободить место на диске.

2. Проверить состояние группы в которую входит вдиск. В группе не должно быть недосупных вдисков, вдисков в состоянии ошибки или репликации.

    Посмотреть состояние группые можно во вьювере (ссылка).

3. Выполнить команду wipe для вдиска.

    Все данные хранимые вдиском будут необратимо удалены, после чего вдиск начнет восстанавливать данные читая их с остальных вдисков группы.

    ```bash
    kikimr admin blobstorage group reconfigure wipe --domain <Номер домена> --node <ID узла> --pdisk <ID ПДиска> --vslot <Номер слота>
    ```

    Посмотреть нужную информацию для команды можно во вьювере (ссылка).

В случае заканчивающегося места на блочном устройстве, можно применить дефрагментацию на все устрйоство.

1. Проверить состояние групп в кластере. Не должно быть проблемных групп которые находятся на том же узле, что и проблемное устройство.

1. Зайти по ssh на узел где находится этот диск

1. Проверить, можно ли перезапустить процесс (ссылка на файл maintanence)

1. Остановить процесс

    ```bash
    sudo systemctl stop kikimr
    ```

1. Форматировать диск

    ```bash
    sudo kikimr admin blobstorage disk obliterate <путь до партлейбла устройства>
    ```

1. Запустить процесс

    ```bash
    sudo systemctl start kikimr
    ```

### Разложить вдиски равномерно по устройствам

В случае, если вдиски расположены на блочных устройствах не равномерно, можно [перевезти их](#moving_vdisks) по одному с перегруженных устройств.

### Распределить нагрузку равномерно по группам

На странице web-мониторинга хайва, в нижней части экрана есть кнокп "Reassign Groups".
При нажатии на нее появится окно с параметрамми для балансировки:

* **Storage pool** - пулл групп хранения для балансировки
* **Storage group** - в случае если не указан предыдущий пункт, можно указать отдельно только одну группу
* **Type** - тип таблеток для которых будет производиться балансировка
* **Channels** - диапазон каналов, для которых будет производиться балансировка
* **Percent** - процент от общего количества каналов таблеток которые переедут в результате балансировки
* **Inflight** - количество одновременно переезжающих на другие группы таблеток

После указания всех параметров, следует нажать сначала "Query", который покажет количество каналов попавшие под переезде и разблокирует кнопку "Reassign".
При нажатии которой начнется балансировка.


## Изменение настроек в CMS

### Получить текущие настройки

Следующая команда позволит получить текущие настройки по кластеру или по тенанту.

```
./kikimr -s <ендпоинт> admin console configs load --out-dir <папка-для-конфигов>
```

```
./kikimr -s <ендпоинт> admin console configs load --out-dir <папка-для-конфигов> --tenant <имя-тенанта>
```

### Обновить настройки

Сначала надо выкачать нужный конфиг как указано выше, после чего требуется подготовить protobuf файл с запросом на изменение.

```
Actions {
  AddConfigItem {
    ConfigItem {
      Cookie: "<куки>"
      UsageScope {
        TenantAndNodeTypeFilter {
          Tenant: "<имя-тенанта>"
        }
      }
      Config {
          <имя-конфига> {
              <полный конфиг>
          }
      }
    }
  }
}
```

Поле UsageScope необязательно, и нужно для применения настроек для определенного тенанта.

```
./kikimr -s <ендпоинт> admin console configs update <файл-с-настройками>
```

## Изменение конфигурации актор-системы

### На статических нода

Статические ноды берут конфигурацию акторсистемы из файла расположенного kikimr/cfg/sys.txt.

После замены конфигурации требуется перезапустить ноду.

### На динамических нодых

Динамические ноды берут конфигурацию из cms, чтобы изменить ее можно воспользоаться следуюшей командой.

```proto
ConfigureRequest {
  Actions {
    AddConfigItem {
      ConfigItem {
        // UsageScope: { ... }
        Config {
          ActorSystemConfig {
            <конфиг актор-системы>
          }  
        }
        MergeStrategy: 3
      }
    }
  }
}

```
kikimr -s <ендпоинт> admin console execute --domain=<domain> --retry=10 actorsystem.txt
```
