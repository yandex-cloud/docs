# Настройка отказоустойчивой архитектуры в {{ yandex-cloud }}

С помощью этой инструкции вы настроите отказоустойчивую архитектуру в {{ yandex-cloud }} и проверите ее работу на различных тестовых сценариях.

Отказоустойчивость — это свойство системы сохранять свою работоспособность после отказа одной или нескольких ее составных частей.

Чтобы настроить и протестировать архитектуру:

1. [Подготовьте облако к работе](#before-begin).
1. [Настройте тестовый стенд](#prepare):
    - [Подготовьте контейнеры приложения TodoList](#create-app).
    - [Разверните инфраструктуру](#create-environment).
    - [Подготовьте и запустите Load Testing Tool](#create-load-testing-tool).
1. [Выполните тестовые сценарии](#run):
    - [Сбой ВМ](#error-vm).
    - [Сбой приложения](#error-app).
    - [Отключение зоны доступности](#zone-down).
    - [Обновление приложения](#update-app).
    - [Масштабирование конфигурации БД](#scaling-database).

Если созданные ресурсы вам больше не нужны, [удалите их](#clear-out).

## Подготовьте облако к работе {#before-begin}

{% include [before-you-begin](../_tutorials_includes/before-you-begin.md) %}


### Необходимые платные ресурсы {#paid-resources}

В стоимость поддержки отказоустойчивой архитектуры {{ yandex-cloud }} входит:

- Плата за диски и постоянно запущенные виртуальные машины (см. [тарифы {{compute-full-name}}](../../compute/pricing.md)).
- Плата за постоянно запущенный кластер {{ mpg-name }} (см. [тарифы {{mpg-full-name}}](../../managed-postgresql/pricing.md)).
- Плата за использование динамического или статического внешнего IP-адреса (см. [тарифы {{vpc-full-name}}](../../vpc/pricing.md)).


## Настройте тестовый стенд {#prepare}

### Описание тестового стенда {#stand}

Описание тестового стенда: 
- Приложение упаковано в Docker-образ и загружено в {{container-registry-short-name}}.
    
    Docker-образы развернуты на четырех виртуальных машинах на основе {{coi}}. Машины объединены в группу и расположены в двух различных зонах доступности.
- Кластер баз данных работает под управлением сервиса {{mpg-short-name}} и состоит из двух хостов, расположенных в различных зонах доступности.
- Нагрузка генерируется приложением [Load Testing Tool](/marketplace/products/yc/load-testing) из {{ marketplace-name }} и подается на {{network-load-balancer-short-name}}. Сетевой балансировщик нагрузки распределяет трафик по виртуальным машинам.

### Подготовьте контейнеры приложения TodoList {#create-app}

Чтобы подготовить приложение для запуска в {{ yandex-cloud }}:

1. Аутентифицируйтесь в {{container-registry-short-name}}:

    ```bash
    yc container registry configure-docker
    ```

1. Создайте реестр:

    ```bash
    yc container registry create --name todo-registry
    ```

1. Соберите Docker-образ с тегом `v1`:

    ```bash
    docker build . --tag cr.yandex/<registry_id>/todo-demo:v1
    ```

1. Соберите Docker-образ с тегом `v2` (для проверки сценария обновления приложения):

    ```bash
    docker build . --build-arg COLOR_SCHEME=dark --tag cr.yandex/<registry_id>/todo-demo:v2
    ```

1. Загрузите Docker-образы в {{container-registry-short-name}}:

    ```bash
    docker push cr.yandex/<registry_id>/todo-demo:v1
    docker push cr.yandex/<registry_id>/todo-demo:v2
    ```

### Разверните инфраструктуру {#create-environment}

Чтобы подготовить окружение для запуска приложения в {{ yandex-cloud }}:

1. Установите [{{ TF }}](https://www.terraform.io).

1. Скачайте [репозиторий](https://github.com/glebmish/yandex-cloud-fault-tolerance-demo/archive/master.zip) с исходным кодом демо-приложения, {{ TF }}-спецификациями и скриптом для имитации сбоя приложения.

1. Перейдите в директорию со спецификацией окружения:

    ```bash
    cd app
    ```

1. Инициализируйте {{ TF }} в директории со спецификацией:

    ```bash
    terraform init
    ```

1. В файле `app/todo-service.tf` укажите путь к публичному SSH-ключу (значение по умолчанию `~/.ssh/id_ed25519.pub`).

1. Разверните и запустите приложение:

    ```bash
    terraform apply -var yc_folder=<folder_id> -var yc_token=<yc_token> -var user=$USER
    ```

    Где:

    * `folder_id` — каталог, в котором будет развернуто приложение.
    * `yc_token` — OAuth-токен пользователя, от имени которого будет развернуто приложение.

Будут созданы следующие ресурсы:

- Сеть {{ vpc-short-name }} с тремя подсетями во всех зонах доступности.
- Два сервисных аккаунта:
  - Сервисный аккаунт для управления группой ВМ с ролью `editor`.
  - Сервисный аккаунт для скачивания Docker-образа на ВМ с ролью `container-registry.images.puller`.
- Группа ВМ из четырех виртуальных машин на базе {{coi}} в зонах доступности `{{ region-id }}-b` и `{{ region-id }}-c`.
- Кластер {{mpg-short-name}} с двумя хостами в зонах доступности `{{ region-id }}-b` и `{{ region-id }}-c`.
- Сетевой балансировщик нагрузки для распределения трафика по машинам группы ВМ.

Для доступа к приложению перейдите по адресу `lb_address`, полученному в результате выполнения `terraform apply`.

### Подготовьте и запустите приложение Load Testing Tool {#create-load-testing-tool}

{% note warning %}

Перед созданием Load Testing Tool [подготовьте контейнеры приложения TodoList](#create-app) и [разверните инфраструктуру](#create-environment).

{% endnote %}

1. Перейдите в директорию со спецификацией Load Testing Tool:

    ```bash
    cd load-testing-tool
    ```

1. Инициализируйте {{ TF }} в директории со спецификацией Load Testing Tool:

    ```bash
    terraform init
    ```

1. В файле `load-testing-tool/main.tf` укажите путь к публичному и приватному SSH-ключам (значения по умолчанию `~/.ssh/id_ed25519.pub` и `~/.ssh/id_ed25519`).

1. Разверните и запустите ВМ:

    ```bash
    terraform apply -var yc_folder=<folder_id> -var yc_token=<yc_token> -var user=$USER -var overload_token=<overload_token>
    ```

    Где:

    * `folder_id` — каталог, в котором будет развернуто Load Testing Tool.
    * `yc_token`-  OAuth-токен пользователя, от имени которого будет развернуто Load Testing Tool.
    * `overload_token` — токен для подключения к `<overload.yandex.net>`. Для получения токена надо аутентифицироваться, после чего нажать справа вверху на свой профиль и в выпадающем меню выбрать **My api token**.

1. Подключитесь к созданной ВМ по SSH. Адрес для подключения указан в выводе команды `terraform apply`.

1. Запустите Load Testing Tool:

    ```bash
    sudo yandex-tank -c load.yaml
    ```

1. Перейдите в `<overload.yandex.net>` и найдите там запущенную стрельбу: **Public tests** -> **show my tests only**.

## Выполнение сценариев {#run}

### Сбой ВМ {#error-vm}

Как проявляется сбой: недоступна виртуальная машина с приложением.

Возможные причины:

- Падение физического хоста, на котором была запущена ВМ.
- По ошибке удалена ВМ с приложением.

Для имитации сбоя удалите одну из виртуальных машин группы.

Реакция тестового стенда:

1. Сетевой балансировщик нагрузки и {{ ig-name }} получают информацию о сбое машины и выводят ее из балансировки — трафик перестает поступать на эту машину и распределяется между оставшимися ВМ в группе.
1. {{ ig-name }} [автоматически восстанавливается](../../compute/concepts/instance-groups/autohealing.md):
   1. Удаляет недоступную машину (в этом сценарии машина уже удалена, шаг будет пропущен).
   1. Создает новую машину.
   1. Ожидает запуска приложения на созданной машине.
   1. Добавляет машину в балансировку.

Балансировщику нагрузки и {{ ig-name }} требуется некоторое время, чтобы обнаружить проблему и отключить подачу трафика на неисправную машину. Из-за этого возможно появление ошибок Connection Timeout (HTTP-код `0` на графиках **Quantities** и **HTTP codes** в мониторинге Load Testing Tool).

После выведения недоступной машины из балансировки пользовательская нагрузка обрабатывается корректно.

### Сбой приложения {#error-app}

Как проявляется сбой: приложение не отвечает вовремя или работает некорректно с точки зрения пользователя.

Возможные причины:

- Утечка памяти привела к падению приложения.
- Приложение не может продолжить работу из-за потери связности с БД.
- Приложение не успевает обрабатывать запросы из-за большой нагрузки.

В соответствии с настройками [проверки состояния](../../compute/concepts/instance-groups/autohealing.md#setting-up-health-checks) {{ ig-name }} опрашивает машины группы по HTTP-протоколу. При нормальной работе обращение к конечной точке `/healthy` возвращается HTTP-код `200`. Иначе {{ ig-name }} запускает процедуру восстановления.

Для имитации сбоя запустите скрипт:

```bash
fail_random_host.sh <group_id>
```

Случайная машина из группы начнет возвращать HTTP-код `503`.

Реакция тестового стенда:

1. {{ ig-name }} получает информацию о сбое приложения и выводит машину из балансировки — трафик перестает поступать на эту машину и распределяется между оставшимися ВМ в группе.
1. {{ ig-name }} [автоматически восстанавливается](../../compute/concepts/instance-groups/autohealing.md):
   1. Перезагружает неисправную машину.
   1. Ожидает запуска приложения на созданной машине.
   1. Добавляет машину в балансировку.

{{ ig-name }} несколько раз опрашивает машину прежде чем отключить трафик и запустить восстановление. Из-за этого возможно появление ошибок Service Unavailable (HTTP-код `503` на графиках **Quantities** и **HTTP codes** в мониторинге Load Testing Tool).

После выведения неисправной машины из балансировки пользовательская нагрузка обрабатывается корректно.

### Отключение зоны доступности {#zone-down}

Как проявляется сбой: недоступны несколько виртуальных машин в одной зоне.

Возможные причины:

- Перебои в работе дата-центра.
- Плановые технические работы в дата-центре.

Чтобы перенести ресурсы в другой дата-центр:

1. В [консоли управления]({{ link-console-main }}) выберите каталог с вашей группой виртуальных машин.
1. В списке сервисов выберите {{compute-name}}.
1. Нажмите **Группы виртуальных машин**.
1. Выберите группу `todo-ig`.
1. Нажмите кнопку **Изменить**.
1. В блоке **Распределение** снимите галочку с зоны доступности `{{ region-id }}-с`.
1. Нажмите кнопку **Сохранить изменения**.

Реакция тестового стенда:

1. {{ ig-name }} выводит из балансировки машины в зоне доступности `{{ region-id }}-с`.
1. Выведенные машины удаляются, одновременно с этим создаются машины в зоне `{{ region-id }}-b`.
1. {{ ig-name }} добавляет созданные машины в балансировку.

Количество одновременно создаваемых и удаляемых машин определяется [политикой развертывания](../../compute/concepts/instance-groups/policies/deploy-policy.md).

Во время выведения машин из балансировки возможно появление ошибок Connection Timeout (HTTP-код `0` на графиках **Quantities** и **HTTP codes** в мониторинге Load Testing Tool).

После выведения машин из балансировки пользовательская нагрузка обрабатывается корректно.

### Обновление приложения {#update-app}

Чтобы обновить приложение:

1. В [консоли управления]({{ link-console-main }}) выберите каталог с вашей Группой виртуальных машин.
1. В списке сервисов выберите {{compute-name}}.
1. Нажмите **Группы виртуальных машин**.
1. Выберите группу `todo-ig`.
1. Нажмите кнопку **Изменить**.
1. В блоке **Шаблон виртуальной машины** нажмите ![horizontal-ellipsis](../../_assets/horizontal-ellipsis.svg) и выберите **Изменить**.
1. На вкладке **Container Solution** выберите необходимый Docker-контейнер.
1. В открывшемся окне в поле **Docker-образ** укажите имя Docker-образа с новой версией приложения.
1. Нажмите кнопку **Применить**.
1. Нажмите кнопку **Сохранить**.
1. Нажмите кнопку **Сохранить изменения**.

Реакция тестового стенда:

1. {{ ig-name }} выводит из балансировки две машины с устаревшей версией приложения ([статус](../../compute/concepts/instance-groups/statuses.md#vm-statuses) таких машин `RUNNING_OUTDATED`).
1. Удаляет выведенные машины, одновременно с этим создает машины с новой версией приложения.
1. Добавляет созданные машины в балансировку.
1. Действия повторяются для оставшихся двух машин с устаревшей версией приложения.

Обновите страницу приложения. Если сетевой балансировщик отправит ваш запрос на уже обновленную машину, то вы увидите версию приложения с темной цветовой схемой.

Количество одновременно создаваемых и удаляемых машин определяется [политикой развертывания](../../compute/concepts/instance-groups/policies/deploy-policy.md).

Во время выведения машин из балансировки возможно появление ошибок Connection Timeout (HTTP-код `0` на графиках **Quantities** и **HTTP codes** в мониторинге Load Testing Tool).

После выведения машин из балансировки пользовательская нагрузка обрабатывается корректно.

### Масштабирование конфигурации БД {#scaling-database}

Масштабирование БД может потребоваться, если:

- Производительности хостов в кластере не хватает для обработки запросов.
- Для данных требуется хранилище большего объема.

Чтобы масштабировать конфигурацию:

1. В [консоли управления]({{ link-console-main }}) выберите каталог с вашим кластером БД.
1. В списке сервисов выберите {{mpg-short-name}}.
1. Выберите кластер `todo-postgresql`.
1. Нажмите **Изменить кластер**.
1. В блоке **Класс хоста** выберите **s2.medium**.
1. Нажмите кнопку **Сохранить изменения**.

{{mpg-short-name}} запустит операцию изменения кластера.

При переключении между мастером и репликой (в начале и в конце процесса изменения) возможно появление ошибок Internal Server Error (HTTP-код `500` на графиках **Quantities** и **HTTP codes** в мониторинге Load Testing Tool).

После переключения пользовательская нагрузка обрабатывается корректно.

## Удаление приложений и окружения {#clear-out}

{% note warning %}

Если создана ВМ с Load Testing Tool, необходимо сначала удалить ее, иначе удаление {{ vpc-short-name }} завершится с ошибкой.

{% endnote %}

Чтобы удалить приложение Load Testing Tool, перейдите в каталог `load-testing-tool` и выполните следующую команду:

```bash
terraform destroy -var yc_folder=<folder_id> -var yc_token=<yc_token> -var user=$USER -var overload_token=not-used
```

Чтобы удалить приложение TodoList, перейдите в каталог `app` и выполните следующую команду:

```bash
terraform destroy -var yc_folder=<folder_id> -var yc_token=<yc_token> -var user=$USER
```
