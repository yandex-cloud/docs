# Обзор AI-моделей сервиса {{ foundation-models-full-name }}

{{ foundation-models-full-name }} предоставляет широкие возможности для работы с генеративным моделями для решения бизнес-задач:

* Собственные и опенсорс-модели в [базовом инстансе](./models.md#generation) c [оплатой](../../pricing.md#rules-generating) за потребленные [токены](./tokens.md).  
* [Дообучение](../tuning/index.md) моделей по методу {{ lora }}.
* Готовые и дообучаемые модели [классификации](../classifier/index.md) текста.
* Большой выбор [текстовых](./models.md#text-batch) и [мультимодальных](./models.md#multimodels-batch) опенсорс-моделей для обработки больших объемов данных в пакетном режиме с [предоплаченным минимальным объемом токенов](../../pricing.md#rules-generating).
* Выделенные инстансы моделей, если вам требуется обрабатывать большие объемы данных с гарантированным временем ответа.

Для работы с моделями доступны два интерфейса: {{ ai-playground }} в консоли управления и различные API для [создания агентов](../agents/index.md) и прямого обращения к моделям.

## Собственные модели Яндекса {#yandex}

В {{ model-gallery-name }} доступны разработанные в Яндексе модели генерации текста и изображений, которые вы можете использовать для бизнеса. 

Самая маленькая и быстрая текстовая модель {{ gpt-lite }} отлично справляется с задачами, где важна скорость ответа и не требуются сложные рассуждения и глубокие познания в сложных предметных областях. Например, {{ gpt-lite }} можно использовать для классификации входящих сообщений пользователей, форматирования текста или суммаризации встреч. 

{{ gpt-pro }} подойдет для решения более сложных задач: поиска по базам знаний и генерации результатов на основе найденной информации (RAG-сценарий), анализа документов, построения отчетов и аналитики, извлечения информации и автоматизации заполнения полей, форм и баз CRM. 

{{ alice-ai }} — новая флагманская модель Яндекса — не только решает сложные задачи не хуже {{ gpt-pro }}, но и значительно лучше поддерживает диалог в чатовых сценариях, извлекая информацию из всего полученного контекста. {{ alice-ai }} отлично подойдет для создания «человеко-ориентированных» AI-ассистентов.

Текстовые модели Яндекса могут понимать около 20 языков, в том числе английский и японский, но предназначены в первую очередь для эффективной работы с текстами на русском языке. Собственный [токенизатор](./tokens.md) позволяет моделям Яндекса эффективнее потреблять токены по сравнению с другими доступными моделями, что экономит ваши средства. [Пример расчета стоимости](../../pricing.md#example-generating) использования разных моделей для решения одной задачи доступен на [странице тарификации](../../pricing.md#text-sync-async).

Кроме текстовых моделей в {{ model-gallery-name }} доступна модель {{ yandexart-name }} — генеративная нейросеть, которая создает изображения по текстовому запросу. {{ yandexart-name }} работает по методу каскадной диффузии, итеративно детализируя изображения из шума. Вы можете указать формат итогового изображения в параметре `mime_type`. На данный момент поддерживается значение `image/jpeg`. По умолчанию {{ yandexart-name }} генерирует изображение размером 1024 х 1024 пикселя. Этот размер может увеличиваться или уменьшаться в зависимости от заданного соотношения сторон, но не более чем на 10%. Примеры инструкций и запросов собраны в [библиотеке промптов {{ yandexart-name }}](../../prompts/yandexart/index.md).

Текстовые модели Яндекса доступны через {{ openai }}-совместимые Completions API и {{ responses-api }}, а также собственный API генерации текста в форматах [REST](../../text-generation/api-ref/index.md) и [gRPC](../../text-generation/api-ref/grpc/index.md).
{{ yandexart-name }} предоставляет собственный API генерации изображений, также доступный в форматах [REST](../../image-generation/api-ref/index.md) и [gRPC](../../image-generation/api-ref/grpc/index.md).
 
Кроме того, все модели доступны через {{ ml-sdk-name }} и в [{{ ai-playground }}]({{ link-console-main }}/link/ai-studio/). 

## Режимы работы с моделями {{ ai-studio-name }} {#working-mode}

Модели {{ ai-studio-name }} имеют три режима взаимодействия: _синхронный_, _асинхронный_ и _пакетный_. Режимы отличаются временем ответа и логикой работы.

В синхронном режиме модель получает ваш запрос и возвращает результат сразу после обработки. Задержка ответа в синхронном режиме минимальна, однако он не придет моментально: для работы модели требуется время, которое зависит от модели и от загруженности системы. При включенной опции `stream` модель в процессе присылает промежуточные варианты генерации. Синхронный режим подходит, если вам нужно поддерживать диалог [чат-бота](../../../glossary/chat-bot.md). В синхронном режиме модели доступны в {{ ai-playground }}, {{ ml-sdk-name }}, через API генерации текста, и {{ openai }}-совместимые API.

В асинхронном режиме в ответ на полученный запрос модель присылает [объект Operation](../../../api-design-guide/concepts/operation.md), который содержит идентификатор выполняемой операции. По идентификатору вы можете узнать статус запроса и позже получить его результат, отправив запрос на специальный эндпоинт получения результата (его значение зависит от модели). Промежуточные результаты генерации недоступны в асинхронном режиме. Как правило, генерация результата в асинхронном режиме занимает больше времени (от пары минут до нескольких часов), чем в синхронном, но будет стоить дешевле. Асинхронный режим подходит, если ваши задачи не требуют срочного ответа. В асинхронном режиме некоторые модели доступны в {{ ml-sdk-name }}, через API генерации текста и API генерации изображений.

Пакетный режим работы (batch processing) позволяет обрабатывать большой массив данных за один запрос к модели. Входные данные передаются в виде [датасета](../resources/dataset.md), тип датасета зависит от модели. Для каждого запроса сервис {{ foundation-models-name }} запускает индивидуальный инстанс модели, который обрабатывает датасет, а после выключает его. Результат сохраняется в виде еще одного датасета, который вы можете скачать в формате [Parquet](https://parquet.apache.org/) или сразу же использовать, например, для дообучения другой модели. Генерация результата может занять несколько часов. Обработать данные в пакетном режиме можно в консоли управления, с помощью {{ ml-sdk-name }} и через Batch API. Список моделей, доступных в пакетном режиме, см. в разделе [{#T}](./batch-processing.md).

#### См. также {#see-also}

* [{#T}](../../prompts/yandexgpt/index.md)
* [{#T}](./chain-of-thought.md)
* [{#T}](../../operations/generation/create-prompt.md)
* [{#T}](../../operations/generation/async-request.md)