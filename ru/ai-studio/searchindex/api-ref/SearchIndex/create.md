---
editable: false
apiPlayground:
  - url: https://rest-assistant.{{ api-host }}/assistants/v1/searchIndex
    method: post
    path: null
    query: null
    body:
      type: object
      properties:
        folderId:
          description: |-
            **string**
            Required field. 
          type: string
        fileIds:
          description: |-
            **string**
            List of file IDs to be indexed.
          type: array
          items:
            type: string
        name:
          description: |-
            **string**
            Name of the search index.
          type: string
        description:
          description: |-
            **string**
            Description of the search index.
          type: string
        expirationConfig:
          description: |-
            **[ExpirationConfig](#yandex.cloud.ai.common.ExpirationConfig)**
            Expiration configuration for the search index.
          $ref: '#/definitions/ExpirationConfig'
        labels:
          description: |-
            **object** (map<**string**, **string**>)
            Set of key-value pairs to label the search index.
          type: object
          additionalProperties:
            type: string
        textSearchIndex:
          description: |-
            **[TextSearchIndex](#yandex.cloud.ai.assistants.v1.searchindex.TextSearchIndex)**
            Configuration for a traditional keyword-based text search index.
            Includes only one of the fields `textSearchIndex`, `vectorSearchIndex`, `hybridSearchIndex`.
          $ref: '#/definitions/TextSearchIndex'
        vectorSearchIndex:
          description: |-
            **[VectorSearchIndex](#yandex.cloud.ai.assistants.v1.searchindex.VectorSearchIndex)**
            Configuration for a vector-based search index using embeddings.
            Includes only one of the fields `textSearchIndex`, `vectorSearchIndex`, `hybridSearchIndex`.
          $ref: '#/definitions/VectorSearchIndex'
        hybridSearchIndex:
          description: |-
            **[HybridSearchIndex](#yandex.cloud.ai.assistants.v1.searchindex.HybridSearchIndex)**
            Configuration for a hybrid (vector-based + keyword-based) search index.
            Includes only one of the fields `textSearchIndex`, `vectorSearchIndex`, `hybridSearchIndex`.
          $ref: '#/definitions/HybridSearchIndex'
      required:
        - folderId
      additionalProperties: false
      oneOf:
        - required:
            - textSearchIndex
        - required:
            - vectorSearchIndex
        - required:
            - hybridSearchIndex
    definitions:
      ExpirationConfig:
        type: object
        properties:
          expirationPolicy:
            description: |-
              **enum** (ExpirationPolicy)
              - `EXPIRATION_POLICY_UNSPECIFIED`
              - `STATIC`
              - `SINCE_LAST_ACTIVE`
            type: string
            enum:
              - EXPIRATION_POLICY_UNSPECIFIED
              - STATIC
              - SINCE_LAST_ACTIVE
          ttlDays:
            description: '**string** (int64)'
            type: string
            format: int64
      StaticChunkingStrategy:
        type: object
        properties:
          maxChunkSizeTokens:
            description: |-
              **string** (int64)
              The maximum number of tokens allowed in a single chunk.
              Constraints: must be within the range [100, 2048].
              Default value: 800
            default: '800'
            type: string
            format: int64
          chunkOverlapTokens:
            description: |-
              **string** (int64)
              The number of tokens that should overlap between consecutive chunks.
              This allows for some context from the previous chunk to be included in the next chunk.
              Constraints: must be less than or equal to half of `max_chunk_size_tokens`.
              Default value: 400
            default: '400'
            type: string
            format: int64
      ChunkingStrategy:
        type: object
        properties:
          staticStrategy:
            description: |-
              **[StaticChunkingStrategy](#yandex.cloud.ai.assistants.v1.searchindex.StaticChunkingStrategy)**
              Includes only one of the fields `staticStrategy`.
            $ref: '#/definitions/StaticChunkingStrategy'
        oneOf:
          - required:
              - staticStrategy
      NgramTokenizer:
        type: object
        properties:
          minGram:
            description: |-
              **string** (int64)
              Minimum length of characters in a gram. Defaults to 3
            type: string
            format: int64
          maxGram:
            description: |-
              **string** (int64)
              Maximum length of characters in a gram. Defaults to 4
            type: string
            format: int64
      StandardTokenizer:
        type: object
        properties: {}
      StandardAnalyzer:
        type: object
        properties: {}
      YandexLemmerAnalyzer:
        type: object
        properties: {}
      TextSearchIndex:
        type: object
        properties:
          chunkingStrategy:
            description: |-
              **[ChunkingStrategy](#yandex.cloud.ai.assistants.v1.searchindex.ChunkingStrategy)**
              Chunking strategy used to split text into smaller chunks before indexing.
              In the case of text search, tokens are individual text characters.
            $ref: '#/definitions/ChunkingStrategy'
          ngramTokenizer:
            description: |-
              **[NgramTokenizer](#yandex.cloud.ai.assistants.v1.searchindex.NgramTokenizer)**
              Tokenizer that generates n-grams.
              Includes only one of the fields `ngramTokenizer`, `standardTokenizer`.
              Tokenizer type used for text search. The tokenizer determines how the
              input text is broken down into tokens before indexing.
              If not specified, the default tokenizer configuration is applied.
            deprecated: true
            $ref: '#/definitions/NgramTokenizer'
          standardTokenizer:
            description: |-
              **object**
              Tokenizer that generates words.
              Includes only one of the fields `ngramTokenizer`, `standardTokenizer`.
              Tokenizer type used for text search. The tokenizer determines how the
              input text is broken down into tokens before indexing.
              If not specified, the default tokenizer configuration is applied.
            $ref: '#/definitions/StandardTokenizer'
          standardAnalyzer:
            description: |-
              **object**
              Standard analyzer that performs common text processing operations to normalize text.
              Includes only one of the fields `standardAnalyzer`, `yandexLemmerAnalyzer`.
              Analyzer type used for text search. The analyzer determines how the
              tokenized text is further processed before indexing.
              If not specified, the default analyzer configuration is applied.
            $ref: '#/definitions/StandardAnalyzer'
          yandexLemmerAnalyzer:
            description: |-
              **object**
              Specialized analyzer that uses Yandex's lemmatization technology,
              particularly effective for Russian and other Slavic languages.
              Includes only one of the fields `standardAnalyzer`, `yandexLemmerAnalyzer`.
              Analyzer type used for text search. The analyzer determines how the
              tokenized text is further processed before indexing.
              If not specified, the default analyzer configuration is applied.
            $ref: '#/definitions/YandexLemmerAnalyzer'
        allOf:
          - oneOf:
              - required:
                  - ngramTokenizer
              - required:
                  - standardTokenizer
          - oneOf:
              - required:
                  - standardAnalyzer
              - required:
                  - yandexLemmerAnalyzer
      VectorSearchIndex:
        type: object
        properties:
          docEmbedderUri:
            description: |-
              **string**
              The [ID of the model](/docs/foundation-models/concepts/embeddings) to be used for obtaining document text embeddings.
            type: string
          queryEmbedderUri:
            description: |-
              **string**
              The [ID of the model](/docs/foundation-models/concepts/embeddings) to be used for obtaining query text embeddings.
            type: string
          chunkingStrategy:
            description: |-
              **[ChunkingStrategy](#yandex.cloud.ai.assistants.v1.searchindex.ChunkingStrategy)**
              Chunking strategy used to split text into smaller chunks before indexing.
              In the case of vector search, tokens are produced by the tokenizer from the embedding model.
            $ref: '#/definitions/ChunkingStrategy'
      MeanCombinationStrategy:
        type: object
        properties:
          meanEvaluationTechnique:
            description: |-
              **enum** (MeanEvaluationTechnique)
              Technique for averaging relevance scores from different indices. Default is ARITHMETIC
              - `MEAN_EVALUATION_TECHNIQUE_UNSPECIFIED`
              - `ARITHMETIC`: https://en.wikipedia.org/wiki/Arithmetic_mean
              - `GEOMETRIC`: https://en.wikipedia.org/wiki/Geometric_mean
              - `HARMONIC`: https://en.wikipedia.org/wiki/Harmonic_mean
            type: string
            enum:
              - MEAN_EVALUATION_TECHNIQUE_UNSPECIFIED
              - ARITHMETIC
              - GEOMETRIC
              - HARMONIC
          weights:
            description: |-
              **string**
              Weights used for evaluating the weighted mean of relevance scores. The sum of the values must equal 1.0
              If not provided, all scores are given equal weight
            type: array
            items:
              type: string
      ReciprocalRankFusionCombinationStrategy:
        type: object
        properties:
          k:
            description: |-
              **string** (int64)
              The parameter k for RRFscore. Default is 60
            type: string
            format: int64
      CombinationStrategy:
        type: object
        properties:
          meanCombination:
            description: |-
              **[MeanCombinationStrategy](#yandex.cloud.ai.assistants.v1.searchindex.MeanCombinationStrategy)**
              Includes only one of the fields `meanCombination`, `rrfCombination`.
            $ref: '#/definitions/MeanCombinationStrategy'
          rrfCombination:
            description: |-
              **[ReciprocalRankFusionCombinationStrategy](#yandex.cloud.ai.assistants.v1.searchindex.ReciprocalRankFusionCombinationStrategy)**
              Includes only one of the fields `meanCombination`, `rrfCombination`.
            $ref: '#/definitions/ReciprocalRankFusionCombinationStrategy'
        oneOf:
          - required:
              - meanCombination
          - required:
              - rrfCombination
      HybridSearchIndex:
        type: object
        properties:
          textSearchIndex:
            description: |-
              **[TextSearchIndex](#yandex.cloud.ai.assistants.v1.searchindex.TextSearchIndex)**
              Configuration for a traditional keyword-based text search index.
            $ref: '#/definitions/TextSearchIndex'
          vectorSearchIndex:
            description: |-
              **[VectorSearchIndex](#yandex.cloud.ai.assistants.v1.searchindex.VectorSearchIndex)**
              Configuration for a vector-based search index.
            $ref: '#/definitions/VectorSearchIndex'
          chunkingStrategy:
            description: |-
              **[ChunkingStrategy](#yandex.cloud.ai.assistants.v1.searchindex.ChunkingStrategy)**
              Common chunking strategy that applies to both text and vector search indexes.
              If provided, it overrides the individual chunking strategies in both `text_search_index` and `vector_search_index`.
              In this case, both text and vector search will use token-based chunking, where tokens are produced by the tokenizer of the embedding model.
            $ref: '#/definitions/ChunkingStrategy'
          normalizationStrategy:
            description: |-
              **enum** (NormalizationStrategy)
              Normalization strategy for relevance scores from different indices. Default is MIN_MAX_STRATEGY
              - `NORMALIZATION_STRATEGY_UNSPECIFIED`
              - `MIN_MAX`: https://en.wikipedia.org/wiki/Feature_scaling#Rescaling_(min-max_normalization)
              - `L2`: https://en.wikipedia.org/wiki/Cosine_similarity#L2-normalized_Euclidean_distance
            type: string
            enum:
              - NORMALIZATION_STRATEGY_UNSPECIFIED
              - MIN_MAX
              - L2
          combinationStrategy:
            description: |-
              **[CombinationStrategy](#yandex.cloud.ai.assistants.v1.searchindex.CombinationStrategy)**
              Combination strategy for merging rankings from different indices. Default is arithmetic mean
            $ref: '#/definitions/CombinationStrategy'
sourcePath: en/_api-ref/ai/assistants/v1/searchindex/api-ref/SearchIndex/create.md
---

# Search Index, REST: SearchIndex.Create

Create a new search index in [asynchronous mode](/docs/foundation-models/concepts/#working-mode).

## HTTP request

```
POST https://rest-assistant.{{ api-host }}/assistants/v1/searchIndex
```

## Body parameters {#yandex.cloud.ai.assistants.v1.searchindex.CreateSearchIndexRequest}

```json
{
  "folderId": "string",
  "fileIds": [
    "string"
  ],
  "name": "string",
  "description": "string",
  "expirationConfig": {
    "expirationPolicy": "string",
    "ttlDays": "string"
  },
  "labels": "object",
  // Includes only one of the fields `textSearchIndex`, `vectorSearchIndex`, `hybridSearchIndex`
  "textSearchIndex": {
    "chunkingStrategy": {
      // Includes only one of the fields `staticStrategy`
      "staticStrategy": {
        "maxChunkSizeTokens": "string",
        "chunkOverlapTokens": "string"
      }
      // end of the list of possible fields
    },
    // Includes only one of the fields `ngramTokenizer`, `standardTokenizer`
    "ngramTokenizer": {
      "minGram": "string",
      "maxGram": "string"
    },
    "standardTokenizer": "object",
    // end of the list of possible fields
    // Includes only one of the fields `standardAnalyzer`, `yandexLemmerAnalyzer`
    "standardAnalyzer": "object",
    "yandexLemmerAnalyzer": "object"
    // end of the list of possible fields
  },
  "vectorSearchIndex": {
    "docEmbedderUri": "string",
    "queryEmbedderUri": "string",
    "chunkingStrategy": {
      // Includes only one of the fields `staticStrategy`
      "staticStrategy": {
        "maxChunkSizeTokens": "string",
        "chunkOverlapTokens": "string"
      }
      // end of the list of possible fields
    }
  },
  "hybridSearchIndex": {
    "textSearchIndex": {
      "chunkingStrategy": {
        // Includes only one of the fields `staticStrategy`
        "staticStrategy": {
          "maxChunkSizeTokens": "string",
          "chunkOverlapTokens": "string"
        }
        // end of the list of possible fields
      },
      // Includes only one of the fields `ngramTokenizer`, `standardTokenizer`
      "ngramTokenizer": {
        "minGram": "string",
        "maxGram": "string"
      },
      "standardTokenizer": "object",
      // end of the list of possible fields
      // Includes only one of the fields `standardAnalyzer`, `yandexLemmerAnalyzer`
      "standardAnalyzer": "object",
      "yandexLemmerAnalyzer": "object"
      // end of the list of possible fields
    },
    "vectorSearchIndex": {
      "docEmbedderUri": "string",
      "queryEmbedderUri": "string",
      "chunkingStrategy": {
        // Includes only one of the fields `staticStrategy`
        "staticStrategy": {
          "maxChunkSizeTokens": "string",
          "chunkOverlapTokens": "string"
        }
        // end of the list of possible fields
      }
    },
    "chunkingStrategy": {
      // Includes only one of the fields `staticStrategy`
      "staticStrategy": {
        "maxChunkSizeTokens": "string",
        "chunkOverlapTokens": "string"
      }
      // end of the list of possible fields
    },
    "normalizationStrategy": "string",
    "combinationStrategy": {
      // Includes only one of the fields `meanCombination`, `rrfCombination`
      "meanCombination": {
        "meanEvaluationTechnique": "string",
        "weights": [
          "string"
        ]
      },
      "rrfCombination": {
        "k": "string"
      }
      // end of the list of possible fields
    }
  }
  // end of the list of possible fields
}
```

Request to create a new search index.

#|
||Field | Description ||
|| folderId | **string**

Required field.  ||
|| fileIds[] | **string**

List of file IDs to be indexed. ||
|| name | **string**

Name of the search index. ||
|| description | **string**

Description of the search index. ||
|| expirationConfig | **[ExpirationConfig](#yandex.cloud.ai.common.ExpirationConfig)**

Expiration configuration for the search index. ||
|| labels | **object** (map<**string**, **string**>)

Set of key-value pairs to label the search index. ||
|| textSearchIndex | **[TextSearchIndex](#yandex.cloud.ai.assistants.v1.searchindex.TextSearchIndex)**

Configuration for a traditional keyword-based text search index.

Includes only one of the fields `textSearchIndex`, `vectorSearchIndex`, `hybridSearchIndex`. ||
|| vectorSearchIndex | **[VectorSearchIndex](#yandex.cloud.ai.assistants.v1.searchindex.VectorSearchIndex)**

Configuration for a vector-based search index using embeddings.

Includes only one of the fields `textSearchIndex`, `vectorSearchIndex`, `hybridSearchIndex`. ||
|| hybridSearchIndex | **[HybridSearchIndex](#yandex.cloud.ai.assistants.v1.searchindex.HybridSearchIndex)**

Configuration for a hybrid (vector-based + keyword-based) search index.

Includes only one of the fields `textSearchIndex`, `vectorSearchIndex`, `hybridSearchIndex`. ||
|#

## ExpirationConfig {#yandex.cloud.ai.common.ExpirationConfig}

#|
||Field | Description ||
|| expirationPolicy | **enum** (ExpirationPolicy)

- `EXPIRATION_POLICY_UNSPECIFIED`
- `STATIC`
- `SINCE_LAST_ACTIVE` ||
|| ttlDays | **string** (int64) ||
|#

## TextSearchIndex {#yandex.cloud.ai.assistants.v1.searchindex.TextSearchIndex}

Defines the configuration for a traditional keyword-based text search index.

#|
||Field | Description ||
|| chunkingStrategy | **[ChunkingStrategy](#yandex.cloud.ai.assistants.v1.searchindex.ChunkingStrategy)**

Chunking strategy used to split text into smaller chunks before indexing.
In the case of text search, tokens are individual text characters. ||
|| ngramTokenizer | **[NgramTokenizer](#yandex.cloud.ai.assistants.v1.searchindex.NgramTokenizer)**

Tokenizer that generates n-grams.

Includes only one of the fields `ngramTokenizer`, `standardTokenizer`.

Tokenizer type used for text search. The tokenizer determines how the
input text is broken down into tokens before indexing.
If not specified, the default tokenizer configuration is applied. ||
|| standardTokenizer | **object**

Tokenizer that generates words.

Includes only one of the fields `ngramTokenizer`, `standardTokenizer`.

Tokenizer type used for text search. The tokenizer determines how the
input text is broken down into tokens before indexing.
If not specified, the default tokenizer configuration is applied. ||
|| standardAnalyzer | **object**

Standard analyzer that performs common text processing operations to normalize text.

Includes only one of the fields `standardAnalyzer`, `yandexLemmerAnalyzer`.

Analyzer type used for text search. The analyzer determines how the
tokenized text is further processed before indexing.
If not specified, the default analyzer configuration is applied. ||
|| yandexLemmerAnalyzer | **object**

Specialized analyzer that uses Yandex's lemmatization technology,
particularly effective for Russian and other Slavic languages.

Includes only one of the fields `standardAnalyzer`, `yandexLemmerAnalyzer`.

Analyzer type used for text search. The analyzer determines how the
tokenized text is further processed before indexing.
If not specified, the default analyzer configuration is applied. ||
|#

## ChunkingStrategy {#yandex.cloud.ai.assistants.v1.searchindex.ChunkingStrategy}

Defines a general strategy for chunking text into smaller segments.
Currently, only StaticChunkingStrategy is supported.

#|
||Field | Description ||
|| staticStrategy | **[StaticChunkingStrategy](#yandex.cloud.ai.assistants.v1.searchindex.StaticChunkingStrategy)**

Includes only one of the fields `staticStrategy`. ||
|#

## StaticChunkingStrategy {#yandex.cloud.ai.assistants.v1.searchindex.StaticChunkingStrategy}

Defines a chunking strategy where chunks are created with a fixed maximum chunk size and an overlap between consecutive chunks.

#|
||Field | Description ||
|| maxChunkSizeTokens | **string** (int64)

The maximum number of tokens allowed in a single chunk.
Constraints: must be within the range [100, 2048].
Default value: 800 ||
|| chunkOverlapTokens | **string** (int64)

The number of tokens that should overlap between consecutive chunks.
This allows for some context from the previous chunk to be included in the next chunk.
Constraints: must be less than or equal to half of `max_chunk_size_tokens`.
Default value: 400 ||
|#

## NgramTokenizer {#yandex.cloud.ai.assistants.v1.searchindex.NgramTokenizer}

Configuration for the NgramTokenizer, which splits text into overlapping character sequences (n-grams) of specified lengths.

Example:
Input text: `hello`
min_gram = 2, max_gram = 3

Generated tokens:
* For n = 2 (2-character n-grams): `he`, `el`, `ll`, `lo`
* For n = 3 (3-character n-grams): `hel`, `ell`, `llo`

Final tokens: `[he, el, ll, lo, hel, ell, llo]`

#|
||Field | Description ||
|| minGram | **string** (int64)

Minimum length of characters in a gram. Defaults to 3 ||
|| maxGram | **string** (int64)

Maximum length of characters in a gram. Defaults to 4 ||
|#

## VectorSearchIndex {#yandex.cloud.ai.assistants.v1.searchindex.VectorSearchIndex}

Defines the configuration for a vector-based search index. This type uses embeddings to represent documents and queries.

#|
||Field | Description ||
|| docEmbedderUri | **string**

The [ID of the model](/docs/foundation-models/concepts/embeddings) to be used for obtaining document text embeddings. ||
|| queryEmbedderUri | **string**

The [ID of the model](/docs/foundation-models/concepts/embeddings) to be used for obtaining query text embeddings. ||
|| chunkingStrategy | **[ChunkingStrategy](#yandex.cloud.ai.assistants.v1.searchindex.ChunkingStrategy)**

Chunking strategy used to split text into smaller chunks before indexing.
In the case of vector search, tokens are produced by the tokenizer from the embedding model. ||
|#

## HybridSearchIndex {#yandex.cloud.ai.assistants.v1.searchindex.HybridSearchIndex}

Defines the configuration for a hybrid (vector-based + keyword-based) search index. This type uses both embeddings and keyword-based search to represent documents and queries.

#|
||Field | Description ||
|| textSearchIndex | **[TextSearchIndex](#yandex.cloud.ai.assistants.v1.searchindex.TextSearchIndex)**

Configuration for a traditional keyword-based text search index. ||
|| vectorSearchIndex | **[VectorSearchIndex](#yandex.cloud.ai.assistants.v1.searchindex.VectorSearchIndex)**

Configuration for a vector-based search index. ||
|| chunkingStrategy | **[ChunkingStrategy](#yandex.cloud.ai.assistants.v1.searchindex.ChunkingStrategy)**

Common chunking strategy that applies to both text and vector search indexes.
If provided, it overrides the individual chunking strategies in both `text_search_index` and `vector_search_index`.
In this case, both text and vector search will use token-based chunking, where tokens are produced by the tokenizer of the embedding model. ||
|| normalizationStrategy | **enum** (NormalizationStrategy)

Normalization strategy for relevance scores from different indices. Default is MIN_MAX_STRATEGY

- `NORMALIZATION_STRATEGY_UNSPECIFIED`
- `MIN_MAX`: https://en.wikipedia.org/wiki/Feature_scaling#Rescaling_(min-max_normalization)
- `L2`: https://en.wikipedia.org/wiki/Cosine_similarity#L2-normalized_Euclidean_distance ||
|| combinationStrategy | **[CombinationStrategy](#yandex.cloud.ai.assistants.v1.searchindex.CombinationStrategy)**

Combination strategy for merging rankings from different indices. Default is arithmetic mean ||
|#

## CombinationStrategy {#yandex.cloud.ai.assistants.v1.searchindex.CombinationStrategy}

Combination strategy for merging rankings from different indices

#|
||Field | Description ||
|| meanCombination | **[MeanCombinationStrategy](#yandex.cloud.ai.assistants.v1.searchindex.MeanCombinationStrategy)**

Includes only one of the fields `meanCombination`, `rrfCombination`. ||
|| rrfCombination | **[ReciprocalRankFusionCombinationStrategy](#yandex.cloud.ai.assistants.v1.searchindex.ReciprocalRankFusionCombinationStrategy)**

Includes only one of the fields `meanCombination`, `rrfCombination`. ||
|#

## MeanCombinationStrategy {#yandex.cloud.ai.assistants.v1.searchindex.MeanCombinationStrategy}

#|
||Field | Description ||
|| meanEvaluationTechnique | **enum** (MeanEvaluationTechnique)

Technique for averaging relevance scores from different indices. Default is ARITHMETIC

- `MEAN_EVALUATION_TECHNIQUE_UNSPECIFIED`
- `ARITHMETIC`: https://en.wikipedia.org/wiki/Arithmetic_mean
- `GEOMETRIC`: https://en.wikipedia.org/wiki/Geometric_mean
- `HARMONIC`: https://en.wikipedia.org/wiki/Harmonic_mean ||
|| weights[] | **string**

Weights used for evaluating the weighted mean of relevance scores. The sum of the values must equal 1.0
If not provided, all scores are given equal weight ||
|#

## ReciprocalRankFusionCombinationStrategy {#yandex.cloud.ai.assistants.v1.searchindex.ReciprocalRankFusionCombinationStrategy}

https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf

#|
||Field | Description ||
|| k | **string** (int64)

The parameter k for RRFscore. Default is 60 ||
|#

## Response {#yandex.cloud.operation.Operation}

**HTTP Code: 200 - OK**

```json
{
  "id": "string",
  "description": "string",
  "createdAt": "string",
  "createdBy": "string",
  "modifiedAt": "string",
  "done": "boolean",
  "metadata": "object",
  // Includes only one of the fields `error`, `response`
  "error": {
    "code": "integer",
    "message": "string",
    "details": [
      "object"
    ]
  },
  "response": {
    "id": "string",
    "folderId": "string",
    "name": "string",
    "description": "string",
    "createdBy": "string",
    "createdAt": "string",
    "updatedBy": "string",
    "updatedAt": "string",
    "expirationConfig": {
      "expirationPolicy": "string",
      "ttlDays": "string"
    },
    "expiresAt": "string",
    "labels": "object",
    // Includes only one of the fields `textSearchIndex`, `vectorSearchIndex`, `hybridSearchIndex`
    "textSearchIndex": {
      "chunkingStrategy": {
        // Includes only one of the fields `staticStrategy`
        "staticStrategy": {
          "maxChunkSizeTokens": "string",
          "chunkOverlapTokens": "string"
        }
        // end of the list of possible fields
      },
      // Includes only one of the fields `ngramTokenizer`, `standardTokenizer`
      "ngramTokenizer": {
        "minGram": "string",
        "maxGram": "string"
      },
      "standardTokenizer": "object",
      // end of the list of possible fields
      // Includes only one of the fields `standardAnalyzer`, `yandexLemmerAnalyzer`
      "standardAnalyzer": "object",
      "yandexLemmerAnalyzer": "object"
      // end of the list of possible fields
    },
    "vectorSearchIndex": {
      "docEmbedderUri": "string",
      "queryEmbedderUri": "string",
      "chunkingStrategy": {
        // Includes only one of the fields `staticStrategy`
        "staticStrategy": {
          "maxChunkSizeTokens": "string",
          "chunkOverlapTokens": "string"
        }
        // end of the list of possible fields
      }
    },
    "hybridSearchIndex": {
      "textSearchIndex": {
        "chunkingStrategy": {
          // Includes only one of the fields `staticStrategy`
          "staticStrategy": {
            "maxChunkSizeTokens": "string",
            "chunkOverlapTokens": "string"
          }
          // end of the list of possible fields
        },
        // Includes only one of the fields `ngramTokenizer`, `standardTokenizer`
        "ngramTokenizer": {
          "minGram": "string",
          "maxGram": "string"
        },
        "standardTokenizer": "object",
        // end of the list of possible fields
        // Includes only one of the fields `standardAnalyzer`, `yandexLemmerAnalyzer`
        "standardAnalyzer": "object",
        "yandexLemmerAnalyzer": "object"
        // end of the list of possible fields
      },
      "vectorSearchIndex": {
        "docEmbedderUri": "string",
        "queryEmbedderUri": "string",
        "chunkingStrategy": {
          // Includes only one of the fields `staticStrategy`
          "staticStrategy": {
            "maxChunkSizeTokens": "string",
            "chunkOverlapTokens": "string"
          }
          // end of the list of possible fields
        }
      },
      "chunkingStrategy": {
        // Includes only one of the fields `staticStrategy`
        "staticStrategy": {
          "maxChunkSizeTokens": "string",
          "chunkOverlapTokens": "string"
        }
        // end of the list of possible fields
      },
      "normalizationStrategy": "string",
      "combinationStrategy": {
        // Includes only one of the fields `meanCombination`, `rrfCombination`
        "meanCombination": {
          "meanEvaluationTechnique": "string",
          "weights": [
            "string"
          ]
        },
        "rrfCombination": {
          "k": "string"
        }
        // end of the list of possible fields
      }
    }
    // end of the list of possible fields
  }
  // end of the list of possible fields
}
```

An Operation resource. For more information, see [Operation](/docs/api-design-guide/concepts/operation).

#|
||Field | Description ||
|| id | **string**

ID of the operation. ||
|| description | **string**

Description of the operation. 0-256 characters long. ||
|| createdAt | **string** (date-time)

Creation timestamp.

String in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) text format. The range of possible values is from
`0001-01-01T00:00:00Z` to `9999-12-31T23:59:59.999999999Z`, i.e. from 0 to 9 digits for fractions of a second.

To work with values in this field, use the APIs described in the
[Protocol Buffers reference](https://developers.google.com/protocol-buffers/docs/reference/overview).
In some languages, built-in datetime utilities do not support nanosecond precision (9 digits). ||
|| createdBy | **string**

ID of the user or service account who initiated the operation. ||
|| modifiedAt | **string** (date-time)

The time when the Operation resource was last modified.

String in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) text format. The range of possible values is from
`0001-01-01T00:00:00Z` to `9999-12-31T23:59:59.999999999Z`, i.e. from 0 to 9 digits for fractions of a second.

To work with values in this field, use the APIs described in the
[Protocol Buffers reference](https://developers.google.com/protocol-buffers/docs/reference/overview).
In some languages, built-in datetime utilities do not support nanosecond precision (9 digits). ||
|| done | **boolean**

If the value is `false`, it means the operation is still in progress.
If `true`, the operation is completed, and either `error` or `response` is available. ||
|| metadata | **object**

Service-specific metadata associated with the operation.
It typically contains the ID of the target resource that the operation is performed on.
Any method that returns a long-running operation should document the metadata type, if any. ||
|| error | **[Status](#google.rpc.Status)**

The error result of the operation in case of failure or cancellation.

Includes only one of the fields `error`, `response`.

The operation result.
If `done == false` and there was no failure detected, neither `error` nor `response` is set.
If `done == false` and there was a failure detected, `error` is set.
If `done == true`, exactly one of `error` or `response` is set. ||
|| response | **[SearchIndex](#yandex.cloud.ai.assistants.v1.searchindex.SearchIndex)**

The normal response of the operation in case of success.
If the original method returns no data on success, such as Delete,
the response is [google.protobuf.Empty](https://developers.google.com/protocol-buffers/docs/reference/google.protobuf#google.protobuf.Empty).
If the original method is the standard Create/Update,
the response should be the target resource of the operation.
Any method that returns a long-running operation should document the response type, if any.

Includes only one of the fields `error`, `response`.

The operation result.
If `done == false` and there was no failure detected, neither `error` nor `response` is set.
If `done == false` and there was a failure detected, `error` is set.
If `done == true`, exactly one of `error` or `response` is set. ||
|#

## Status {#google.rpc.Status}

The error result of the operation in case of failure or cancellation.

#|
||Field | Description ||
|| code | **integer** (int32)

Error code. An enum value of [google.rpc.Code](https://github.com/googleapis/googleapis/blob/master/google/rpc/code.proto). ||
|| message | **string**

An error message. ||
|| details[] | **object**

A list of messages that carry the error details. ||
|#

## SearchIndex {#yandex.cloud.ai.assistants.v1.searchindex.SearchIndex}

Represents a search index used to store and query data, either using traditional keyword-based text search or vector-based search mechanisms.

#|
||Field | Description ||
|| id | **string**

Unique identifier of the search index. ||
|| folderId | **string**

ID of the folder that the search index belongs to. ||
|| name | **string**

Name of the search index. ||
|| description | **string**

Description of the search index. ||
|| createdBy | **string**

Identifier of the subject who created this search index. ||
|| createdAt | **string** (date-time)

Timestamp representing when the search index was created.

String in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) text format. The range of possible values is from
`0001-01-01T00:00:00Z` to `9999-12-31T23:59:59.999999999Z`, i.e. from 0 to 9 digits for fractions of a second.

To work with values in this field, use the APIs described in the
[Protocol Buffers reference](https://developers.google.com/protocol-buffers/docs/reference/overview).
In some languages, built-in datetime utilities do not support nanosecond precision (9 digits). ||
|| updatedBy | **string**

Identifier of the subject who last updated this search index. ||
|| updatedAt | **string** (date-time)

Timestamp representing the last time this search index was updated.

String in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) text format. The range of possible values is from
`0001-01-01T00:00:00Z` to `9999-12-31T23:59:59.999999999Z`, i.e. from 0 to 9 digits for fractions of a second.

To work with values in this field, use the APIs described in the
[Protocol Buffers reference](https://developers.google.com/protocol-buffers/docs/reference/overview).
In some languages, built-in datetime utilities do not support nanosecond precision (9 digits). ||
|| expirationConfig | **[ExpirationConfig](#yandex.cloud.ai.common.ExpirationConfig2)**

Configuration for the expiration of the search index, defining when and how the search index will expire. ||
|| expiresAt | **string** (date-time)

Timestamp representing when the search index will expire.

String in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) text format. The range of possible values is from
`0001-01-01T00:00:00Z` to `9999-12-31T23:59:59.999999999Z`, i.e. from 0 to 9 digits for fractions of a second.

To work with values in this field, use the APIs described in the
[Protocol Buffers reference](https://developers.google.com/protocol-buffers/docs/reference/overview).
In some languages, built-in datetime utilities do not support nanosecond precision (9 digits). ||
|| labels | **object** (map<**string**, **string**>)

Set of key-value pairs that can be used to organize and categorize the search index. ||
|| textSearchIndex | **[TextSearchIndex](#yandex.cloud.ai.assistants.v1.searchindex.TextSearchIndex2)**

Keyword-based text search index configuration.
This type of index is used for traditional text search, where documents are indexed based on their keywords.

Includes only one of the fields `textSearchIndex`, `vectorSearchIndex`, `hybridSearchIndex`.

Type of the search index. It can be either a traditional keyword-based text search or a vector-based search. ||
|| vectorSearchIndex | **[VectorSearchIndex](#yandex.cloud.ai.assistants.v1.searchindex.VectorSearchIndex2)**

Vector-based search index configuration.
This type is used for vector search, where documents are indexed using vector embeddings.

Includes only one of the fields `textSearchIndex`, `vectorSearchIndex`, `hybridSearchIndex`.

Type of the search index. It can be either a traditional keyword-based text search or a vector-based search. ||
|| hybridSearchIndex | **[HybridSearchIndex](#yandex.cloud.ai.assistants.v1.searchindex.HybridSearchIndex2)**

Hybrid (vector-based + keyword-based) search index configuration
This type is used for hybrid search, where documents are indexed using both keyword-based and vector-based search mechanisms.

Includes only one of the fields `textSearchIndex`, `vectorSearchIndex`, `hybridSearchIndex`.

Type of the search index. It can be either a traditional keyword-based text search or a vector-based search. ||
|#

## ExpirationConfig {#yandex.cloud.ai.common.ExpirationConfig2}

#|
||Field | Description ||
|| expirationPolicy | **enum** (ExpirationPolicy)

- `EXPIRATION_POLICY_UNSPECIFIED`
- `STATIC`
- `SINCE_LAST_ACTIVE` ||
|| ttlDays | **string** (int64) ||
|#

## TextSearchIndex {#yandex.cloud.ai.assistants.v1.searchindex.TextSearchIndex2}

Defines the configuration for a traditional keyword-based text search index.

#|
||Field | Description ||
|| chunkingStrategy | **[ChunkingStrategy](#yandex.cloud.ai.assistants.v1.searchindex.ChunkingStrategy2)**

Chunking strategy used to split text into smaller chunks before indexing.
In the case of text search, tokens are individual text characters. ||
|| ngramTokenizer | **[NgramTokenizer](#yandex.cloud.ai.assistants.v1.searchindex.NgramTokenizer2)**

Tokenizer that generates n-grams.

Includes only one of the fields `ngramTokenizer`, `standardTokenizer`.

Tokenizer type used for text search. The tokenizer determines how the
input text is broken down into tokens before indexing.
If not specified, the default tokenizer configuration is applied. ||
|| standardTokenizer | **object**

Tokenizer that generates words.

Includes only one of the fields `ngramTokenizer`, `standardTokenizer`.

Tokenizer type used for text search. The tokenizer determines how the
input text is broken down into tokens before indexing.
If not specified, the default tokenizer configuration is applied. ||
|| standardAnalyzer | **object**

Standard analyzer that performs common text processing operations to normalize text.

Includes only one of the fields `standardAnalyzer`, `yandexLemmerAnalyzer`.

Analyzer type used for text search. The analyzer determines how the
tokenized text is further processed before indexing.
If not specified, the default analyzer configuration is applied. ||
|| yandexLemmerAnalyzer | **object**

Specialized analyzer that uses Yandex's lemmatization technology,
particularly effective for Russian and other Slavic languages.

Includes only one of the fields `standardAnalyzer`, `yandexLemmerAnalyzer`.

Analyzer type used for text search. The analyzer determines how the
tokenized text is further processed before indexing.
If not specified, the default analyzer configuration is applied. ||
|#

## ChunkingStrategy {#yandex.cloud.ai.assistants.v1.searchindex.ChunkingStrategy2}

Defines a general strategy for chunking text into smaller segments.
Currently, only StaticChunkingStrategy is supported.

#|
||Field | Description ||
|| staticStrategy | **[StaticChunkingStrategy](#yandex.cloud.ai.assistants.v1.searchindex.StaticChunkingStrategy2)**

Includes only one of the fields `staticStrategy`. ||
|#

## StaticChunkingStrategy {#yandex.cloud.ai.assistants.v1.searchindex.StaticChunkingStrategy2}

Defines a chunking strategy where chunks are created with a fixed maximum chunk size and an overlap between consecutive chunks.

#|
||Field | Description ||
|| maxChunkSizeTokens | **string** (int64)

The maximum number of tokens allowed in a single chunk.
Constraints: must be within the range [100, 2048].
Default value: 800 ||
|| chunkOverlapTokens | **string** (int64)

The number of tokens that should overlap between consecutive chunks.
This allows for some context from the previous chunk to be included in the next chunk.
Constraints: must be less than or equal to half of `max_chunk_size_tokens`.
Default value: 400 ||
|#

## NgramTokenizer {#yandex.cloud.ai.assistants.v1.searchindex.NgramTokenizer2}

Configuration for the NgramTokenizer, which splits text into overlapping character sequences (n-grams) of specified lengths.

Example:
Input text: `hello`
min_gram = 2, max_gram = 3

Generated tokens:
* For n = 2 (2-character n-grams): `he`, `el`, `ll`, `lo`
* For n = 3 (3-character n-grams): `hel`, `ell`, `llo`

Final tokens: `[he, el, ll, lo, hel, ell, llo]`

#|
||Field | Description ||
|| minGram | **string** (int64)

Minimum length of characters in a gram. Defaults to 3 ||
|| maxGram | **string** (int64)

Maximum length of characters in a gram. Defaults to 4 ||
|#

## VectorSearchIndex {#yandex.cloud.ai.assistants.v1.searchindex.VectorSearchIndex2}

Defines the configuration for a vector-based search index. This type uses embeddings to represent documents and queries.

#|
||Field | Description ||
|| docEmbedderUri | **string**

The [ID of the model](/docs/foundation-models/concepts/embeddings) to be used for obtaining document text embeddings. ||
|| queryEmbedderUri | **string**

The [ID of the model](/docs/foundation-models/concepts/embeddings) to be used for obtaining query text embeddings. ||
|| chunkingStrategy | **[ChunkingStrategy](#yandex.cloud.ai.assistants.v1.searchindex.ChunkingStrategy2)**

Chunking strategy used to split text into smaller chunks before indexing.
In the case of vector search, tokens are produced by the tokenizer from the embedding model. ||
|#

## HybridSearchIndex {#yandex.cloud.ai.assistants.v1.searchindex.HybridSearchIndex2}

Defines the configuration for a hybrid (vector-based + keyword-based) search index. This type uses both embeddings and keyword-based search to represent documents and queries.

#|
||Field | Description ||
|| textSearchIndex | **[TextSearchIndex](#yandex.cloud.ai.assistants.v1.searchindex.TextSearchIndex2)**

Configuration for a traditional keyword-based text search index. ||
|| vectorSearchIndex | **[VectorSearchIndex](#yandex.cloud.ai.assistants.v1.searchindex.VectorSearchIndex2)**

Configuration for a vector-based search index. ||
|| chunkingStrategy | **[ChunkingStrategy](#yandex.cloud.ai.assistants.v1.searchindex.ChunkingStrategy2)**

Common chunking strategy that applies to both text and vector search indexes.
If provided, it overrides the individual chunking strategies in both `text_search_index` and `vector_search_index`.
In this case, both text and vector search will use token-based chunking, where tokens are produced by the tokenizer of the embedding model. ||
|| normalizationStrategy | **enum** (NormalizationStrategy)

Normalization strategy for relevance scores from different indices. Default is MIN_MAX_STRATEGY

- `NORMALIZATION_STRATEGY_UNSPECIFIED`
- `MIN_MAX`: https://en.wikipedia.org/wiki/Feature_scaling#Rescaling_(min-max_normalization)
- `L2`: https://en.wikipedia.org/wiki/Cosine_similarity#L2-normalized_Euclidean_distance ||
|| combinationStrategy | **[CombinationStrategy](#yandex.cloud.ai.assistants.v1.searchindex.CombinationStrategy2)**

Combination strategy for merging rankings from different indices. Default is arithmetic mean ||
|#

## CombinationStrategy {#yandex.cloud.ai.assistants.v1.searchindex.CombinationStrategy2}

Combination strategy for merging rankings from different indices

#|
||Field | Description ||
|| meanCombination | **[MeanCombinationStrategy](#yandex.cloud.ai.assistants.v1.searchindex.MeanCombinationStrategy2)**

Includes only one of the fields `meanCombination`, `rrfCombination`. ||
|| rrfCombination | **[ReciprocalRankFusionCombinationStrategy](#yandex.cloud.ai.assistants.v1.searchindex.ReciprocalRankFusionCombinationStrategy2)**

Includes only one of the fields `meanCombination`, `rrfCombination`. ||
|#

## MeanCombinationStrategy {#yandex.cloud.ai.assistants.v1.searchindex.MeanCombinationStrategy2}

#|
||Field | Description ||
|| meanEvaluationTechnique | **enum** (MeanEvaluationTechnique)

Technique for averaging relevance scores from different indices. Default is ARITHMETIC

- `MEAN_EVALUATION_TECHNIQUE_UNSPECIFIED`
- `ARITHMETIC`: https://en.wikipedia.org/wiki/Arithmetic_mean
- `GEOMETRIC`: https://en.wikipedia.org/wiki/Geometric_mean
- `HARMONIC`: https://en.wikipedia.org/wiki/Harmonic_mean ||
|| weights[] | **string**

Weights used for evaluating the weighted mean of relevance scores. The sum of the values must equal 1.0
If not provided, all scores are given equal weight ||
|#

## ReciprocalRankFusionCombinationStrategy {#yandex.cloud.ai.assistants.v1.searchindex.ReciprocalRankFusionCombinationStrategy2}

https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf

#|
||Field | Description ||
|| k | **string** (int64)

The parameter k for RRFscore. Default is 60 ||
|#