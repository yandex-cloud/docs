# Классификация изображений на видеокадрах

{{ ml-platform-full-name }} позволяет строить модели машинного обучения, используя интерфейс Jupyter Notebook в {{ yandex-cloud }}.

В этом сценарии решена задача бинарной классификации изображений. Такая задача возникает при определении типа транспортного средства по изображению с камеры видеонаблюдения. Предполагается, что система управления видеомониторингом захватывает изображения с камеры при обнаружении движения. Далее изображения передаются в S3-бакет.

Чтобы познакомиться с решением задачи:
1. [Установите зависимости](#satisfy-dependencies).
1. [Загрузите и разметьте данные](#load-dataset).
1. [Подготовьте ML-модель и вычислите признаки](#get-cnn-model).
1. [Обучите классификатор на полученных признаках](#classifier-fit).
1. [Получите результаты предсказания признака на тестовом изображении](#model-test).
1. [Посмотрите варианты практического применения модели](#model-apply).

## Перед началом работы {#before-you-begin}

1. [Создайте](../../storage/quickstart.md#the-first-bucket) S3-бакет. Загрузите в него изображения для обучения модели из каталога по [ссылке](https://www.kaggle.com/kdnishanth/bus-or-car-using-cnn-100-accuracy/data).
1. [Создайте](../../iam/operations/sa/create.md) сервисный аккаунт.
1. [Назначьте роль](../../iam/operations/sa/assign-role-for-sa.md) `storage.viewer` сервисному аккаунту для доступа на чтение объектного хранилища, в котором создан бакет.
1. [Создайте](../../iam/operations/sa/create-access-key.md) статический ключ доступа.
1. Сохраните статический ключ доступа в файл:

   ```bash
   [default]
   aws_access_key_id=<идентификатор статического ключа>
   aws_secret_access_key=<секретный ключ>
   ```
  
1. [Создайте проект](../operations/projects/create.md) в **{{ ml-platform-name }}** и откройте его.
1. [Склонируйте](../operations/projects/work-with-git.md#clone) Git-репозиторий, в котором находятся ноутбуки с примерами обучения и тестирования модели машинного обучения:

   ```
   https://github.com/MaxKhlupnov/ImageClassificationML
   ```

   Дождитесь окончания клонирования, это может занять некоторое время. После завершения операции в блоке ![folder](../../_assets/datasphere/jupyterlab/folder.svg) **File Browser** появится каталог склонированного репозитория.

1. Откройте каталог **ImageClassificationML** и затем файл `yc.config`. Замените содержимое файла строками из локального файла со статическим ключом доступа.

1. Откройте каталог **ML** и затем ноутбук **model-building.ipynb**.

   {% note info %}

   Если вы обновите вкладку браузера, на которой запущен ноутбук, или закроете ее, то состояние ноутбука сохранится. Переменные и результаты уже сделанных вычислений при этих действиях не сбрасываются.

   {% endnote %}

## Установите зависимости {#satisfy-dependencies}

1. Выделите первую ячейку, кликнув на нее:

   ```
   #!L
   %matplotlib inline
   import matplotlib
   import matplotlib.pyplot as plt
   import os
   import io
   from os import path
   ...
   ```

1. Запустите выделенную ячейку, выбрав в меню **Run → Run Selected Cells** (также можно использовать сочетание клавиш *Shift+Enter*)      
1. Дождитесь завершения операции.

В решении используется [интерфейс Keras](https://keras.io/about/) библиотеки TensorFlow с [CNTK-бэкендом](https://docs.microsoft.com/en-us/cognitive-toolkit/). Пакет `boto3` используется для подключения к S3-бакету как источнику изображений. Также в ячейке задаются переменные окружения, необходимые для работы с CNTK-бэкендом и подключения к S3-бакету.

Указанные в ячейке пакеты уже установлены в {{ ml-platform-name }} и импортируются с помощью команды `import`. Полный список предустановленных в {{ ml-platform-name }} пакетов см. в разделе [{#T}](../concepts/preinstalled-packages.md).

{% note info %}

Эта и последующие ячейки используют L-конфигурацию вычислительных ресурсов для ускорения загрузки и обучения модели. Подробнее см. в разделе [{#T}](../concepts/configurations.md).

{% endnote %}

## Загрузите и разметьте данные {#load-dataset}

Перейдите к разделу **Функции для подключения к S3**. В нем выполняются следующие операции:

1. Настраивается подключение к S3-бакету.
1. Загружается список объектов (изображений) автомобилей и автобусов. Они будут использоваться при обучении модели.
1. Определяется функция для извлечения изображения по ключу (названию).

В следующем разделе **Маркировка** выполняется разметка данных:
- Изображения маркируются в соответствии со значением ключа (именем папки).
- Изображения автобусов помечаются меткой `0`, автомобилей — `1`.

Чтобы загрузить и разметить данные:

1. Выделите все ячейки с кодом в разделах **Функции для подключения к S3** и **Маркировка**, удерживая *Shift* и кликая слева от нужных ячеек:

   ```
   #!L

   session = boto3.session.Session()
   ...
   ```

1. Запустите выделенные ячейки.
1. Дождитесь завершения операции. По завершении операции выводится одно из изображений для проверки корректности загрузки и разметки данных.

## Подготовьте ML-модель и вычислите признаки {#get-cnn-model}

Перейдите к разделу **Вычисление признаков**. В нем выполняются следующие операции:

1. Из пакета Keras загружается модель ResNet50 с весами, предварительно подобранными на наборе данных ImageNet. Этот набор содержит 1,2 миллиона изображений, которые разнесены по 1000 категорий.
1. Определяется функция для разделения списка изображений на пачки (chunks) по 32 в каждой.
1. Определяется функция, которая читает список изображений и преобразует в формат, пригодный для обработки моделью, а также вычисляет признаки и возвращает их в массиве NumPy.
1. С помощью данных функций вычисляются бинарные признаки (`1` — автомобиль, `0` — иное) и сохраняются в файл. Этот шаг может занять 10-15 минут. [Подробнее про модель ResNet50](https://www.kaggle.com/keras/resnet50).

Чтобы подготовить модель и вычислить признаки:

1. Выделите все ячейки с кодом в разделе **Вычисление признаков**:

   ```
   #!l
   model = ResNet50(weights='imagenet',  input_shape=(224, 224, 3))
   ...
   ```

1. Запустите выделенные ячейки.
1. Дождитесь завершения операции.


## Обучите классификатор на полученных признаках {#classifier-fit}

Перейдите к разделам **Training and Cross Validation** и **Save the model**. В них выполняются следующие операции:

1. Определяется объект для кросс-валидации результатов обучения методом **K-fold**.
1. Готовится таблица для сохранения метрик качества классификации.
1. Определяется функция вычисления выбранных метрик.
1. Запускается обучение классификатора LightGBM. В данном примере используется кросс-валидация с пятью фолдами:
   1. Обучающая выборка разбивается на пять непересекающихся одинаковых по объему частей.
   1. Выполняется пять итераций. На каждой итерации выполняются следующие шаги:
      1. Модель обучается на четырех частях выборки.
      1. Модель тестируется на части выборки, которая не участвовала в обучении.
      1. Выводятся выбранные метрики качества.
1. Классификатор обучается на полном наборе данных и выводится итоговая матрица ошибок.

Для обучения классификатора запустите последовательно все ячейки в разделах **Training and Cross Validation** и **Save the model**.

Результатом обучения является модель, сохраненная в отдельном файле.

## Получите результаты предсказания признаков на тестовых данных {#model-test}

Чтобы использовать полученную модель:

1. Откройте каталог **ImageClassificationML/ML** и затем ноутбук **model-testing.ipynb**.

   {% note info %}

   Для использования модели нужно существенно меньше ресурсов, чем для ее обучения, поэтому здесь оставлена минимальная S-конфигурация (по умолчанию).

   {% endnote %}

1. Запустите первые две ячейки. В этих ячейках:
   1. Импортируются необходимые для теста пакеты.
   1. Настраивается подключение к S3-бакету с изображениями из сервиса видеомониторинга.
1. Задайте тестовое изображение с автомобилем:

   ```
   test_image = 'car/test/3_60184_41.jpg'
   ```

1. В следующей ячейке загрузите модель ResNet50 и подготовленный классификатор LightGBM, и вычислите вероятность предсказанного значения бинарного признака (`1` соответствует автомобилю).
  
   В первый раз ячейка с вычислением предсказания обрабатывается дольше, так как модели загружаются в память. При последующих запусках ячейка будет выполняться быстрее:

   ```
   %%time
   clf = lgb.Booster(model_file='ImageClassificationML/lightgbm_classifier.model')
   model = ResNet50(weights='imagenet',  input_shape=(224, 224, 3))
   ...
   ```

1. Убедитесь, что значение вероятности близко к единице (должно получиться `≈0.98`).

1. Поменяйте код в ячейке перед загрузкой модели:

   ```
   test_image = 'car/test/3_59296_27.jpg'
   ```

   Это тестовое изображение, на котором нет автомобиля. 

1. Выполните ячейку.

1. Повторите вычисление вероятности и убедитесь, что значение существенно меньше `0.5`.

Таким образом, классификатор успешно предсказывает признак для этих двух изображений.

{% note info %}

Вы можете [поделиться](../operations/projects/publication.md) готовым ноутбуком с расчетами или [экспортировать проект](../operations/projects/export.md) целиком.

{% endnote %}

## Практическое применение модели {#model-apply}

Есть несколько вариантов практического применения построенной модели:
- На основе кода предлагаемого решения можно запустить веб-сервис с помощью [{{ sf-full-name }}](../../functions/) и анализировать изображения при наступлении соответствующего события в видеомониторинге.
- Для параллельной обработки изображений, приходящих с большого количества видеокамер в S3-бакет, можно загрузить код в кластер Apache Spark™ в [{{ dataproc-full-name }}](../../data-proc/) с помощью пакета PySpark.

  Пример кода Python для интеграции модели с PySpark:

  ```python
  from sparkdl import readImages, KerasImageFileTransformer

  # load cctv image body from S3 and return image tensor
  
  def load_image_body_and_process(uri):
      import PIL.image
      from keras.applications.imagenet_utils import preprocess.input
  ...

  # load cctv images in batch (from S3 or copy to local hdfs)
  
  image_uri_dataset = readImages("/cctv-in/*.jpg")
  
  # create a Keras estimator that takes our saved model file and train it using Spark
  
  estimator = KerasImageFileEstimator(inputCol="imageUri",
                                      outputCol="predict_car",
                                      labelCol="categoryVec",
                                      imageLoader=load_image_body_and_process,
                                      kerasOptimizer="adam",
                                      kerasLoss="categorical_crossentropy",
                                      kerasFitParams={"epochs": 5, "batchSize": 64},
                                      modelFile="lightgbm_classifier.model")
  predictions = estimator.fit(image_uri_dataset)
  ```
