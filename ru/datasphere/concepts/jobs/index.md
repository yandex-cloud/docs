# {{ ml-platform-name }} Jobs

В {{ ml-platform-name }} вы можете удаленно запускать задания (jobs) — вычисления на ВМ {{ ml-platform-name }} за пределами {{ jlab }}Lab. Это могут быть скрипты и проекты на Python, bash-скрипты и исполняемые бинарные файлы, скомпилированные под платформу Linux x86_64.

Задания создаются и выполняются в [проектах](../project.md), но не зависят от ноутбуков и запущенных ВМ проекта.

Для работы с {{ ml-platform-name }} Jobs [аутентифицируйтесь](../../operations/projects/authentication.md) от имени пользовательского аккаунта.

Перед [запуском задания](../../operations/projects/work-with-jobs.md) настройте виртуальное окружение Python, установите [{{ ds-cli }}](cli.md) с помощью команды `pip install datasphere` и подготовьте файл конфигурации, в котором будут описаны все параметры запуска задания. Также вы можете [установить](../../../cli/quickstart.md) и сконфигурировать [интерфейс командной строки {{ yandex-cloud }}](../../../cli/), чтобы с его помощью аутентифицироваться в {{ yandex-cloud }}.

{% include [vscode-extension-info](../../../_includes/datasphere/vscode-extension-info.md) %}

Задания можно найти в проекте на вкладке **{{ ml-platform-name }} Jobs**. Прогресс выполнения и результаты будут доступны в разделе **История запусков**.

{% note tip %}

При выполнении длительных заданий рекомендуем сохранять промежуточный результат в объектном хранилище [S3](../../../glossary/s3.md).

{% endnote %}

## Хранение данных заданий

{{ ml-platform-name }} Jobs хранит кеш входных данных и окружения, логи и результаты выполнения заданий. Вы можете переиспользовать данные и делиться ими между заданиями в пределах одного проекта. Так, повторные запуски одного и того же задания не будут каждый раз загружать входные данные в {{ ml-platform-name }}, а переиспользует данные, загруженные при первом запуске.

Размер хранимых данных ограничен. Подробнее об ограничениях {{ ml-platform-name }} см. в разделе [{#T}](../limits.md).

По умолчанию время жизни данных задания составляет 14 дней. Вы можете изменить это значение с помощью {{ ds-cli }}:

```bash
datasphere project job set-data-ttl --id <идентификатор_задания> --days <время_жизни_в_днях>
```

## Файл конфигурации заданий {#config}

При создании задания в файле конфигурации `config.yaml` указываются его параметры — [конфигурация вычислительных ресурсов](../configurations.md), на которой задание будет выполняться, и необходимые файлы с входными данными. В соответствии с настройками в файле конфигурации {{ ml-platform-name }} анализирует задание, определяет зависимости, [развертывает окружение](environment.md) на ВМ и выполняет код задания. Результаты выполнения задания сохраняются в проекте {{ ml-platform-name }} в файлах, определенных в конфигурации задания.

```yaml
# Имя задания
name: simple-python-script
# Описание задания
desc: Program description

# Параметры точки входа для запуска вычислений
cmd: >  # многострочная строка YAML
  python3 src/main.py
    --params ${PARAMS}
    --features ${<идентификатор_коннектора>}/features.tsv
    --validate ${CIFAR}/val.json
    --normalizer ${DS_PROJECT_HOME}/misc/norm.bin
    --model ${MODEL}
    --epochs 5

# Файлы с входными данными
inputs:
  - misc/logging.yaml  # Путь к файлу относительно директории запуска задания на локальном компьютере
  - /usr/share/params.json: # Абсолютный путь к файлу на локальном компьютере сохранен в переменную PARAMS
      var: PARAMS

# Файлы с результатами
outputs:
  - data/model.bin: MODEL  # Относительный путь к файлу сохранен в переменную MODEL
  - other/metrics.png  # Относительный путь к файлу

# Ресурсы, необходимые для запуска задания, должны быть доступны в проекте
s3-mounts: # Коннекторы S3
  - <идентификатор_коннектора>   # Идентификатор коннектора S3
                           # Имя коннектора не задано, поэтому обращение к коннектору возможно по его идентификатору
datasets:
  - <идентификатор_датасета>:  # Идентификатор датасета, доступного в проекте
      var: CIFAR   # CIFAR — переменная для обращения к датасету

# Параметры окружения
env:
  vars:  # Переменные окружения
    - DEVICE_COUNT: 8    # значение переменной окружения можно указать явно
    - PYTHONBUFFERED     # если параметр не задан, его значение будет определено из текущего окружения
  docker: <идентификатор_Docker-образа>  # Docker-образ, доступный в проекте {{ ml-platform-name }}
  # Также можно указать Docker-образ в реестре образов
  # docker:
  #   image: <путь_к_образу_в_реестре>:<тег>  # Например <{{ registry }}/crtabcdef12345678900/myenv:0.1>
                                              # Для Docker Hub достаточно указать `<имя>:<тег>`, например `ubuntu:focal`
  #   username: <логин>
  #   password: 
  #     secret-id: PASSWORD  # имя секрета {{ ml-platform-name }}

  # Способ сборки зависимостей окружения
  python: auto # Полная автоматизация сборки окружения

  # python: # Параметры окружения задаются вручную. Если параметры не заданы, их значения будут определены из текущего окружения автоматически
  # type: manual
  # version: 3.10.13 # Версия Python
  # pip:
  #   index-url: https://pypi.org/simple # Адрес основного репозитория для установки пакетов
  #   extra-index-urls: # Адреса дополнительных репозиториев
  #     - https://pypi.ngc.nvidia.com
  #   trusted-hosts: # Список доверенных хостов
  #     - nvidia.com
  #   no-deps: true  # По умолчанию false
  # requirements-file: requirements.txt  # Файл с параметрами окружения
  # root-path:   # Явное указание дополнительных точек входа
  #   - other.py
  # local-paths: # Список локальных Python-файлов, которые нужно перенести. Нельзя использовать с опцией root-paths
  #  - foo.py
  #  - lib/ 

# Флаги запуска задания
flags:
  - attach-project-disk # Смонтировать хранилище проекта

# Конфигурации вычислительных ресурсов для запуска задания
cloud-instance-types:
  - g2.1 # Приоритетная конфигурация
  - g1.1 # Конфигурация с вторым приоритетом

# Конфигурация расширенной рабочей директории
working-storage:
  type: SSD    # тип используемого диска. Опционально, по умолчанию SSD. Доступные значения: SSD
  size: 150Gb  # размер рабочей директории в интервале 100 ГБ — 10 ТБ

# Конфигурация плавного завершения работы
graceful-shutdown:
  signal: SIGTERM  # Сигнал, который будет отправлен процессу задания при нажатии Ctrl + C (cancel), по умолчанию SIGTERM
                   # Доступные значения: SIGTERM, SIGINT, SIGHUP, SIGUSR1, SIGUSR2
  timeout: 15s     # Таймаут, через который процесс задания получит SIGKILL, если не успевает завершиться

# Список датасетов, которые будут созданы при успешном завершении задания
output-datasets:
  - name: job-test-dataset-1  # Название датасета
    var: OUT_DS               # Переменная, содержащая путь до датасета. Содержимое указанной директории будет оформлено в виде датасета
    description: "Описание"
    size: 100Gb               # Максимальный объем данных в датасете
    labels:                   # Произвольный список меток, которые будут присвоены датасету
      a: b
      c: d
```

Файл конфигурации задания `config.yaml` состоит из нескольких секций.

1. Секции `name` и `description` определяют имя и описание задания. Имя задания должно быть уникальным в пределах проекта. Описание является опциональным и поможет найти нужное задание в проекте.

1. Секция `cmd` определяет точку входа в задание. Укажите, как запускать ваш код и задайте все параметры запуска, которые нужно передать исполняемому файлу или скрипту. Вы можете использовать переменные и идентификаторы, которые будут определены в секциях ниже, для указания путей к нужным файлам.

1. Секция `input` определяет файлы с входными данными и другой информацией, которую требуется передать для исполнения задания с вашего локального компьютера. Вы можете определить путь к файлам относительно директории задания или сохранить относительный или абсолютный путь к файлу в переменную, чтобы использовать ее в других секциях файла конфигурации.

1. Секция `output` определяет файлы, в которые будут сохранены результаты вычислений. После выполнения задания эти файлы появятся на вашем компьютере. Правила указания путей совпадают с секцией `input`.

1. Ресурсы {{ ml-platform-name }}, задействованные в заданиях, определяются в секциях `s3-mounts` ([коннекторы S3](../s3-connector.md)) и `datasets` ([датасеты](../dataset.md)). Чтобы использовать коннектор s3 или датасет в задании, укажите идентификатор доступного в проекте ресурса и (опционально) определите переменную для него. Если переменная не задана, обращение к ресурсу в секции `cmd` возможно по его идентификатору.

   Также вы можете использовать в задании хранилище проекта. Для этого в секции `flags` укажите флаг `attach-project-disk`. Хранилище проекта будет смонтировано в качестве внешнего диска для чтения к ВМ, на которой выполняется задание. Путь к хранилищу будет доступен в переменной окружения `DS_PROJECT_HOME`.

1. В секции `env` определяются параметры окружения для выполнения задания: способ сборки окружения на ВМ, переменные окружения и (опционально) Docker-образ, собранный в {{ ml-platform-name }} или хранящийся в другом реестре образов. При необходимости вы можете указать данные для авторизации в реестре.

   Есть два способа задать окружение для проектов на Python:

   * Позволить {{ ml-platform-name }} автоматически определить все необходимые зависимости, проанализировать текущее окружение на вашем локальном компьютере и самостоятельно собрать и перенести его. Для этого в секции `env` укажите `python: auto`.
   * Вы можете самостоятельно указать версию интерпретатора Python, используемые библиотеки и другие параметры прямо в файле конфигурации или в отдельном файле `requirements.txt`. При явном определении хотя бы одного параметра недостающие будут взяты из текущего окружения автоматически.

   {% note warning %}

   Если вы используете автоматический режим задания окружения или указываете только часть зависимостей, запускайте задание из виртуального окружения Python, в котором установлены все актуальные пакеты и локальные модули, чтобы библиотека `datasphere` смогла автоматически определить параметры окружения для выполнения задания.

   {% endnote %}

   В разделе `vars` секции `env` задаются переменные окружения. [Секреты](../secrets.md) проекта также будут добавлены в переменные окружения при запуске задания.

   {% include [jobs-info](../../../_includes/datasphere/jobs-environment.md) %}

   Подробное описание параметров окружения Python см. на странице [Среда исполнения задания](environment.md).

1. Секция `cloud-instance-types` определяет допустимые типы [конфигурации вычислительных ресурсов](../configurations.md), на которых может быть запущено задание. Конфигурации указываются в порядке приоритета, то есть при наличии доступных ресурсов задание будет запущено на первой конфигурации. Если доступных ВМ с первой конфигурацией нет, то задание попробует запуститься на второй, затем на третьей и так далее.

   Если у вас есть только одна конфигурация, допустимо использовать старое поле `cloud-instance-type` (например, `cloud-instance-type: g1.1`), однако предпочтительнее использовать новое.

1. Секция `working-storage` определяет параметры расширенной рабочей директории. По умолчанию рабочая директория создается на системном диске, ее размер не гарантирован и обычно составляет около 20 ГБ. Если для выполнения задания нужно больше места, вы можете явно указать это. Расширенная рабочая директория может быть от 100 ГБ до 10 ТБ.

   Расширенная рабочая директория, указанная в секции `working-storage`, оплачивается согласно [правилам тарификации хранения данных](../../pricing.md#prices-jobs).

1. Секция `graceful-shutdown` определяет параметры плавного завершения работы. Если секция не указана, то при нажатии пользователем **Ctrl** + **C** заданию посылается сигнал `SIGKILL`. В секции можно переопределить сам сигнал, а также время ожидания плавного завершения.

1. Секция `output-dataset` описывает [датасеты](../dataset.md), которые будут созданы при успешном завершении задания. Каждый датасет имеет название, описание, размер и список меток.

   После выполнения задания в [логе](cli.md#logs) `cli` появится сообщение о создании датасета. Например:

   ```text
   2024-09-13 16:22:28,894 - [INFO] - Created datasets:
   2024-09-13 16:22:28,894 - [INFO] -   * <dataset-id> (dataset name) size: <size> Gb
   ```

#### См. также {#see-also}

* [{#T}](../../operations/projects/work-with-jobs.md)
* [GitHub-репозиторий](https://github.com/yandex-cloud-examples/yc-datasphere-jobs-examples) с примерами для запуска заданий.
