# {{ ml-platform-name }} Jobs

В {{ ml-platform-name }} вы можете удаленно запускать задания (jobs) — вычисления на ВМ {{ ml-platform-name }} за пределами {{ jlab }}Lab. Это могут быть скрипты и проекты на Python, bash-скрипты и исполняемые бинарные файлы, скомпилированные под платформу Linux x86_64.

Задания создаются и выполняются в [проектах](../project.md), но не зависят от ноутбуков и запущенных ВМ проекта. 

Для [запуска задания](../../operations/projects/work-with-jobs.md) необходимо настроить виртуальное окружение Python, установить [{{ ds-cli }}](cli.md) с помощью команды `pip install datasphere` и подготовить файл конфигурации, в котором будут описаны все параметры запуска задания. Также можно [установить](../../../cli/quickstart.md) и сконфигурировать [интерфейс командной строки {{ yandex-cloud }}](../../../cli/), чтобы с его помощью аутентифицироваться в {{ yandex-cloud }}.

{% include [vscode-extension-info](../../../_includes/datasphere/vscode-extension-info.md) %}

Задания можно найти в проекте на вкладке **{{ ml-platform-name }} Jobs**. Прогресс выполнения и результаты будут доступны в разделе **История запусков**.

{% note tip %}

При выполнении длительных заданий рекомендуем сохранять промежуточный результат в объектном хранилище [S3](../../../glossary/s3.md).

{% endnote %}

## Хранение данных заданий

{{ ml-platform-name }} Jobs хранит кеш входных данных и окружения, логи и результаты выполнения заданий. Вы можете переиспользовать данные и делиться ими между заданиями в пределах одного проекта. Так, повторные запуски одного и того же задания не будут каждый раз загружать входные данные в {{ ml-platform-name }}, а переиспользует данные, загруженные при первом запуске. 

Размер хранимых данных ограничен. Подробнее об ограничениях {{ ml-platform-name }} см. в разделе [{#T}](../limits.md).

По умолчанию время жизни данных задания составляет 14 дней. Вы можете изменить это значение с помощью {{ ds-cli }}:

```bash
datasphere project job set-data-ttl --id <идентификатор_задания> --days <время_жизни_в_днях>
```

## Файл конфигурации заданий {#config}

При создании задания в файле конфигурации `config.yaml` указываются его параметры — [конфигурация вычислительных ресурсов](../configurations.md), на которой задание будет выполняться, и необходимые файлы с входными данными. В соответствии с настройками в файле конфигурации {{ ml-platform-name }} анализирует задание, определяет зависимости, [развертывает окружение](environment.md) на ВМ и выполняет код задания. Результаты выполнения задания сохраняются в проекте {{ ml-platform-name }} в файлах, определенных в конфигурации задания.

```yaml
# Имя задания
name: simple-python-script 
# Описание задания
desc: Program description 

# Параметры точки входа для запуска вычислений
cmd: >  # многострочная строка YAML
  python src/main.py 
    --params ${PARAMS} 
    --features ${<идентификатор_коннектора>}/features.tsv 
    --validate ${CIFAR}/val.json
    --normalizer ${DS_PROJECT_HOME}/misc/norm.bin
    --model ${MODEL}
    --epochs 5

# Файлы с входными данными
inputs:
  - misc/logging.yaml  # Путь к файлу относительно директории запуска задания на локальном компьютере
  - /usr/share/params.json: # Абсолютный путь к файлу на локальном компьютере сохранен в переменную PARAMS
      var: PARAMS

# Файлы с результатами
outputs:
  - data/model.bin: MODEL  # Относительный путь к файлу сохранен в переменную MODEL
  - other/metrics.png  # Относительный путь к файлу

# Ресурсы, необходимые для запуска задания, должны быть доступны в проекте 
s3-mounts: # Коннекторы S3
  - <идентификатор_коннектора>   # Идентификатор коннектора S3
                           # Имя коннектора не задано, поэтому обращение к коннектору возможно по его идентификатору
datasets:
  - <идентификатор_датасета>:  # Идентификатор датасета, доступного в проекте
      var: CIFAR   # CIFAR — переменная для обращения к датасету

# Параметры окружения       
env:
  vars:  # Переменные окружения
    - DEVICE_COUNT: 8    # значение переменной окружения можно указать явно
    - PYTHONBUFFERED     # если параметр не задан, его значение будет определено из текущего окружения
  docker: <идентификатор_Docker-образа>  # Docker-образ, доступный в проекте {{ ml-platform-name }}
  # Также можно указать Docker-образ в реестре образов
  # docker:
  #   image: <путь_к_образу_в_реестре>:<тег>  # Например <{{ registry }}/crtabcdef12345678900/myenv:0.1>
                                              # Для Docker Hub достаточно указать `<имя>:<тег>`, например `ubuntu:focal` 
  #   username: <логин>
  #   password: 
  #     secret-id: PASSWORD  # имя секрета {{ ml-platform-name }}

  # Способ сборки зависимостей окружения
  python: auto # Полная автоматизация сборки окружения

  # python: # Параметры окружения задаются вручную. Если параметры не заданы, их значения будут определены из текущего окружения автоматически
  #   type: manual
  #   version: 3.10.5  # Версия Python
  #   requirements-file: requirements.txt  # Файл с параметрами окружения

# Флаги запуска задания
flags:
  - attach-project-disk # Смонтировать хранилище проекта

# Конфигурации вычислительных ресурсов для запуска задания
cloud-instance-types: 
  - g2.1 # Приоритетная конфигурация
  - g1.1 # Конфигурация с вторым приоритетом

# Конфигурация расширенной рабочей директории
working-storage:
  type: SSD    # тип используемого диска. Опционально, по умолчанию SSD. Доступные значения: SSD
  size: 150Gb  # размер рабочей директории в интервале 100 ГБ — 10 ТБ
```

Файл конфигурации задания `config.yaml` состоит из нескольких секций.

1. Секции `name` и `description` определяют имя и описание задания. Имя задания должно быть уникальным в пределах проекта. Описание является опциональным и поможет найти нужное задание в проекте.

1. Секция `cmd` определяет точку входа в задание. Укажите, как запускать ваш код и задайте все параметры запуска, которые нужно передать исполняемому файлу или скрипту. Вы можете использовать переменные и идентификаторы, которые будут определены в секциях ниже, для указания путей к нужным файлам.

1. Секция `input` определяет файлы с входными данными и другой информацией, которую требуется передать для исполнения задания с вашего локального компьютера. Вы можете определить путь к файлам относительно директории задания или сохранить относительный или абсолютный путь к файлу в переменную, чтобы использовать ее в других секциях файла конфигурации.

1. Секция `output` определяет файлы, в которые будут сохранены результаты вычислений. После выполнения задания эти файлы появятся на вашем компьютере. Правила указания путей совпадают с секцией `input`.

1. Ресурсы {{ ml-platform-name }}, задействованные в заданиях, определяются в секциях `s3-mounts` ([коннекторы S3](../s3-connector.md)) и `datasets` ([датасеты](../dataset.md)). Чтобы использовать коннектор s3 или датасет в задании, укажите идентификатор доступного в проекте ресурса и (опционально) определите переменную для него. Если переменная не задана, обращение к ресурсу в секции `cmd` возможно по его идентификатору.

   Также вы можете использовать в задании хранилище проекта. Для этого в секции `flags` укажите флаг `attach-project-disk`. Хранилище проекта будет смонтировано в качестве внешнего диска для чтения к ВМ, на которой выполняется задание. Путь к хранилищу будет доступен в переменной окружения `DS_PROJECT_HOME`.

1. В секции `env` определяются параметры окружения для выполнения задания: способ сборки окружения на ВМ, переменные окружения и (опционально) Docker-образ, собранный в {{ ml-platform-name }} или хранящийся в другом реестре образов. При необходимости вы можете указать данные для авторизации в реестре.

   Есть два способа задать окружение для проектов на Python:

   * Позволить {{ ml-platform-name }} автоматически определить все необходимые зависимости, проанализировать текущее окружение на вашем локальном компьютере и самостоятельно собрать и перенести его. Для этого в секции `env` укажите `python: auto`.
   * Вы можете самостоятельно указать версию интерпретатора Python и используемые библиотеки прямо в файле конфигурации или в отдельном файле `requirements.txt`. При явном определении хотя бы одного параметра недостающие будут взяты из текущего окружения автоматически.

   {% note warning %}

   Если вы используете автоматический режим задания окружения или указываете только часть зависимостей, запускайте задание из виртуального окружения Python, в котором установлены все актуальные пакеты и локальные модули, чтобы библиотека `datasphere` смогла автоматически определить параметры окружения для выполнения задания.

   {% endnote %}

   В разделе `vars` секции `env` задаются переменные окружения. Секреты проекта также будут добавлены в переменные окружения при запуске задания.

   {% include [jobs-info](../../../_includes/datasphere/jobs-environment.md) %}

1. Секция `cloud-instance-types` определяет допустимые типы [конфигурации вычислительных ресурсов](../configurations.md), на которых может быть запущено задание. Конфигурации указываются в порядке приоритета, то есть при наличии доступных ресурсов задание будет запущено на первой конфигурации. Если доступных ВМ с первой конфигурацией нет, то задание попробует запуститься на второй, затем на третьей и так далее.

   Для одной конфигурации также допустимо использовать старое поле `cloud-instance-type` (например, `cloud-instance-type: g1.1`), однако предпочтительнее использовать новое.

1. Секция `working-storage` определяет параметры расширенной рабочей директории. По умолчанию рабочая директория создается на системном диске, ее размер не гарантирован и обычно составляет около 20 ГБ. Если для выполнения задания нужно больше места, вы можете явно указать это. Расширенная рабочая директория может быть от 100 ГБ до 10 ТБ. 

   Расширенная рабочая директория, указанная в секции `working-storage`, оплачивается согласно [правилам тарификации хранения данных](../../pricing.md#prices-jobs).

#### См. также {#see-also}

* [{#T}](../../operations/projects/work-with-jobs.md)
* [GitHub-репозиторий](https://github.com/yandex-cloud-examples/yc-datasphere-jobs-examples) с примерами для запуска заданий.
