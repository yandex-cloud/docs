# Специальные фоновые операции

{% note info %}

Специальные фоновые операции доступны только в [режиме раннего доступа](early-access.md).

{% endnote %}

Специальные фоновые операции позволяют:

* выполнять aсинхронный запуск последовательности операций;
* запускать параллельные вычисления.

В отличие от [фонового запуска одной операции](../concepts/async.md), для специальных фоновых операций нужно указать желаемое количество запусков, периодичность сохранения промежуточных результатов и правило выбора конечного результата.

Если в другой части ноутбука используется та же переменная, что и в асинхронной операции, в ноутбуке появится уведомление, и вам нужно будет явно указать значение переменной после выполнения асинхронной операции.

Особенности выполнения специальных фоновых операций:

* Запуск операций в фоновом режиме не гарантирует немедленный запуск исполнения.
* Специальные фоновые операции в общем случае могут выполняться дольше, чем обычные операции.
* Специальные фоновые операции могут выполняться на [прерываемых](../../compute/concepts/preemptible-vm.md) виртуальных машинах и ресурсах.
* Любые фоновые операции прерываются при попытке выполнения интерактивных функций (например, `input()` или `getpass()`).
* Исполнение специальной фоновой операции может быть прервано, если в системе наблюдается дефицит машин нужной конфигурации. Когда вычислительные ресурсы освободятся, исполнение будет продолжено с последнего сохраненного результата. 

Специальные фоновые операции тарифицируются по [правилам фоновых операций](../pricing.md#async).

## Запуск специальной фоновой операции {#run}

Для фонового запуска последовательных операций в ячейке надо указать команду `#pragma repeat`.

Чтобы запустить последовательные операции в фоне:

1. Обновите пакет tensorflow до версии 2.3.0:

    ```python
    %pip install tensorflow==2.3.0
    ```

1. Перезапустите ядро.

    1. На верхней панели в окне проекта нажмите кнопку **Kernel**.
    1. В открывшемся меню нажмите кнопку **Reset kernel**.

1. Задайте тестовую модель, например:

    ```python
    import tensorflow as tf
    import datetime

    mnist = tf.keras.datasets.mnist

    (x_train, y_train),(x_test, y_test) = mnist.load_data()
    x_train, x_test = x_train / 255.0, x_test / 255.0

    def create_model():
        return tf.keras.models.Sequential([
            tf.keras.layers.Flatten(input_shape=(28, 28)),
            tf.keras.layers.Dense(512, activation='relu'),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.Dense(10, activation='softmax')
        ])
    ```

1. Создайте и скомпилируйте модель:

    ```python
    model = create_model()
    model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
    ```

1. Запустите обучение модели, указав служебную команду `#pragma repeat` в начале ячейки: 

    ```python
    #pragma repeat --iterations 20 --checkpoint-period 5 --max-by "model.evaluate(x_test, y_test, verbose=0)[1]"

    model.fit(x_train, y_train, epochs=1, verbose=0)
    ```

      * `--iterations` — количество запусков.
      * `--checkpoint-period` — период сохранения результатов.
      * `--max-by` — правило выбора конечного результата.

В этом примере мы запускаем обучение модели 20 раз и сохраняем результат каждые 5 итераций. В состояние попадет модель, которая показала лучший результат на тестовых данных.

## Параллельный запуск фоновых операций {#parallel}

Для параллельного запуска фоновых операций в ячейке используется команда `#pragma parallel`. 

Параллельный запуск операции позволяет за меньшее время методом перебора получить необходимый результат. Операции выполняются независимо друг от друга. Если при работе ВМ возникла ошибка, вычисления продолжатся на меньшем количестве машин.

Чтобы запустить параллельные вычисления, перед запуском обучения укажите в начале ячейки команду:

```python
#pragma parallel --iterations 20 --parallel-runs 5 --iteration-var "var" --max-by "model.evaluate(x_test, y_test, verbose=0)[1]"

model.fit(x_train, y_train, epochs=1, verbose=0)
```

* `--iterations` — количество запусков.
* `--parallel-runs` — максимальное количество ВМ.
* `--iteration-var` — переменная для разделения итераций между собой (по умолчанию используется переменная `'iteration'`). После выполнения вычислений переменная удаляется. 
* `--max-by` — правило выбора конечного результата.

В этом случае обучение модели будет производиться 20 раз на 5 машинах выбранной конфигурации. Для разделения итераций между собой используется переменная `var`. 

## Прерывание специальной фоновой операции {#interrupt}

{% include [interrupt](../../_includes/datasphere/interrupt-cell.md) %}

