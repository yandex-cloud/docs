# Коннектор Spark

{{ ml-platform-name }} позволяет обрабатывать большие объемы данных на кластерах [{{ dataproc-full-name }}](../../data-proc/). С помощью коннектора Spark вы можете как [использовать уже имеющиеся кластеры {{ dataproc-name }}](data-processing.md#spark-with-existing-cluster), так и [создавать временные кластеры](data-processing.md#spark-with-temporary-cluster).

Коннектор Spark — это специальный ресурс, который хранит настройки подключения и взаимодействия с существующими и временными кластерами {{ dataproc-name }}. Выбранные кластеры автоматически подключаются или создаются при запуске вычислений в IDE. При создании ресурса вы также можете указать данные для подключения к объектному хранилищу [S3](../../glossary/s3.md).

## Информация о коннекторе Spark как ресурсе {#info}

О каждом коннекторе Spark хранится следующая информация:

* уникальный идентификатор ресурса;
* создатель ресурса;
* дата создания и дата последнего изменения в формате в [UTC](https://ru.wikipedia.org/wiki/Всемирное_координированное_время), например `22 апр. 2024 г., 13:21`.
* конфигурация кластера {{ dataproc-name }};
* настройки для подключения к S3.

## Работа с коннектором Spark {#work}

[Создать](../operations/data/spark-connectors.md) коннектор Spark можно в [интерфейсе {{ ml-platform-name }}]({{ link-datasphere-main }}). При создании коннектора Spark вы можете выбрать тип подключения к существующему кластеру {{ dataproc-name }} — SparkContext или Spark Connect (доступен только для кластеров {{ dataproc-name }} версии 2.2 или старше). Для временных кластеров используется подключение SparkContext.

Коннекторы Spark используются в ноутбуках проекта. При первом запуске вычислений вы выбираете [конфигурацию](./configurations.md), на которой будет выполняться код ноутбука. Эта ВМ располагается в сети, указанной в коннекторе Spark, поэтому она имеет сетевой доступ к кластеру {{ dataproc-name }}, однако не принадлежит кластеру. По умолчанию код ячейки ноутбука будет выполняться на ВМ. Для выполнения кода на кластере {{ dataproc-name }} необходимо явно задать это при вызове (например, через `SparkContext::runJob`).

Окружение ВМ для работы с кластером отличается от [стандартного окружения](./preinstalled-packages.md) {{ ml-platform-name }} и позволяет получить доступ к окружению кластера {{ dataproc-name }}. При этом вы также можете использовать [сессии](./data-processing.md#session) для работы с кластером.

После создания коннектор Spark доступен для проекта. Как и любой другой ресурс, коннектор Spark можно опубликовать в сообществе, чтобы использовать его в других проектах. Для этого вам минимально необходимы роли `Editor` в проекте и `Developer` в сообществе, в котором вы хотите его опубликовать. Открыть доступ можно на вкладке **{{ ui-key.yc-ui-datasphere.common.access }}** на странице просмотра коннектора Spark. Ресурс, доступный для сообщества, появится на странице сообщества в разделе **{{ ui-key.yc-ui-datasphere.spaces-page.community-resources }}**.

Если при создании коннектора Spark вы выбрали временный кластер {{ dataproc-name }}, {{ ml-platform-name }} создаст кластер {{ dataproc-name }} при первом запуске вычислений в ноутбуке и будет самостоятельно следить за ним. Кластер запускается и останавливается вместе с ВМ ноутбука. Кластер будет удален, если на нем не будет вычислений в течение времени, указанного в параметре **{{ ui-key.yc-ui-datasphere.edit-project-page.dedicated-vm-inactivity-timeout }}**, или если принудительно остановить ВМ ноутбука.

### Конфигурации временных кластеров {#configurations}

Временные кластеры {{ dataproc-name }} разворачиваются на базе [виртуальных машин {{ compute-full-name }}](../../compute/concepts/vm.md) на платформе Intel Cascade Lake (`standard-v2`).

Необходимый суммарный объем дисков для разных конфигураций кластеров можно рассчитать по формуле:

```text
<количество_хостов_Yandex_Data_Processing> × 256 + 128
```

| Тип кластера | Количество хостов | Объем дисков |  Параметры хоста   |
|:------------:|:-----------------:|--------------|------------------- |
|    **XS**    |         1         | 384 ГБ HDD   | 4 vCPU, 16 ГБ RAM  |
|    **S**     |         4         | 1152 ГБ SSD  | 4 vCPU, 16 ГБ RAM  |
|    **M**     |         8         | 2176 ГБ SSD  | 16 vCPU, 64 ГБ RAM |
|    **L**     |        16         | 4224 ГБ SSD  | 16 vCPU, 64 ГБ RAM |
|    **XL**    |        32         | 8320 ГБ SSD  | 16 vCPU, 64 ГБ RAM |

{% note tip %}

Перед запуском проекта с коннектором Spark для создания временного кластера {{ dataproc-name }} убедитесь, что [квоты]({{ link-console-quotas }}) на создание HDD или SSD-дисков позволяют создать диск достаточного размера.

{% endnote %}

Работа временных кластеров, созданных из шаблонов {{ dataproc-name }}, тарифицируется дополнительно по [правилам тарификации {{ dataproc-full-name }}](../../data-proc/pricing.md).

#### См. также {#see-also}

* [Как создать, изменить и удалить коннектор Spark](../operations/data/spark-connectors.md).
* [{#T}](../troubleshooting/troubles-with-spark.md)
