# Запуск распределенного обучения

{% note info %}

Возможность распределенного обучения находится на стадии [Preview](../../overview/concepts/launch-stages.md). Доступ предоставляется по запросу в техническую поддержку.

{% endnote %} 

[Распределенное обучение](../concepts/taas.md) поддерживает PyTorch и PyTorch Lighting. По умолчанию в {{ ml-platform-name }} установлена версия PyTorch 1.6.0. Обновите ее до версии 1.9.1, чтобы {{ taas }} мог работать корректно:

```bash
%pip install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html
```

{% note warning %}

На стадии Preview распределенное обучение доступно только на ВМ [конфигурации g2.8](../concepts/configurations.md).

{% endnote %}

## {{ taas }} на нескольких GPU {#few-gpus}

1. Подготовьте код обучения и опишите загрузку данных (DataLoader) для PyTorch. 

1. Если вы используете PyTorch, инициализируйте распределенное обучение на основе набора переменных окружения:

   ```python
   torch.distributed.init_process_group(backend='nccl', init_method='env://')
   ```

   Если вы используете PyTorch Lightning, пропустите этот шаг: дополнительная инициализация не требуется. 

1. В отдельной ячейке вызовите служебную команду `#pragma taas`. Укажите количество GPU, между которыми будет распределено обучение.

   ```bash
   #!g2.8
   #pragma taas --gpus 8

   <запуск обучения>
   ```

При запуске обучения в нескольких процессах хранилище проекта {{ ml-platform-name }} будет доступно для записи только тому процессу, для которого переменная окружения `RANK=0`. Учитывайте это при сохранении модели в процессе обучения. 

## {{ taas }} с распределенной доставкой данных {#distributed-dataloader}

Помимо распределения обучения между несколькими GPU {{ taas }} предоставляет возможность оптимизировать загрузку и подготовку данных для обучения. Это может быть полезно, если большие данные находятся в облачном хранилище, скорость доступа к которому серьезно уступает скорости обработки этих данных.

1. Опишите загрузчик данных (DataLoader) PyTorch в отдельной ячейке и зарегистрируйте его. 

   ```python
   import taas

   data_loader=DataLoader(DataSet)
   taas.register(data_loader)
   ```

   Зарегистрированный загрузчик данных будет запущен на нескольких ВМ c1.4 и подготовит данные до запуска обучения на дорогих ресурсах GPU. После подготовки данные будут доставлены на ВМ с GPU, а загрузка может продолжиться параллельно с вычислениями и обучением.

   Для отмены регистрации вызовите:

   ```python
   taas.unregister(data_loader)
   ```

2. Запустите обучение:

   ```python
   #!g2.8
   #pragma taas --gpus 8 --cpus 1 --units 20480000

    <запуск обучения>
   ```

   * `gpus` — количество GPU. Параметр может принимать значения: 
     * 8 — одна ВМ 
     * 16 — две ВМ
     * 32 — четыре ВМ
   * `cpus` — количество ВМ c1.4, на которых будет запущен каждый зарегистрированный загрузчик данных. Значение параметра — от 1 до 8.
   * `units` — количество элементов, которое необходимо извлечь из загрузчика данных.

