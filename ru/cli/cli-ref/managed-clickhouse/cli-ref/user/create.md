---
editable: false
sourcePath: en/_cli-ref/cli-ref/managed-clickhouse/cli-ref/user/create.md
---

# yc managed-clickhouse user create

Create a ClickHouse user.

#### Command Usage

Syntax: 

`yc managed-clickhouse user create <USER-NAME> [Flags...] [Global Flags...]`

#### Flags

| Flag | Description |
|----|----|
|`--cluster-id`|<b>`string`</b><br/>ID of the ClickHouse cluster.|
|`--cluster-name`|<b>`string`</b><br/>Name of the ClickHouse cluster.|
|`--async`|Display information about the operation in progress, without waiting for the operation to complete.|
|`--password`|<b>`string`</b><br/>Password of the ClickHouse user.|
|`--permissions`|<b>`value[,value]`</b><br/>Databases that the user should be able to access.|
|`--generate-password`|Generate password using Connection Manager.|
|`--settings`|<b>`key1=value1[,key2=value2][,"key3=val3a,val3b"]`</b><br/>User-specific settings. Acceptable keys:<br/><ul> <li> <p><code>readonly</code>:     Restricts permissions for non-DDL queries. To restrict permissions for DDL queries, use <strong>allow_ddl</strong> instead.</p> <ul> <li><strong>0</strong> - no restrictions.</li> <li><strong>1</strong> - only read data queries are allowed.</li> <li><strong>2</strong> - read data and change settings queries are allowed.</li> </ul> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/permissions-for-queries#readonly">ClickHouse documentation</a>.</p> </li> <li> <p><code>allow_ddl</code>:     Allows or denies DDL queries (e.g., <strong>CREATE</strong>, <strong>ALTER</strong>, <strong>RENAME</strong>, etc).</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/permissions-for-queries#allow_ddl">ClickHouse documentation</a>.</p> </li> <li> <p><code>allow_introspection_functions</code>:     Enables or disables introspection functions for query profiling.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#allow_introspection_functions">ClickHouse documentation</a>.</p> </li> <li> <p><code>connect_timeout</code>:     Connection timeout in milliseconds.</p> <p>Default value: <strong>10000</strong> (10 seconds).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#connect_timeout">ClickHouse documentation</a>.</p> </li> <li> <p><code>connect_timeout_with_failover</code>:     The timeout in milliseconds for connecting to a remote server for a Distributed table engine.</p> <p>Applies only if the cluster uses sharding and replication. If unsuccessful, several attempts are made to connect to various replicas.</p> <p>Default value: <strong>1000</strong> (1 second).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#connect_timeout_with_failover_ms">ClickHouse documentation</a>.</p> </li> <li> <p><code>receive_timeout</code>:     Receive timeout in milliseconds.</p> <p>Default value: <strong>300000</strong> (5 minutes).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#receive_timeout">ClickHouse documentation</a>.</p> </li> <li> <p><code>send_timeout</code>:     Send timeout in milliseconds.</p> <p>Default value: <strong>300000</strong> (5 minutes).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#send_timeout">ClickHouse documentation</a>.</p> </li> <li> <p><code>idle_connection_timeout</code>:     Timeout to close idle TCP connections after specified time has elapsed, in milliseconds.</p> <p>Default value: <strong>3600000</strong> (1 hour).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#idle_connection_timeout">ClickHouse documentation</a>.</p> </li> <li> <p><code>timeout_before_checking_execution_speed</code>:     Checks that the speed is not too low after the specified time has elapsed, in milliseconds. It is checked that execution speed is not less that specified in <strong>min_execution_speed</strong> parameter.</p> <p>Default value: <strong>60000</strong> (1 minute).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#timeout_before_checking_execution_speed">ClickHouse documentation</a>.</p> </li> <li> <p><code>insert_quorum</code>:     Enables or disables the quorum writes. If the value is less than <strong>2</strong>, then the quorum writes is disabled, otherwise it is enabled.</p> <p>When used, write quorum guarantees that ClickHouse has written data to the quorum of <strong>insert_quorum</strong> replicas with no errors until the <strong>insert_quorum_timeout</strong> expires. All replicas in the quorum are in the consistent state, meaning that they contain linearized data from the previous <strong>INSERT</strong> queries. Employ write quorum, if you need the guarantees that the written data would not be lost in case of one or more replicas failure.</p> <p>You can use <strong>select_sequential_consistency</strong> setting to read the data written with write quorum.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#insert_quorum">ClickHouse documentation</a>.</p> </li> <li> <p><code>insert_quorum_timeout</code>:     Quorum write timeout in milliseconds.</p> <p>If the write quorum is enabled in the cluster, this timeout expires and some data is not written to the <strong>insert_quorum</strong> replicas, then ClickHouse will abort the execution of <strong>INSERT</strong> query and return an error. In this case, the client must send the query again to write the data block into the same or another replica.</p> <p>Default value: <strong>600000</strong> (10 minutes).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#insert_quorum_timeout">ClickHouse documentation</a>.</p> </li> <li> <p><code>insert_quorum_parallel</code>:     Enables or disables parallelism for quorum <strong>INSERT</strong> queries.</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#insert_quorum_parallel">ClickHouse documentation</a>.</p> </li> <li> <p><code>select_sequential_consistency</code>:     Determines the behavior of <strong>SELECT</strong> queries from replicated tables. If enabled, ClickHouse will terminate a query with error message in case the replica does not have a chunk written with the quorum and will not read the parts that have not yet been written with the quorum.</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#select_sequential_consistency">ClickHouse documentation</a>.</p> </li> <li> <p><code>replication_alter_partitions_sync</code>:     Wait mode for asynchronous actions in <strong>ALTER</strong> queries on replicated tables.</p> <ul> <li><strong>0</strong> - do not wait for replicas.</li> <li><strong>1</strong> - only wait for own execution.</li> <li><strong>2</strong> - wait for all replicas.</li> </ul> <p>Default value: <strong>1</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#alter_sync">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_replica_delay_for_distributed_queries</code>:     Max replica delay in milliseconds. If a replica lags more than the set value, this replica is not used and becomes a stale one.</p> <p>Default value: <strong>300000</strong> (5 minutes).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_replica_delay_for_distributed_queries">ClickHouse documentation</a>.</p> </li> <li> <p><code>fallback_to_stale_replicas_for_distributed_queries</code>:     Enables or disables query forcing to a stale replica in case the actual data is unavailable. If enabled, ClickHouse will choose the most up-to-date replica and force the query to use the data in this replica. This setting can be used when doing <strong>SELECT</strong> query from a distributed table that points to replicated tables.</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#fallback_to_stale_replicas_for_distributed_queries">ClickHouse documentation</a>.</p> </li> <li> <p><code>distributed_product_mode</code>:     Determines the behavior of distributed subqueries.</p> <p>Default value: <strong>DISTRIBUTED_PRODUCT_MODE_DENY</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#distributed_product_mode">ClickHouse documentation</a>.</p> </li> <li> <p><code>distributed_aggregation_memory_efficient</code>:     Enables of disables memory saving mode when doing distributed aggregation.</p> <p>When ClickHouse works with a distributed query, external aggregation is done on remote servers. Enable this setting to achieve a smaller memory footprint on the server that sourced such a distributed query.</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#distributed_aggregation_memory_efficient">ClickHouse documentation</a>.</p> </li> <li> <p><code>distributed_ddl_task_timeout</code>:     Timeout for DDL queries, in milliseconds.</p> <p>Default value: <strong>180000</strong> (3 minutes).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#distributed_ddl_task_timeout">ClickHouse documentation</a>.</p> </li> <li> <p><code>distributed_ddl_output_mode</code>:     Determines the format of distributed DDL query result.</p> <p>Default value: <strong>DISTRIBUTED_DDL_OUTPUT_MODE_THROW</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#distributed_ddl_output_mode">ClickHouse documentation</a>.</p> </li> <li> <p><code>skip_unavailable_shards</code>:     Enables or disables silent skipping of unavailable shards.</p> <p>A shard is considered unavailable if all its replicas are also unavailable.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#skip_unavailable_shards">ClickHouse documentation</a>.</p> </li> <li> <p><code>use_hedged_requests</code>:     Enables or disables hedged requests logic for remote queries.</p> <p>It allows to establish many connections with different replicas for query. New connection is enabled in case existent connection(s) with replica(s) were not established within <strong>hedged_connection_timeout</strong> or no data was received within <strong>receive_data_timeout</strong>. Query uses the first connection which send non empty progress packet, other connections are cancelled.</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#use_hedged_requests">ClickHouse documentation</a>.</p> </li> <li> <p><code>hedged_connection_timeout_ms</code>:     Connection timeout for establishing connection with replica for Hedged requests.</p> <p>Default value: <strong>50</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#hedged_connection_timeout_ms">ClickHouse documentation</a>.</p> </li> <li> <p><code>load_balancing</code>:     Algorithm of replicas selection that is used for distributed query processing.</p> <p>Default value: <strong>LOAD_BALANCING_RANDOM</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#load_balancing">ClickHouse documentation</a>.</p> </li> <li> <p><code>prefer_localhost_replica</code>:     Enable or disable preferable using the localhost replica when processing distributed queries.</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#prefer_localhost_replica">ClickHouse documentation</a>.</p> </li> <li> <p><code>compile_expressions</code>:     Enable or disable expression compilation to native code.</p> <p>If you execute a lot of queries that contain identical expressions, then enable this setting. As a result, such queries may be executed faster due to use of compiled expressions.</p> <p>Use this setting in combination with <strong>min_count_to_compile_expression</strong> setting.</p> <p>Default value: <strong>true</strong> for versions 25.5 and higher, <strong>false</strong> for versions 25.4 and lower.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#compile_expressions">ClickHouse documentation</a>.</p> </li> <li> <p><code>min_count_to_compile_expression</code>:     How many identical expressions ClickHouse has to encounter before they are compiled.</p> <p>For the <strong>0</strong> value compilation is synchronous: a query waits for expression compilation process to complete prior to continuing execution. It is recommended to set this value only for testing purposes.</p> <p>For all other values, compilation is asynchronous: the compilation process executes in a separate thread. When a compiled expression is ready, it will be used by ClickHouse for eligible queries, including the ones that are currently running.</p> <p>Default value: <strong>3</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#min_count_to_compile_expression">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_block_size</code>:     Sets the recommended maximum number of rows to include in a single block when loading data from tables.</p> <p>Blocks the size of <strong>max_block_size</strong> are not always loaded from the table: if ClickHouse determines that less data needs to be retrieved, a smaller block is processed.</p> <p>The block size should not be too small to avoid noticeable costs when processing each block. It should also not be too large to ensure that queries with a <strong>LIMIT</strong> clause execute quickly after processing the first block. When setting <strong>max_block_size</strong>, the goal should be to avoid consuming too much memory when extracting a large number of columns in multiple threads and to preserve at least some cache locality.</p> <p>Default value: <strong>65409</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_block_size">ClickHouse documentation</a>.</p> </li> <li> <p><code>min_insert_block_size_rows</code>:     Limits the minimum number of rows in a block to be inserted in a table by <strong>INSERT</strong> query. Blocks that are smaller than the specified value, will be squashed together into the bigger blocks. If set to <strong>0</strong>, block squashing is disabled.</p> <p>Default value: <strong>1048449</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#min_insert_block_size_rows">ClickHouse documentation</a>.</p> </li> <li> <p><code>min_insert_block_size_bytes</code>:     Limits the minimum number of bytes in a block to be inserted in a table by <strong>INSERT</strong> query. Blocks that are smaller than the specified value, will be squashed together into the bigger blocks. If set to <strong>0</strong>, block squashing is disabled.</p> <p>Default value: <strong>268402944</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#min_insert_block_size_bytes">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_insert_block_size</code>:     The size of blocks (in a count of rows) to form for insertion into a table.</p> <p>This setting only applies in cases when the server forms the blocks. For example, for an <strong>INSERT</strong> via the HTTP interface, the server parses the data format and forms blocks of the specified size. But when using clickhouse-client, the client parses the data itself, and the <strong>max_insert_block_size</strong> setting on the server does not affect the size of the inserted blocks. The setting also does not have a purpose when using <strong>INSERT SELECT</strong>, since data is inserted using the same blocks that are formed after <strong>SELECT</strong>.</p> <p>Default value: <strong>1048449</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_insert_block_size">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_partitions_per_insert_block</code>:     When inserting data, ClickHouse calculates the number of partitions in the inserted block. If the number of partitions is more than <strong>max_partitions_per_insert_block</strong>, ClickHouse throws an exception.</p> <p>Default value: <strong>100</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/query-complexity#settings-max_partitions_per_insert_block">ClickHouse documentation</a>.</p> </li> <li> <p><code>min_bytes_to_use_direct_io</code>:     Limits the minimum number of bytes to enable unbuffered direct reads from disk (Direct I/O). If set to <strong>0</strong>, Direct I/O is disabled.</p> <p>By default, ClickHouse does not read data directly from disk, but relies on the filesystem and its cache instead. Such reading strategy is effective when the data volume is small. If the amount of the data to read is huge, it is more effective to read directly from the disk, bypassing the filesystem cache.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#min_bytes_to_use_direct_io">ClickHouse documentation</a>.</p> </li> <li> <p><code>use_uncompressed_cache</code>:     Determines whether to use the cache of uncompressed blocks, or not.</p> <p>Using this cache can significantly reduce latency and increase the throughput when a huge amount of small queries is to be processed. Enable this setting for the users who instantiates small queries frequently.</p> <p>This setting has effect only for tables of the MergeTree family.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#use_uncompressed_cache">ClickHouse documentation</a>.</p> </li> <li> <p><code>merge_tree_max_rows_to_use_cache</code>:     Limits the maximum size in rows of the request that can use the cache of uncompressed data. The cache is not used for requests larger than the specified value.</p> <p>Use this setting in combination with <strong>use_uncompressed_cache</strong> setting.</p> <p>Default value: <strong>1048576</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#merge_tree_max_rows_to_use_cache">ClickHouse documentation</a>.</p> </li> <li> <p><code>merge_tree_max_bytes_to_use_cache</code>:     Limits the maximum size in bytes of the request that can use the cache of uncompressed data. The cache is not used for requests larger than the specified value.</p> <p>Use this setting in combination with <strong>use_uncompressed_cache</strong> setting.</p> <p>Default value: <strong>2013265920</strong> (1920 MiB).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#merge_tree_max_bytes_to_use_cache">ClickHouse documentation</a>.</p> </li> <li> <p><code>merge_tree_min_rows_for_concurrent_read</code>:     Limits the minimum number of rows to be read from a file to enable concurrent read. If the number of rows to be read exceeds this value, then ClickHouse will try to use a few threads to read from a file concurrently.</p> <p>This setting has effect only for tables of the MergeTree family.</p> <p>Default value: <strong>163840</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#merge_tree_min_rows_for_concurrent_read">ClickHouse documentation</a>.</p> </li> <li> <p><code>merge_tree_min_bytes_for_concurrent_read</code>:     Limits the number of bytes to be read from a file to enable concurrent read. If the number of bytes to be read exceeds this value, then ClickHouse will try to use a few threads to read from a file concurrently.</p> <p>This setting has effect only for tables of the MergeTree family.</p> <p>Default value: <strong>251658240</strong> (240 MiB).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#merge_tree_min_bytes_for_concurrent_read">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_bytes_before_external_group_by</code>:     Sets the threshold of RAM consumption (in bytes) after that the temporary data, collected during the <strong>GROUP BY</strong> operation, should be flushed to disk to limit the RAM consumption. If set to <strong>0</strong>, <strong>GROUP BY</strong> in the external memory is disabled.</p> <p>By default, aggregation is done by employing hash table that resides in RAM. A query can result in aggregation of huge data volumes that can lead to memory exhaustion and abortion of the query (see the <strong>max_memory_usage</strong> setting). For such queries, you can use this setting to force ClickHouse to do flushing and complete aggregation successfully.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_bytes_before_external_group_by">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_bytes_before_external_sort</code>:     Sets the threshold of RAM consumption (in bytes) after that the temporary data, collected during the <strong>ORDER BY</strong> operation, should be flushed to disk to limit the RAM consumption. If set to <strong>0</strong>, <strong>ORDER BY</strong> in the external memory is disabled.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_bytes_before_external_sort">ClickHouse documentation</a>.</p> </li> <li> <p><code>group_by_two_level_threshold</code>:     Sets the threshold of the number of keys, after that the two-level aggregation should be used. <strong>0</strong> means threshold is not set.</p> <p>Default value: <strong>100000</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#group_by_two_level_threshold">ClickHouse documentation</a>.</p> </li> <li> <p><code>group_by_two_level_threshold_bytes</code>:     Sets the threshold of the number of bytes, after that the two-level aggregation should be used. <strong>0</strong> means threshold is not set.</p> <p>Default value: <strong>50000000</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#group_by_two_level_threshold_bytes">ClickHouse documentation</a>.</p> </li> <li> <p><code>deduplicate_blocks_in_dependent_materialized_views</code>:     Enables or disables the deduplication check for materialized views that receive data from replicated tables.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#deduplicate_blocks_in_dependent_materialized_views">ClickHouse documentation</a>.</p> </li> <li> <p><code>local_filesystem_read_method</code>:     Method of reading data from local filesystem.</p> <p>The LOCAL_FILESYSTEM_READ_METHOD_IO_URING is experimental and does not work for Log, TinyLog, StripeLog, File, Set and Join, and other tables with append-able files in presence of concurrent reads and writes.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#local_filesystem_read_method">ClickHouse documentation</a>.</p> </li> <li> <p><code>remote_filesystem_read_method</code>:     Method of reading data from remote filesystem.</p> <p>Default value: <strong>REMOTE_FILESYSTEM_READ_METHOD_THREADPOOL</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#remote_filesystem_read_method">ClickHouse documentation</a>.</p> </li> <li> <p><code>priority</code>:     Sets the priority of a query.</p> <ul> <li><strong>0</strong> - priorities are not used.</li> <li><strong>1</strong> - the highest priority.</li> <li>and so on. The higher the number, the lower a query's priority.</li> </ul> <p>If ClickHouse is working with the high-priority queries, and a low-priority query enters, then the low-priority query is paused until higher-priority queries are completed.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#priority">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_threads</code>:     Limits the maximum number of threads to process the request. If set to <strong>0</strong>, the number of threads is calculated automatically based on the number of available CPU cores.</p> <p>The setting applies to threads that perform the same stages of the query processing pipeline in parallel. It does not take threads that read data from remote servers into account.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_threads">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_insert_threads</code>:     The maximum number of threads to execute the <strong>INSERT SELECT</strong> query.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_insert_threads">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_memory_usage</code>:     Limits the maximum memory usage (in bytes) for processing of a single user's query on a single server. <strong>0</strong> means unlimited.</p> <p>This limitation is enforced for any user's single query on a single server.</p> <p>If you use <strong>max_bytes_before_external_group_by</strong> or <strong>max_bytes_before_external_sort</strong> setting, then it is recommended to set their values twice as low as <strong>max_memory_usage</strong> setting value.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_memory_usage">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_memory_usage_for_user</code>:     Limits the maximum memory usage (in bytes) for processing of user's queries on a single server. <strong>0</strong> means unlimited.</p> <p>This limitation is enforced for all queries that belong to one user and run simultaneously on a single server.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_memory_usage_for_user">ClickHouse documentation</a>.</p> </li> <li> <p><code>memory_overcommit_ratio_denominator</code>:     It represents the soft memory limit when the hard limit is reached on the global level. This value is used to compute the overcommit ratio for the query. <strong>0</strong> means skip the query.</p> <p>Default value: <strong>1073741824</strong> (1 GiB).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#memory_overcommit_ratio_denominator">ClickHouse documentation</a>.</p> </li> <li> <p><code>memory_overcommit_ratio_denominator_for_user</code>:     It represents the soft memory limit when the hard limit is reached on the user level. This value is used to compute the overcommit ratio for the user. <strong>0</strong> means skip the query.</p> <p>Default value: <strong>1073741824</strong> (1 GiB).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#memory_overcommit_ratio_denominator_for_user">ClickHouse documentation</a>.</p> </li> <li> <p><code>memory_usage_overcommit_max_wait_microseconds</code>:     Maximum time thread will wait for memory to be freed in the case of memory overcommit. If the timeout is reached and memory is not freed, an exception is thrown.</p> <p>Default value: <strong>5000000</strong> (5 seconds).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#memory_usage_overcommit_max_wait_microseconds">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_network_bandwidth</code>:     The maximum speed of data exchange over the network in bytes per second for a query. <strong>0</strong> means unlimited.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max-network-bandwidth">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_network_bandwidth_for_user</code>:     The maximum speed of data exchange over the network in bytes per second for all concurrently running user queries. <strong>0</strong> means unlimited.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max-network-bandwidth-for-user">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_temporary_data_on_disk_size_for_query</code>:     The maximum amount of data consumed by temporary files on disk in bytes for all concurrently running queries. <strong>0</strong> means unlimited.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/query-complexity#settings_max_temporary_data_on_disk_size_for_query">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_temporary_data_on_disk_size_for_user</code>:     The maximum amount of data consumed by temporary files on disk in bytes for all concurrently running user queries. <strong>0</strong> means unlimited.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/query-complexity#settings_max_temporary_data_on_disk_size_for_user">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_concurrent_queries_for_user</code>:     The maximum number of simultaneously processed queries per user. <strong>0</strong> means unlimited.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_concurrent_queries_for_user">ClickHouse documentation</a>.</p> </li> <li> <p><code>force_index_by_date</code>:     Disables query execution if the index cannot be used by date.</p> <p>This setting has effect only for tables of the MergeTree family.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#force_index_by_date">ClickHouse documentation</a>.</p> </li> <li> <p><code>force_primary_key</code>:     Disables query execution if indexing by the primary key cannot be used.</p> <p>This setting has effect only for tables of the MergeTree family.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#force_primary_key">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_rows_to_read</code>:     Limits the maximum number of rows that can be read from a table when running a query.  <strong>0</strong> means unlimited.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/query-complexity#max-rows-to-read">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_bytes_to_read</code>:     Limits the maximum number of bytes (uncompressed data) that can be read from a table when running a query.  <strong>0</strong> means unlimited.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/query-complexity#max-bytes-to-read">ClickHouse documentation</a>.</p> </li> <li> <p><code>read_overflow_mode</code>:     Determines the behavior on exceeding limits while reading the data.</p> <p>Default value: <strong>OVERFLOW_MODE_THROW</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#read_overflow_mode">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_rows_to_group_by</code>:     Limits the maximum number of unique keys received from aggregation. <strong>0</strong> means unlimited. This setting lets you limit RAM consumption when aggregating.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_rows_to_group_by">ClickHouse documentation</a>.</p> </li> <li> <p><code>group_by_overflow_mode</code>:     Determines the behavior on exceeding limits while doing aggregation.</p> <p>Default value: <strong>GROUP_BY_OVERFLOW_MODE_THROW</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#group_by_overflow_mode">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_rows_to_sort</code>:     Limits the maximum number of rows that can be read from a table for sorting. <strong>0</strong> means unlimited. This setting lets you to limit RAM consumption when sorting</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_rows_to_sort">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_bytes_to_sort</code>:     Limits the maximum number of bytes (uncompressed data) that can be read from a table for sorting. <strong>0</strong> means unlimited. This setting lets you to limit RAM consumption when sorting</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_bytes_to_sort">ClickHouse documentation</a>.</p> </li> <li> <p><code>sort_overflow_mode</code>:     Determines the behavior on exceeding limits while sorting.</p> <p>Default value: <strong>OVERFLOW_MODE_THROW</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#sort_overflow_mode">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_result_rows</code>:     Limits the number of rows in the result. <strong>0</strong> means unlimited.</p> <p>This limitation is also checked for subqueries and parts of distributed queries that run on remote servers.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_result_rows">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_result_bytes</code>:     Limits the result size in bytes (uncompressed data). <strong>0</strong> means unlimited.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_result_bytes">ClickHouse documentation</a>.</p> </li> <li> <p><code>result_overflow_mode</code>:     Determines the behavior on exceeding limits while forming result.</p> <p>Default value: <strong>OVERFLOW_MODE_THROW</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#result_overflow_mode">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_rows_in_distinct</code>:     Limits the maximum number of different rows in the state, which is used for performing <strong>DISTINCT</strong>. <strong>0</strong> means unlimited.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_rows_in_distinct">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_bytes_in_distinct</code>:     Limits the maximum number of bytes (uncompressed data) in the state, which is used for performing <strong>DISTINCT</strong>. <strong>0</strong> means unlimited.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_bytes_in_distinct">ClickHouse documentation</a>.</p> </li> <li> <p><code>distinct_overflow_mode</code>:     Determines the behavior on exceeding limits while performing <strong>DISTINCT</strong>.</p> <p>Default value: <strong>OVERFLOW_MODE_THROW</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#distinct_overflow_mode">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_rows_to_transfer</code>:     Limits the maximum number of rows that can be passed to a remote server or saved in a temporary table when using <strong>GLOBAL IN\|JOIN</strong>. <strong>0</strong> means unlimited.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_rows_to_transfer">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_bytes_to_transfer</code>:     Limits the maximum number of bytes (uncompressed data) that can be passed to a remote server or saved in a temporary table when using <strong>GLOBAL IN\|JOIN</strong>. <strong>0</strong> means unlimited.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_bytes_to_transfer">ClickHouse documentation</a>.</p> </li> <li> <p><code>transfer_overflow_mode</code>:     Determines the behavior on exceeding limits while transfering data.</p> <p>Default value: <strong>OVERFLOW_MODE_THROW</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#transfer_overflow_mode">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_execution_time</code>:     Limits the maximum query execution time in milliseconds. <strong>0</strong> means unlimited.</p> <p>The timeout is checked and the query can stop only in designated places during data processing.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_execution_time">ClickHouse documentation</a>.</p> </li> <li> <p><code>timeout_overflow_mode</code>:     Determines the behavior on exceeding limits of execution time.</p> <p>Default value: <strong>OVERFLOW_MODE_THROW</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#timeout_overflow_mode">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_rows_in_set</code>:     Limits on the maximum number of rows in the set resulting from the execution of the <strong>IN</strong> section. <strong>0</strong> means unlimited.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_rows_in_set">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_bytes_in_set</code>:     Limits on the maximum number of bytes (uncompressed data) in the set resulting from the execution of the <strong>IN</strong> section. <strong>0</strong> means unlimited.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_bytes_in_set">ClickHouse documentation</a>.</p> </li> <li> <p><code>set_overflow_mode</code>:     Determines the behavior on exceeding max_rows_in_set or max_bytes_in_set limit.</p> <p>Default value: <strong>OVERFLOW_MODE_THROW</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#set_overflow_mode">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_rows_in_join</code>:     Limits the maximum number of rows in the hash table that is used when joining tables. <strong>0</strong> means unlimited.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_rows_in_join">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_bytes_in_join</code>:     Limits the maximum number of bytes in the hash table that is used when joining tables. <strong>0</strong> means unlimited.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_bytes_in_join">ClickHouse documentation</a>.</p> </li> <li> <p><code>join_overflow_mode</code>:     Determines the behavior on exceeding max_rows_in_join or max_bytes_in_join limit.</p> <p>Default value: <strong>OVERFLOW_MODE_THROW</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#join_overflow_mode">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_columns_to_read</code>:     Limits the maximum number of columns that can be read from a table in a single query. <strong>0</strong> means unlimited. If the query requires to read more columns to complete, then it will be aborted.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_columns_to_read">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_temporary_columns</code>:     Limits the maximum number of temporary columns that must be kept in RAM simultaneously when running a query, including constant columns. <strong>0</strong> means unlimited. If the query generates more than the specified number of temporary columns in memory as a result of intermediate calculation, then it will be aborted.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_temporary_columns">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_temporary_non_const_columns</code>:     Limits the maximum number of temporary columns that must be kept in RAM simultaneously when running a query, not including constant columns. <strong>0</strong> means unlimited. If the query generates more than the specified number of temporary columns in memory as a result of intermediate calculation, then it will be aborted.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_temporary_non_const_columns">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_query_size</code>:     Limits the size of the part of a query that can be transferred to RAM for parsing with the SQL parser, in bytes.</p> <p>Data in the <strong>VALUES</strong> clause of <strong>INSERT</strong> queries is processed by a separate stream parser (that consumes O(1) RAM) and not affected by this restriction.</p> <p>Default value: <strong>262144</strong> (256 KiB).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_query_size">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_ast_depth</code>:     Limits the maximum depth of query syntax tree.</p> <p>Executing a big and complex query may result in building a syntax tree of enormous depth. By using this setting, you can prohibit execution of over-sized or non-optimized queries for huge tables.</p> <p>Default value: <strong>1000</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_ast_depth">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_ast_elements</code>:     Limits the maximum size of query syntax tree in number of nodes.</p> <p>Executing a big and complex query may result in building a syntax tree of enormous size. By using this setting, you can prohibit execution of over-sized or non-optimized queries for huge tables.</p> <p>Default value: <strong>50000</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_ast_elements">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_expanded_ast_elements</code>:     Limits the maximum size of query syntax tree in number of nodes after expansion of aliases and the asterisk values.</p> <p>Executing a big and complex query may result in building a syntax tree of enormous size. By using this setting, you can prohibit execution of over-sized or non-optimized queries for huge tables.</p> <p>Default value: <strong>500000</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_expanded_ast_elements">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_parser_depth</code>:     Limits maximum recursion depth in the recursive descent parser. Allows controlling the stack size. If set to <strong>0</strong>, recursion depth is unlimited.</p> <p>Default value: <strong>1000</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_parser_depth">ClickHouse documentation</a>.</p> </li> <li> <p><code>min_execution_speed</code>:     Minimal execution speed in rows per second. Checked on every data block when timeout_before_checking_execution_speed expires. If the execution speed is lower, an exception is thrown. <strong>0</strong> means unlimited.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#min_execution_speed">ClickHouse documentation</a>.</p> </li> <li> <p><code>min_execution_speed_bytes</code>:     Minimal execution speed in bytes per second. Checked on every data block when timeout_before_checking_execution_speed expires. If the execution speed is lower, an exception is thrown. <strong>0</strong> means unlimited.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#min_execution_speed_bytes">ClickHouse documentation</a>.</p> </li> <li> <p><code>input_format_values_interpret_expressions</code>:     Enables or disables SQL parser if the fast stream parser cannot parse the data.</p> <p>Enable this setting, if the data that you want to insert into a table contains SQL expressions.</p> <p>For example, the stream parser is unable to parse a value that contains <strong>now()</strong> expression; therefore an <strong>INSERT</strong> query for this value will fail and no data will be inserted into a table. With enabled SQL parser, this expression is parsed correctly: the <strong>now()</strong> expression will be parsed as SQL function, interpreted, and the current date and time will be inserted into the table as a result.</p> <p>This setting has effect only if you use <a href="https://clickhouse.com/docs/en/interfaces/formats/#data-format-values">Values</a> format when inserting data.</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/formats#input_format_values_interpret_expressions">ClickHouse documentation</a>.</p> </li> <li> <p><code>input_format_defaults_for_omitted_fields</code>:     Enables or disables replacing omitted input values with default values of the respective columns when performing <strong>INSERT</strong> queries.</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/formats#input_format_defaults_for_omitted_fields">ClickHouse documentation</a>.</p> </li> <li> <p><code>input_format_null_as_default</code>:     Enables or disables the initialization of <strong>NULL</strong> fields with default values, if data type of these fields is not nullable.</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/formats#input_format_null_as_default">ClickHouse documentation</a>.</p> </li> <li> <p><code>input_format_with_names_use_header</code>:     Enables or disables checking the column order when inserting data.</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/formats#input_format_with_names_use_header">ClickHouse documentation</a>.</p> </li> <li> <p><code>output_format_json_quote_64bit_integers</code>:     Enables or disables quoting of 64-bit integers in JSON output format.</p> <p>If this setting is enabled, then 64-bit integers (<strong>UInt64</strong> and <strong>Int64</strong>) will be quoted when written to JSON output in order to maintain compatibility with the most of the JavaScript engines. Otherwise, such integers will not be quoted.</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/formats#output_format_json_quote_64bit_integers">ClickHouse documentation</a>.</p> </li> <li> <p><code>output_format_json_quote_denormals</code>:     Enables special floating-point values (<strong>+nan</strong>, <strong>-nan</strong>, <strong>+inf</strong> and <strong>-inf</strong>) in JSON output format.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/formats#output_format_json_quote_denormals">ClickHouse documentation</a>.</p> </li> <li> <p><code>date_time_input_format</code>:     Specifies which of date time parsers to use.</p> <p>Default value: <strong>DATE_TIME_INPUT_FORMAT_BASIC</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/formats#date_time_input_format">ClickHouse documentation</a>.</p> </li> <li> <p><code>date_time_output_format</code>:     Specifies which of date time output formats to use.</p> <p>Default value: <strong>DATE_TIME_OUTPUT_FORMAT_SIMPLE</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/formats#date_time_output_format">ClickHouse documentation</a>.</p> </li> <li> <p><code>low_cardinality_allow_in_native_format</code>:     Allows or restricts using the LowCardinality data type with the Native format.</p> <p>LowCardinality columns (aka sparse columns) store data in more effective way, compared to regular columns, by using hash tables. If data to insert suits this storage format, ClickHouse will place them into LowCardinality column.</p> <p>If you use a third-party ClickHouse client that can't work with LowCardinality columns, then this client will not be able to correctly interpret the result of the query that asks for data stored in LowCardinality column. Disable this setting to convert LowCardinality column to regular column when creating the result, so such clients will be able to process the result.</p> <p>Official ClickHouse client works with LowCardinality columns out-of-the-box.</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#low_cardinality_allow_in_native_format">ClickHouse documentation</a>.</p> </li> <li> <p><code>empty_result_for_aggregation_by_empty_set</code>:     Enables or disables returning of empty result when aggregating without keys (with <strong>GROUP BY</strong> operation absent) on empty set (e.g., <strong>SELECT count(*) FROM table WHERE 0</strong>).</p> <ul> <li><strong>true</strong> - ClickHouse will return an empty result for such queries.</li> <li><strong>false</strong> - ClickHouse will return a single-line result consisting of <strong>NULL</strong> values for aggregation functions, in accordance with SQL standard.</li> </ul> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#empty_result_for_aggregation_by_empty_set">ClickHouse documentation</a>.</p> </li> <li> <p><code>format_regexp</code>:     Regular expression (for Regexp format).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/formats#format_regexp">ClickHouse documentation</a>.</p> </li> <li> <p><code>format_regexp_escaping_rule</code>:     Field escaping rule (for Regexp format).</p> <p>Default value: <strong>FORMAT_REGEXP_ESCAPING_RULE_RAW</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/formats#format_regexp_escaping_rule">ClickHouse documentation</a>.</p> </li> <li> <p><code>format_regexp_skip_unmatched</code>:     Skip lines unmatched by regular expression (for Regexp format)</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/formats#format_regexp_skip_unmatched">ClickHouse documentation</a>.</p> </li> <li> <p><code>input_format_parallel_parsing</code>:     Enables or disables order-preserving parallel parsing of data formats. Supported only for TSV, TSKV, CSV and JSONEachRow formats.</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#input_format_parallel_parsing">ClickHouse documentation</a>.</p> </li> <li> <p><code>input_format_import_nested_json</code>:     Enables or disables the insertion of JSON data with nested objects.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/formats#input_format_import_nested_json">ClickHouse documentation</a>.</p> </li> <li> <p><code>format_avro_schema_registry_url</code>:     Avro schema registry URL.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/formats#format_avro_schema_registry_url">ClickHouse documentation</a>.</p> </li> <li> <p><code>data_type_default_nullable</code>:     Allows data types without explicit modifiers <strong>NULL</strong> or <strong>NOT NULL</strong> in column definition will be Nullable.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#data_type_default_nullable">ClickHouse documentation</a>.</p> </li> <li> <p><code>http_connection_timeout</code>:     HTTP connection timeout, in milliseconds.</p> <p>Default value: <strong>1000</strong> (1 second).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#http_connection_timeout">ClickHouse documentation</a>.</p> </li> <li> <p><code>http_receive_timeout</code>:     HTTP receive timeout, in milliseconds.</p> <p>Default value: <strong>30000</strong> (30 seconds).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#http_receive_timeout">ClickHouse documentation</a>.</p> </li> <li> <p><code>http_send_timeout</code>:     HTTP send timeout, in milliseconds.</p> <p>Default value: <strong>30000</strong> (30 seconds).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#http_send_timeout">ClickHouse documentation</a>.</p> </li> <li> <p><code>enable_http_compression</code>:     Enables or disables data compression in HTTP responses.</p> <p>By default, ClickHouse stores data compressed. When executing a query, its result is uncompressed. Use this setting to command ClickHouse to compress the result when sending it via HTTP.</p> <p>Enable this setting and add the <strong>Accept-Encoding: <compression method></strong> HTTP header in a HTTP request to force compression of HTTP response from ClickHouse.</p> <p>ClickHouse support the following compression methods: <strong>gzip</strong>, <strong>br</strong> and <strong>deflate</strong>.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#enable_http_compression">ClickHouse documentation</a>.</p> </li> <li> <p><code>send_progress_in_http_headers</code>:     Enables or disables progress notifications using <strong>X-ClickHouse-Progress</strong> HTTP header.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#send_progress_in_http_headers">ClickHouse documentation</a>.</p> </li> <li> <p><code>http_headers_progress_interval</code>:     Minimum interval between progress notifications with <strong>X-ClickHouse-Progress</strong> HTTP header, in milliseconds.</p> <p>Default value: <strong>100</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#http_headers_progress_interval_ms">ClickHouse documentation</a>.</p> </li> <li> <p><code>add_http_cors_header</code>:     Adds CORS header in HTTP responses.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#add_http_cors_header">ClickHouse documentation</a>.</p> </li> <li> <p><code>cancel_http_readonly_queries_on_client_close</code>:     Cancels HTTP read-only queries (e.g. <strong>SELECT</strong>) when a client closes the connection without waiting for the response.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#cancel_http_readonly_queries_on_client_close">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_http_get_redirects</code>:     Limits the maximum number of HTTP GET redirect hops. If set to <strong>0</strong>, no hops is allowed.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_http_get_redirects">ClickHouse documentation</a>.</p> </li> <li> <p><code>http_max_field_name_size</code>:     Maximum length of field name in HTTP header.</p> <p>Default value: <strong>131072</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#http_max_field_name_size">ClickHouse documentation</a>.</p> </li> <li> <p><code>http_max_field_value_size</code>:     Maximum length of field value in HTTP header.</p> <p>Default value: <strong>131072</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#http_max_field_value_size">ClickHouse documentation</a>.</p> </li> <li> <p><code>quota_mode</code>:     Quota accounting mode.</p> <p>Default value: <strong>QUOTA_MODE_DEFAULT</strong>.</p> </li> <li> <p><code>async_insert</code>:     If enabled, data from <strong>INSERT</strong> query is stored in queue and later flushed to table in background.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#async_insert">ClickHouse documentation</a>.</p> </li> <li> <p><code>wait_for_async_insert</code>:     Enables or disables waiting for processing of asynchronous insertion. If enabled, server returns OK only after the data is inserted.</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#wait_for_async_insert">ClickHouse documentation</a>.</p> </li> <li> <p><code>wait_for_async_insert_timeout</code>:     Timeout for waiting for processing asynchronous inserts, in seconds.</p> <p>Default value: <strong>120</strong> (2 minutes).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#wait_for_async_insert_timeout">ClickHouse documentation</a>.</p> </li> <li> <p><code>async_insert_max_data_size</code>:     The maximum size of the unparsed data in bytes collected per query before being inserted.</p> <p>Default value: <strong>10485760</strong> (10 MiB).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#async_insert_max_data_size">ClickHouse documentation</a>.</p> </li> <li> <p><code>async_insert_busy_timeout</code>:     Maximum time to wait before dumping collected data per query since the first data appeared.</p> <p>Default value: <strong>200</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#async_insert_busy_timeout_max_ms">ClickHouse documentation</a>.</p> </li> <li> <p><code>async_insert_use_adaptive_busy_timeout</code>:     Enables of disables adaptive busy timeout for asynchronous inserts.</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#async_insert_use_adaptive_busy_timeout">ClickHouse documentation</a>.</p> </li> <li> <p><code>log_query_threads</code>:     Enables or disables query threads logging to the the system.query_thread_log table. This setting has effect only when <strong>log_queries</strong> setting is enabled.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#log_query_threads">ClickHouse documentation</a>.</p> </li> <li> <p><code>log_query_views</code>:     Enables or disables query views logging to the the system.query_views_log table.</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#log_query_views">ClickHouse documentation</a>.</p> </li> <li> <p><code>log_queries_probability</code>:     Log queries with the specified probability.</p> <p>Default value: <strong>1</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#log_queries_probability">ClickHouse documentation</a>.</p> </li> <li> <p><code>log_processors_profiles</code>:     Enables or disables logging of processors level profiling data to the the system.processors_profile_log table.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#log_processors_profiles">ClickHouse documentation</a>.</p> </li> <li> <p><code>use_query_cache</code>:     If turned on, <strong>SELECT</strong> queries may utilize the query cache.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#use_query_cache">ClickHouse documentation</a>.</p> </li> <li> <p><code>enable_reads_from_query_cache</code>:     If turned on, results of <strong>SELECT</strong> queries are retrieved from the query cache.</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#enable_reads_from_query_cache">ClickHouse documentation</a>.</p> </li> <li> <p><code>enable_writes_to_query_cache</code>:     If turned on, results of <strong>SELECT</strong> queries are stored in the query cache.</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#enable_writes_to_query_cache">ClickHouse documentation</a>.</p> </li> <li> <p><code>query_cache_min_query_runs</code>:     Minimum number of times a <strong>SELECT</strong> query must run before its result is stored in the query cache.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#query_cache_min_query_runs">ClickHouse documentation</a>.</p> </li> <li> <p><code>query_cache_min_query_duration</code>:     Minimum duration in milliseconds a query needs to run for its result to be stored in the query cache.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#query_cache_min_query_duration">ClickHouse documentation</a>.</p> </li> <li> <p><code>query_cache_ttl</code>:     After this time in seconds entries in the query cache become stale.</p> <p>Default value: <strong>60</strong> (1 minute).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#query_cache_ttl">ClickHouse documentation</a>.</p> </li> <li> <p><code>query_cache_max_entries</code>:     The maximum number of query results the current user may store in the query cache. <strong>0</strong> means unlimited.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#query_cache_max_entries">ClickHouse documentation</a>.</p> </li> <li> <p><code>query_cache_max_size_in_bytes</code>:     The maximum amount of memory (in bytes) the current user may allocate in the query cache. <strong>0</strong> means unlimited.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#query_cache_max_size_in_bytes">ClickHouse documentation</a>.</p> </li> <li> <p><code>query_cache_tag</code>:     A string which acts as a label for query cache entries. The same queries with different tags are considered different by the query cache.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#query_cache_tag">ClickHouse documentation</a>.</p> </li> <li> <p><code>query_cache_share_between_users</code>:     If turned on, the result of <strong>SELECT</strong> queries cached in the query cache can be read by other users.</p> <p>It is not recommended to enable this setting due to security reasons.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#query_cache_share_between_users">ClickHouse documentation</a>.</p> </li> <li> <p><code>query_cache_nondeterministic_function_handling</code>:     Controls how the query cache handles <strong>SELECT</strong> queries with non-deterministic functions like rand() or now().</p> <p>Default value: <strong>QUERY_CACHE_NONDETERMINISTIC_FUNCTION_HANDLING_THROW</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#query_cache_nondeterministic_function_handling">ClickHouse documentation</a>.</p> </li> <li> <p><code>query_cache_system_table_handling</code>:     Controls how the query cache handles <strong>SELECT</strong> queries against system tables.</p> <p>Default value: <strong>QUERY_CACHE_SYSTEM_TABLE_HANDLING_THROW</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#query_cache_system_table_handling">ClickHouse documentation</a>.</p> </li> <li> <p><code>count_distinct_implementation</code>:     Specifies which of the uniq* functions should be used to perform the <strong>COUNT(DISTINCT ...)</strong> construction.</p> <p>Default value: <strong>COUNT_DISTINCT_IMPLEMENTATION_UNIQ_EXACT</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#count_distinct_implementation">ClickHouse documentation</a>.</p> </li> <li> <p><code>joined_subquery_requires_alias</code>:     Force joined subqueries and table functions to have aliases for correct name qualification.</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#joined_subquery_requires_alias">ClickHouse documentation</a>.</p> </li> <li> <p><code>join_use_nulls</code>:     Determines <strong>JOIN</strong> behavior on filling empty cells when merging tables. If enabled, the empty cells are filled with <strong>NULL</strong>. Otherwise, the empty cells are filled with the default value of the corresponding field type.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#join_use_nulls">ClickHouse documentation</a>.</p> </li> <li> <p><code>transform_null_in</code>:     Enables equality of <strong>NULL</strong> values for <strong>IN</strong> operator.</p> <p>By default, <strong>NULL</strong> values can't be compared because <strong>NULL</strong> means undefined value. Thus, comparison <strong>expr = NULL</strong> must always return false. With this setting enabled <strong>NULL = NULL</strong> returns true for <strong>IN</strong> operator.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#transform_null_in">ClickHouse documentation</a>.</p> </li> <li> <p><code>insert_null_as_default</code>:     Enables or disables the insertion of default values instead of <strong>NULL</strong> into columns with not nullable data type.</p> <p>If column type is not nullable and this setting is disabled, then inserting NULL causes an exception. If column type is nullable, then NULL values are inserted as is, regardless of this setting.</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#insert_null_as_default">ClickHouse documentation</a>.</p> </li> <li> <p><code>join_algorithm</code>:     Specifies which JOIN algorithm to use.</p> <p>Default value: <strong>JOIN_ALGORITHM_DIRECT,JOIN_ALGORITHM_PARALLEL_HASH,JOIN_ALGORITHM_HASH</strong> for versions 24.12 and higher, <strong>JOIN_ALGORITHM_DIRECT,JOIN_ALGORITHM_AUTO</strong> for versions from 23.8 to 24.11, <strong>JOIN_ALGORITHM_AUTO</strong> for versions 23.7 and lower.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#join_algorithm">ClickHouse documentation</a>.</p> </li> <li> <p><code>any_join_distinct_right_table_keys</code>:     Enables legacy ClickHouse server behaviour in <strong>ANY INNER\|LEFT JOIN</strong> operations.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#any_join_distinct_right_table_keys">ClickHouse documentation</a>.</p> </li> <li> <p><code>allow_suspicious_low_cardinality_types</code>:     Allows or restricts using LowCardinality with data types with fixed size of 8 bytes or less.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#allow_suspicious_low_cardinality_types">ClickHouse documentation</a>.</p> </li> <li> <p><code>flatten_nested</code>:     Sets the data format of nested columns.</p> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#flatten_nested">ClickHouse documentation</a>.</p> </li> <li> <p><code>memory_profiler_step</code>:     Sets the step of memory profiler. Whenever query memory usage becomes larger than every next step in number of bytes the memory profiler will collect the allocating stacktrace and will write it into trace_log. If set to <strong>0</strong>, memory profiler is disabled.</p> <p>Default value: <strong>4194304</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#memory_profiler_step">ClickHouse documentation</a>.</p> </li> <li> <p><code>memory_profiler_sample_probability</code>:     Collect random allocations and deallocations and write them into system.trace_log with MemorySample trace_type. The probability is for every alloc/free regardless to the size of the allocation.</p> <p>Default value: <strong>0</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#memory_profiler_sample_probability">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_final_threads</code>:     Sets the maximum number of parallel threads for the <strong>SELECT</strong> query data read phase with the <strong>FINAL</strong> modifier.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_final_threads">ClickHouse documentation</a>.</p> </li> <li> <p><code>max_read_buffer_size</code>:     The maximum size of the buffer to read from the filesystem.</p> <p>Default value: <strong>1048576</strong> (1 MiB).</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#max_read_buffer_size">ClickHouse documentation</a>.</p> </li> <li> <p><code>insert_keeper_max_retries</code>:     The setting sets the maximum number of retries for ClickHouse Keeper (or ZooKeeper) requests during insert into replicated MergeTree tables. Only Keeper requests which failed due to network error, Keeper session timeout or request timeout are considered for retries.</p> <p>Default value: <strong>20</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#insert_keeper_max_retries">ClickHouse documentation</a>.</p> </li> <li> <p><code>do_not_merge_across_partitions_select_final</code>:     Enable or disable independent processing of partitions for <strong>SELECT</strong> queries with <strong>FINAL</strong>.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/guides/replacing-merge-tree#exploiting-partitions-with-replacingmergetree">ClickHouse documentation</a>.</p> </li> <li> <p><code>ignore_materialized_views_with_dropped_target_table</code>:     Ignore materialized views with dropped target table during pushing to views.</p> <p>Default value: <strong>false</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#ignore_materialized_views_with_dropped_target_table">ClickHouse documentation</a>.</p> </li> <li> <p><code>enable_analyzer</code>:     Enables or disables new query analyzer.</p> <p>Default value: <strong>true</strong> for versions 25.5 and higher, <strong>false</strong> for versions 25.4 and lower.</p> <p>For details, see <a href="https://clickhouse.com/docs/guides/developer/understanding-query-execution-with-the-analyzer#analyzer">ClickHouse documentation</a>.</p> </li> <li> <p><code>s3_use_adaptive_timeouts</code>:     Enables or disables adaptive timeouts for S3 requests.</p> <ul> <li><strong>true</strong> - for all S3 requests first two attempts are made with low send and receive timeouts.</li> <li><strong>false</strong> - all attempts are made with identical timeouts.</li> </ul> <p>Default value: <strong>true</strong>.</p> <p>For details, see <a href="https://clickhouse.com/docs/operations/settings/settings#s3_use_adaptive_timeouts">ClickHouse documentation</a>.</p> </li> <li> <p><code>compile</code>:     The setting is deprecated and has no effect.</p> </li> <li> <p><code>min_count_to_compile</code>:     The setting is deprecated and has no effect.</p> </li> <li> <p><code>async_insert_threads</code>:     The setting is deprecated and has no effect.</p> </li> <li> <p><code>async_insert_stale_timeout</code>:     The setting is deprecated and has no effect.</p> </li> </ul>|
|`--quota`|<b>`PROPERTY=VALUE[,PROPERTY=VALUE...]`</b><br/>User specific quotas<br/><br/>Possible property names:<br/><ul> <li><code>interval</code>:     Duration of interval for quota in milliseconds. Possible to use time units - &quot;1m30s&quot;. Minimal value is 1 second.</li> <li><code>queries</code>:     The total number of queries. 0 - unlimited.</li> <li><code>errors</code>:     The number of queries that threw exception. 0 - unlimited.</li> <li><code>result-rows</code>:     The total number of rows given as the result. 0 - unlimited.</li> <li><code>read-rows</code>:     The total number of source rows read from tables for running the query, on all remote servers. 0 - unlimited.</li> <li><code>execution-time</code>:     The total query execution time, in milliseconds (wall time). Possible to use time units - &quot;1m30s&quot;. 0 - unlimited.</li> </ul>|

#### Global Flags

| Flag | Description |
|----|----|
|`--profile`|<b>`string`</b><br/>Set the custom configuration file.|
|`--debug`|Debug logging.|
|`--debug-grpc`|Debug gRPC logging. Very verbose, used for debugging connection problems.|
|`--no-user-output`|Disable printing user intended output to stderr.|
|`--retry`|<b>`int`</b><br/>Enable gRPC retries. By default, retries are enabled with maximum 5 attempts.<br/>Pass 0 to disable retries. Pass any negative value for infinite retries.<br/>Even infinite retries are capped with 2 minutes timeout.|
|`--cloud-id`|<b>`string`</b><br/>Set the ID of the cloud to use.|
|`--folder-id`|<b>`string`</b><br/>Set the ID of the folder to use.|
|`--folder-name`|<b>`string`</b><br/>Set the name of the folder to use (will be resolved to id).|
|`--endpoint`|<b>`string`</b><br/>Set the Cloud API endpoint (host:port).|
|`--token`|<b>`string`</b><br/>Set the OAuth token to use.|
|`--impersonate-service-account-id`|<b>`string`</b><br/>Set the ID of the service account to impersonate.|
|`--no-browser`|Disable opening browser for authentication.|
|`--format`|<b>`string`</b><br/>Set the output format: text (default), yaml, json, json-rest.|
|`--jq`|<b>`string`</b><br/>Query to select values from the response using jq syntax|
|`-h`,`--help`|Display help for the command.|
