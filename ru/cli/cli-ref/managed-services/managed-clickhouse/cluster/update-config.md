---
editable: false
sourcePath: en/_cli-ref/cli-ref/managed-services/managed-clickhouse/cluster/update-config.md
---

# yc managed-clickhouse cluster update-config

Update the configuration of a ClickHouse cluster.

#### Command Usage

Syntax: 

`yc managed-clickhouse cluster update-config <CLUSTER-NAME>|<CLUSTER-ID> [Flags...] [Global Flags...]`

#### Flags

| Flag | Description |
|----|----|
|`--id`|<b>`string`</b><br/>ID of the ClickHouse cluster.|
|`--name`|<b>`string`</b><br/>Name of the ClickHouse cluster.|
|`--async`|Display information about the operation in progress, without waiting for the operation to complete.|
|`--set`|<b>`key1=value1[,key2=value2][,"key3=val3a,val3b"]`</b><br/>Set a parameter for a ClickHouse cluster. Can be specified multiple times. Acceptable keys:<br/><ul> <li> <p><code>log_level</code>:     Logging level for the ClickHouse cluster. Possible values: TRACE, DEBUG, INFORMATION, WARNING, ERROR.</p> </li> <li> <p><code>merge_tree.replicated_deduplication_window</code>:     Number of blocks of hashes to keep in ZooKeeper.</p> </li> <li> <p><code>merge_tree.replicated_deduplication_window_seconds</code>:     Period of time to keep blocks of hashes for.</p> </li> <li> <p><code>merge_tree.parts_to_delay_insert</code>:     If table contains at least that many active parts in single partition, artificially slow down insert into table.</p> </li> <li> <p><code>merge_tree.parts_to_throw_insert</code>:     If more than this number active parts in single partition, throw 'Too many parts ...' exception.</p> </li> <li> <p><code>merge_tree.inactive_parts_to_delay_insert</code>:</p> </li> <li> <p><code>merge_tree.inactive_parts_to_throw_insert</code>:</p> </li> <li> <p><code>merge_tree.max_replicated_merges_in_queue</code>:     How many tasks of merging and mutating parts are allowed simultaneously in ReplicatedMergeTree queue.</p> </li> <li> <p><code>merge_tree.number_of_free_entries_in_pool_to_lower_max_size_of_merge</code>:     If there is less than specified number of free entries in background pool (or replicated queue), start to lower maximum size of merge to process.</p> </li> <li> <p><code>merge_tree.max_bytes_to_merge_at_min_space_in_pool</code>:     Maximum in total size of parts to merge, when there are minimum free threads in background pool (or entries in replication queue).</p> </li> <li> <p><code>merge_tree.max_bytes_to_merge_at_max_space_in_pool</code>:</p> </li> <li> <p><code>merge_tree.min_bytes_for_wide_part</code>:     Minimum number of bytes in a data part that can be stored in <strong>Wide</strong> format.</p> <p>More info see in <a href="https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/mergetree/#min_bytes_for_wide_part">ClickHouse documentation</a>.</p> </li> <li> <p><code>merge_tree.min_rows_for_wide_part</code>:     Minimum number of rows in a data part that can be stored in <strong>Wide</strong> format.</p> <p>More info see in <a href="https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/mergetree/#min_bytes_for_wide_part">ClickHouse documentation</a>.</p> </li> <li> <p><code>merge_tree.ttl_only_drop_parts</code>:     Enables or disables complete dropping of data parts where all rows are expired in MergeTree tables.</p> <p>More info see in <a href="https://clickhouse.com/docs/en/operations/settings/settings/#ttl_only_drop_parts">ClickHouse documentation</a>.</p> </li> <li> <p><code>merge_tree.allow_remote_fs_zero_copy_replication</code>:</p> </li> <li> <p><code>merge_tree.merge_with_ttl_timeout</code>:</p> </li> <li> <p><code>merge_tree.merge_with_recompression_ttl_timeout</code>:</p> </li> <li> <p><code>merge_tree.max_parts_in_total</code>:</p> </li> <li> <p><code>merge_tree.max_number_of_merges_with_ttl_in_pool</code>:</p> </li> <li> <p><code>merge_tree.cleanup_delay_period</code>:</p> </li> <li> <p><code>merge_tree.number_of_free_entries_in_pool_to_execute_mutation</code>:</p> </li> <li> <p><code>kafka.security_protocol</code>:</p> </li> <li> <p><code>kafka.sasl_mechanism</code>:</p> </li> <li> <p><code>kafka.sasl_username</code>:</p> </li> <li> <p><code>kafka.sasl_password</code>:</p> </li> <li> <p><code>kafka_topics.name</code>:</p> </li> <li> <p><code>kafka_topics.settings.security_protocol</code>:</p> </li> <li> <p><code>kafka_topics.settings.sasl_mechanism</code>:</p> </li> <li> <p><code>kafka_topics.settings.sasl_username</code>:</p> </li> <li> <p><code>kafka_topics.settings.sasl_password</code>:</p> </li> <li> <p><code>rabbitmq.username</code>:     <a href="https://clickhouse.com/docs/en/engines/table-engines/integrations/rabbitmq/">RabbitMQ</a> username</p> </li> <li> <p><code>rabbitmq.password</code>:     <a href="https://clickhouse.com/docs/en/engines/table-engines/integrations/rabbitmq/">RabbitMQ</a> password</p> </li> <li> <p><code>rabbitmq.vhost</code>:     <a href="https://clickhouse.com/docs/en/engines/table-engines/integrations/rabbitmq/">RabbitMQ</a> virtual host</p> </li> <li> <p><code>max_connections</code>:     Maximum number of inbound connections.</p> </li> <li> <p><code>max_concurrent_queries</code>:     Maximum number of simultaneously processed requests.</p> </li> <li> <p><code>keep_alive_timeout</code>:     Number of milliseconds that ClickHouse waits for incoming requests before closing the connection.</p> </li> <li> <p><code>uncompressed_cache_size</code>:     Cache size (in bytes) for uncompressed data used by MergeTree tables.</p> </li> <li> <p><code>mark_cache_size</code>:     Approximate size (in bytes) of the cache of &quot;marks&quot; used by MergeTree tables.</p> </li> <li> <p><code>max_table_size_to_drop</code>:     Maximum size of the table that can be deleted using a DROP query.</p> </li> <li> <p><code>max_partition_size_to_drop</code>:     Maximum size of the partition that can be deleted using a DROP query.</p> </li> <li> <p><code>builtin_dictionaries_reload_interval</code>:     The setting is deprecated and has no effect.</p> </li> <li> <p><code>timezone</code>:     The server's time zone to be used in DateTime fields conversions. Specified as an IANA identifier.</p> </li> <li> <p><code>geobase_uri</code>:     Address of the archive with the user geobase in Object Storage.</p> </li> <li> <p><code>query_log_retention_size</code>:     The maximum size that query_log can grow to before old data will be removed. If set to 0, automatic removal of query_log data based on size is disabled.</p> </li> <li> <p><code>query_log_retention_time</code>:     The maximum time that query_log records will be retained before removal. If set to 0, automatic removal of query_log data based on time is disabled.</p> </li> <li> <p><code>query_thread_log_enabled</code>:     Whether query_thread_log system table is enabled.</p> </li> <li> <p><code>query_thread_log_retention_size</code>:     The maximum size that query_thread_log can grow to before old data will be removed. If set to 0, automatic removal of query_thread_log data based on size is disabled.</p> </li> <li> <p><code>query_thread_log_retention_time</code>:     The maximum time that query_thread_log records will be retained before removal. If set to 0, automatic removal of query_thread_log data based on time is disabled.</p> </li> <li> <p><code>part_log_retention_size</code>:     The maximum size that part_log can grow to before old data will be removed. If set to 0, automatic removal of part_log data based on size is disabled.</p> </li> <li> <p><code>part_log_retention_time</code>:     The maximum time that part_log records will be retained before removal. If set to 0, automatic removal of part_log data based on time is disabled.</p> </li> <li> <p><code>metric_log_enabled</code>:     Whether metric_log system table is enabled.</p> </li> <li> <p><code>metric_log_retention_size</code>:     The maximum size that metric_log can grow to before old data will be removed. If set to 0, automatic removal of metric_log data based on size is disabled.</p> </li> <li> <p><code>metric_log_retention_time</code>:     The maximum time that metric_log records will be retained before removal. If set to 0, automatic removal of metric_log data based on time is disabled.</p> </li> <li> <p><code>trace_log_enabled</code>:     Whether trace_log system table is enabled.</p> </li> <li> <p><code>trace_log_retention_size</code>:     The maximum size that trace_log can grow to before old data will be removed. If set to 0, automatic removal of trace_log data based on size is disabled.</p> </li> <li> <p><code>trace_log_retention_time</code>:     The maximum time that trace_log records will be retained before removal. If set to 0, automatic removal of trace_log data based on time is disabled.</p> </li> <li> <p><code>text_log_enabled</code>:     Whether text_log system table is enabled.</p> </li> <li> <p><code>text_log_retention_size</code>:     The maximum size that text_log can grow to before old data will be removed. If set to 0, automatic removal of text_log data based on size is disabled.</p> </li> <li> <p><code>text_log_retention_time</code>:     The maximum time that text_log records will be retained before removal. If set to 0, automatic removal of text_log data based on time is disabled.</p> </li> <li> <p><code>text_log_level</code>:     Logging level for text_log system table. Possible values: TRACE, DEBUG, INFORMATION, WARNING, ERROR.</p> </li> <li> <p><code>opentelemetry_span_log_enabled</code>:</p> </li> <li> <p><code>background_pool_size</code>:</p> </li> <li> <p><code>background_schedule_pool_size</code>:</p> </li> <li> <p><code>background_fetches_pool_size</code>:     Sets the number of threads performing background fetches for tables with <strong>ReplicatedMergeTree</strong> engines. Default value: 8.</p> <p>More info see in <a href="https://clickhouse.com/docs/en/operations/server-configuration-parameters/settings/#background_fetches_pool_size">ClickHouse documentation</a>.</p> </li> <li> <p><code>background_move_pool_size</code>:</p> </li> <li> <p><code>background_distributed_schedule_pool_size</code>:</p> </li> <li> <p><code>background_buffer_flush_schedule_pool_size</code>:</p> </li> <li> <p><code>background_message_broker_schedule_pool_size</code>:</p> </li> <li> <p><code>default_database</code>:     The default database.</p> <p>To get a list of cluster databases, see <a href="https://cloud.yandex.com/en/docs/managed-clickhouse/operations/databases#list-db">Yandex Managed ClickHouse documentation</a>.</p> </li> <li> <p><code>total_memory_profiler_step</code>:     Sets the memory size (in bytes) for a stack trace at every peak allocation step. Default value: <strong>4194304</strong>.</p> <p>More info see in <a href="https://clickhouse.com/docs/en/operations/server-configuration-parameters/settings/#total-memory-profiler-step">ClickHouse documentation</a>.</p> </li> </ul> <p>total_memory_tracker_sample_probability</p>|

#### Global Flags

| Flag | Description |
|----|----|
|`--profile`|<b>`string`</b><br/>Set the custom configuration file.|
|`--debug`|Debug logging.|
|`--debug-grpc`|Debug gRPC logging. Very verbose, used for debugging connection problems.|
|`--no-user-output`|Disable printing user intended output to stderr.|
|`--retry`|<b>`int`</b><br/>Enable gRPC retries. By default, retries are enabled with maximum 5 attempts.<br/>Pass 0 to disable retries. Pass any negative value for infinite retries.<br/>Even infinite retries are capped with 2 minutes timeout.|
|`--cloud-id`|<b>`string`</b><br/>Set the ID of the cloud to use.|
|`--folder-id`|<b>`string`</b><br/>Set the ID of the folder to use.|
|`--folder-name`|<b>`string`</b><br/>Set the name of the folder to use (will be resolved to id).|
|`--endpoint`|<b>`string`</b><br/>Set the Cloud API endpoint (host:port).|
|`--token`|<b>`string`</b><br/>Set the OAuth token to use.|
|`--impersonate-service-account-id`|<b>`string`</b><br/>Set the ID of the service account to impersonate.|
|`--format`|<b>`string`</b><br/>Set the output format: text (default), yaml, json, json-rest.|
|`-h`,`--help`|Display help for the command.|
