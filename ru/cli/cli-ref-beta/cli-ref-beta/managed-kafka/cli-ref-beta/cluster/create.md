---
editable: false
noIndex: true
sourcePath: en/_cli-ref-beta/cli-ref-beta/managed-kafka/cli-ref-beta/cluster/create.md
---

# yc beta managed-kafka cluster create

Creates a new Apache Kafka® cluster in the specified folder.

#### Command Usage

Syntax: 

`yc beta managed-kafka cluster create <FOLDER-ID>`

#### Flags

| Flag | Description |
|----|----|
|`-r`,`--request-file`|<b>`string`</b><br/>Path to a request file.|
|`--example-json`|Generates a JSON template of the request.<br/>The template can be customized and used as input for the command.<br/>Usage example:<br/><br/>1. Generate template: yc beta compute instance create --example-json > request.json<br/>2. Edit the template: vim request.json<br/>3. Run with template: yc beta compute instance create -r request.json|
|`--example-yaml`|Generates a YAML template of the request.<br/>The template can be customized and used as input for the command.<br/>Usage example:<br/><br/>1. Generate template: yc beta compute instance create --example-yaml > request.yaml<br/>2. Edit the template: vim request.yaml<br/>3. Run with template: yc beta compute instance create -r request.yaml|
|`--config-spec`|<b>`shorthand/json`</b><br/>Kafka and hosts configuration the Apache Kafka® cluster.<br/>Shorthand Syntax:<br/>{<br/>access = {<br/>data-transfer = bool<br/>},<br/>assign-public-ip = bool,<br/>brokers-count = int,<br/>disk-size-autoscaling = {<br/>disk-size-limit = int,<br/>emergency-usage-threshold = int,<br/>planned-usage-threshold = int<br/>},<br/>kafka = {<br/>kafka-config = kafka-config-2-8={<br/>auto-create-topics-enable = bool,<br/>compression-type = COMPRESSION_TYPE_UNCOMPRESSED\|COMPRESSION_TYPE_ZSTD\|COMPRESSION_TYPE_LZ4\|COMPRESSION_TYPE_SNAPPY\|COMPRESSION_TYPE_GZIP\|COMPRESSION_TYPE_PRODUCER,<br/>default-replication-factor = int,<br/>log-flush-interval-messages = int,<br/>log-flush-interval-ms = int,<br/>log-flush-scheduler-interval-ms = int,<br/>log-preallocate = bool,<br/>log-retention-bytes = int,<br/>log-retention-hours = int,<br/>log-retention-minutes = int,<br/>log-retention-ms = int,<br/>log-segment-bytes = int,<br/>message-max-bytes = int,<br/>num-partitions = int,<br/>offsets-retention-minutes = int,<br/>replica-fetch-max-bytes = int,<br/>sasl-enabled-mechanisms = SASL_MECHANISM_SCRAM_SHA_256\|SASL_MECHANISM_SCRAM_SHA_512,...,<br/>socket-receive-buffer-bytes = int,<br/>socket-send-buffer-bytes = int,<br/>ssl-cipher-suites = str,...<br/>} \| kafka-config-3={<br/>auto-create-topics-enable = bool,<br/>compression-type = COMPRESSION_TYPE_UNCOMPRESSED\|COMPRESSION_TYPE_ZSTD\|COMPRESSION_TYPE_LZ4\|COMPRESSION_TYPE_SNAPPY\|COMPRESSION_TYPE_GZIP\|COMPRESSION_TYPE_PRODUCER,<br/>default-replication-factor = int,<br/>log-flush-interval-messages = int,<br/>log-flush-interval-ms = int,<br/>log-flush-scheduler-interval-ms = int,<br/>log-preallocate = bool,<br/>log-retention-bytes = int,<br/>log-retention-hours = int,<br/>log-retention-minutes = int,<br/>log-retention-ms = int,<br/>log-segment-bytes = int,<br/>message-max-bytes = int,<br/>num-partitions = int,<br/>offsets-retention-minutes = int,<br/>replica-fetch-max-bytes = int,<br/>sasl-enabled-mechanisms = SASL_MECHANISM_SCRAM_SHA_256\|SASL_MECHANISM_SCRAM_SHA_512,...,<br/>socket-receive-buffer-bytes = int,<br/>socket-send-buffer-bytes = int,<br/>ssl-cipher-suites = str,...<br/>} \| kafka-config-4={<br/>auto-create-topics-enable = bool,<br/>compression-type = COMPRESSION_TYPE_UNCOMPRESSED\|COMPRESSION_TYPE_ZSTD\|COMPRESSION_TYPE_LZ4\|COMPRESSION_TYPE_SNAPPY\|COMPRESSION_TYPE_GZIP\|COMPRESSION_TYPE_PRODUCER,<br/>default-replication-factor = int,<br/>log-flush-interval-messages = int,<br/>log-flush-interval-ms = int,<br/>log-flush-scheduler-interval-ms = int,<br/>log-retention-bytes = int,<br/>log-retention-hours = int,<br/>log-retention-minutes = int,<br/>log-retention-ms = int,<br/>log-segment-bytes = int,<br/>message-max-bytes = int,<br/>num-partitions = int,<br/>offsets-retention-minutes = int,<br/>replica-fetch-max-bytes = int,<br/>sasl-enabled-mechanisms = SASL_MECHANISM_SCRAM_SHA_256\|SASL_MECHANISM_SCRAM_SHA_512,...,<br/>socket-receive-buffer-bytes = int,<br/>socket-send-buffer-bytes = int,<br/>ssl-cipher-suites = str,...<br/>},<br/>resources = {<br/>disk-size = int,<br/>disk-type-id = str,<br/>resource-preset-id = str<br/>}<br/>},<br/>kafka-ui-config = {<br/>enabled = bool<br/>},<br/>kraft = {<br/>resources = {<br/>disk-size = int,<br/>disk-type-id = str,<br/>resource-preset-id = str<br/>}<br/>},<br/>patch-version = str,<br/>rest-api-config = {<br/>enabled = bool<br/>},<br/>schema-registry = bool,<br/>unmanaged-topics = bool,<br/>version = str,<br/>zone-id = str,...,<br/>zookeeper = {<br/>resources = {<br/>disk-size = int,<br/>disk-type-id = str,<br/>resource-preset-id = str<br/>}<br/>}<br/>}<br/>JSON Syntax:<br/>"{<br/>"access": {<br/>"data-transfer": "bool"<br/>},<br/>"assign-public-ip": "bool",<br/>"brokers-count": "int",<br/>"disk-size-autoscaling": {<br/>"disk-size-limit": "int",<br/>"emergency-usage-threshold": "int",<br/>"planned-usage-threshold": "int"<br/>},<br/>"kafka": {<br/>"kafka-config": {<br/>"kafka-config-2-8": {<br/>"auto-create-topics-enable": "bool",<br/>"compression-type": "COMPRESSION_TYPE_UNCOMPRESSED\|COMPRESSION_TYPE_ZSTD\|COMPRESSION_TYPE_LZ4\|COMPRESSION_TYPE_SNAPPY\|COMPRESSION_TYPE_GZIP\|COMPRESSION_TYPE_PRODUCER",<br/>"default-replication-factor": "int",<br/>"log-flush-interval-messages": "int",<br/>"log-flush-interval-ms": "int",<br/>"log-flush-scheduler-interval-ms": "int",<br/>"log-preallocate": "bool",<br/>"log-retention-bytes": "int",<br/>"log-retention-hours": "int",<br/>"log-retention-minutes": "int",<br/>"log-retention-ms": "int",<br/>"log-segment-bytes": "int",<br/>"message-max-bytes": "int",<br/>"num-partitions": "int",<br/>"offsets-retention-minutes": "int",<br/>"replica-fetch-max-bytes": "int",<br/>"sasl-enabled-mechanisms": [<br/>"SASL_MECHANISM_SCRAM_SHA_256\|SASL_MECHANISM_SCRAM_SHA_512", ...<br/>],<br/>"socket-receive-buffer-bytes": "int",<br/>"socket-send-buffer-bytes": "int",<br/>"ssl-cipher-suites": [<br/>"str", ...<br/>]<br/>},<br/>"kafka-config-3": {<br/>"auto-create-topics-enable": "bool",<br/>"compression-type": "COMPRESSION_TYPE_UNCOMPRESSED\|COMPRESSION_TYPE_ZSTD\|COMPRESSION_TYPE_LZ4\|COMPRESSION_TYPE_SNAPPY\|COMPRESSION_TYPE_GZIP\|COMPRESSION_TYPE_PRODUCER",<br/>"default-replication-factor": "int",<br/>"log-flush-interval-messages": "int",<br/>"log-flush-interval-ms": "int",<br/>"log-flush-scheduler-interval-ms": "int",<br/>"log-preallocate": "bool",<br/>"log-retention-bytes": "int",<br/>"log-retention-hours": "int",<br/>"log-retention-minutes": "int",<br/>"log-retention-ms": "int",<br/>"log-segment-bytes": "int",<br/>"message-max-bytes": "int",<br/>"num-partitions": "int",<br/>"offsets-retention-minutes": "int",<br/>"replica-fetch-max-bytes": "int",<br/>"sasl-enabled-mechanisms": [<br/>"SASL_MECHANISM_SCRAM_SHA_256\|SASL_MECHANISM_SCRAM_SHA_512", ...<br/>],<br/>"socket-receive-buffer-bytes": "int",<br/>"socket-send-buffer-bytes": "int",<br/>"ssl-cipher-suites": [<br/>"str", ...<br/>]<br/>},<br/>"kafka-config-4": {<br/>"auto-create-topics-enable": "bool",<br/>"compression-type": "COMPRESSION_TYPE_UNCOMPRESSED\|COMPRESSION_TYPE_ZSTD\|COMPRESSION_TYPE_LZ4\|COMPRESSION_TYPE_SNAPPY\|COMPRESSION_TYPE_GZIP\|COMPRESSION_TYPE_PRODUCER",<br/>"default-replication-factor": "int",<br/>"log-flush-interval-messages": "int",<br/>"log-flush-interval-ms": "int",<br/>"log-flush-scheduler-interval-ms": "int",<br/>"log-retention-bytes": "int",<br/>"log-retention-hours": "int",<br/>"log-retention-minutes": "int",<br/>"log-retention-ms": "int",<br/>"log-segment-bytes": "int",<br/>"message-max-bytes": "int",<br/>"num-partitions": "int",<br/>"offsets-retention-minutes": "int",<br/>"replica-fetch-max-bytes": "int",<br/>"sasl-enabled-mechanisms": [<br/>"SASL_MECHANISM_SCRAM_SHA_256\|SASL_MECHANISM_SCRAM_SHA_512", ...<br/>],<br/>"socket-receive-buffer-bytes": "int",<br/>"socket-send-buffer-bytes": "int",<br/>"ssl-cipher-suites": [<br/>"str", ...<br/>]<br/>}<br/>},<br/>"resources": {<br/>"disk-size": "int",<br/>"disk-type-id": "str",<br/>"resource-preset-id": "str"<br/>}<br/>},<br/>"kafka-ui-config": {<br/>"enabled": "bool"<br/>},<br/>"kraft": {<br/>"resources": {<br/>"disk-size": "int",<br/>"disk-type-id": "str",<br/>"resource-preset-id": "str"<br/>}<br/>},<br/>"patch-version": "str",<br/>"rest-api-config": {<br/>"enabled": "bool"<br/>},<br/>"schema-registry": "bool",<br/>"unmanaged-topics": "bool",<br/>"version": "str",<br/>"zone-id": [<br/>"str", ...<br/>],<br/>"zookeeper": {<br/>"resources": {<br/>"disk-size": "int",<br/>"disk-type-id": "str",<br/>"resource-preset-id": "str"<br/>}<br/>}<br/>}"<br/>Fields:<br/>access -> (struct)<br/>Access policy for external services.<br/>data-transfer -> (bool)<br/>Allow access for DataTransfer.<br/>assign-public-ip -> (bool)<br/>The flag that defines whether a public IP address is assigned to the cluster. If the value is 'true', then Apache Kafka® cluster is available on the Internet via it's public IP address.<br/>brokers-count -> (int)<br/>The number of Kafka brokers deployed in each availability zone.<br/>disk-size-autoscaling -> (struct)<br/>DiskSizeAutoscaling settings<br/>disk-size-limit -> (int)<br/>New storage size (in bytes) that is set when one of the thresholds is achieved.<br/>emergency-usage-threshold -> (int)<br/>Threshold of storage usage (in percent) that triggers immediate automatic scaling of the storage. Zero value means disabled threshold.<br/>planned-usage-threshold -> (int)<br/>Threshold of storage usage (in percent) that triggers automatic scaling of the storage during the maintenance window. Zero value means disabled threshold.<br/>kafka -> (struct)<br/>Configuration and resource allocation for Kafka brokers.<br/>resources -> (struct)<br/>Resources allocated to Kafka brokers.<br/>disk-size -> (int)<br/>Volume of the storage available to a host, in bytes. Must be greater than 2 * partition segment size in bytes * partitions count, so each partition can have one active segment file and one closed segment file that can be deleted.<br/>disk-type-id -> (string)<br/>Type of the storage environment for the host.<br/>resource-preset-id -> (string)<br/>ID of the preset for computational resources available to a host (CPU, memory, etc.). All available presets are listed in the documentation.<br/>kafka-config -> (oneof<kafka-config-2-8\|kafka-config-3\|kafka-config-4>)<br/>Oneof kafka-config field<br/>kafka-config-2-8 -> (struct)<br/>Configuration of an Apache Kafka® 2.8 broker.<br/>auto-create-topics-enable -> (bool)<br/>Enable auto creation of topic on the server<br/>compression-type -> (enum<COMPRESSION_TYPE_GZIP\|COMPRESSION_TYPE_LZ4\|COMPRESSION_TYPE_PRODUCER\|COMPRESSION_TYPE_SNAPPY\|COMPRESSION_TYPE_UNCOMPRESSED\|COMPRESSION_TYPE_ZSTD>)<br/>Cluster topics compression type.<br/>default-replication-factor -> (int)<br/>Default replication factor of the topic on the whole cluster<br/>log-flush-interval-messages -> (int)<br/>The number of messages accumulated on a log partition before messages are flushed to disk. This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.<br/>log-flush-interval-ms -> (int)<br/>The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk. If not set, the value of [log_flush_scheduler_interval_ms] is used. This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.<br/>log-flush-scheduler-interval-ms -> (int)<br/>The frequency of checks (in milliseconds) for any logs that need to be flushed to disk. This check is done by the log flusher.<br/>log-preallocate -> (bool)<br/>Should pre allocate file when create new segment? This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting. Deprecated. Feature useless for Yandex Cloud.<br/>log-retention-bytes -> (int)<br/>Partition size limit; Kafka will discard old log segments to free up space if 'delete' [TopicConfig2_8.cleanup_policy] is in effect. This setting is helpful if you need to control the size of a log due to limited disk space. This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.<br/>log-retention-hours -> (int)<br/>The number of hours to keep a log segment file before deleting it.<br/>log-retention-minutes -> (int)<br/>The number of minutes to keep a log segment file before deleting it. If not set, the value of [log_retention_hours] is used.<br/>log-retention-ms -> (int)<br/>The number of milliseconds to keep a log segment file before deleting it. If not set, the value of [log_retention_minutes] is used. This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.<br/>log-segment-bytes -> (int)<br/>The maximum size of a single log file. This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.<br/>message-max-bytes -> (int)<br/>The largest record batch size allowed by Kafka. Default value: 1048588.<br/>num-partitions -> (int)<br/>Default number of partitions per topic on the whole cluster<br/>offsets-retention-minutes -> (int)<br/>Offset storage time after a consumer group loses all its consumers. Default: 10080.<br/>replica-fetch-max-bytes -> (int)<br/>The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.<br/>sasl-enabled-mechanisms -> ([]int)<br/>The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].<br/>socket-receive-buffer-bytes -> (int)<br/>The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.<br/>socket-send-buffer-bytes -> (int)<br/>The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.<br/>ssl-cipher-suites -> ([]string)<br/>A list of cipher suites.<br/>kafka-config-3 -> (struct)<br/>Configuration of an Apache Kafka® 3.x broker.<br/>auto-create-topics-enable -> (bool)<br/>Enable auto creation of topic on the server<br/>compression-type -> (enum<COMPRESSION_TYPE_GZIP\|COMPRESSION_TYPE_LZ4\|COMPRESSION_TYPE_PRODUCER\|COMPRESSION_TYPE_SNAPPY\|COMPRESSION_TYPE_UNCOMPRESSED\|COMPRESSION_TYPE_ZSTD>)<br/>Cluster topics compression type.<br/>default-replication-factor -> (int)<br/>Default replication factor of the topic on the whole cluster<br/>log-flush-interval-messages -> (int)<br/>The number of messages accumulated on a log partition before messages are flushed to disk. This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_messages] setting.<br/>log-flush-interval-ms -> (int)<br/>The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk. If not set, the value of [log_flush_scheduler_interval_ms] is used. This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_ms] setting.<br/>log-flush-scheduler-interval-ms -> (int)<br/>The frequency of checks (in milliseconds) for any logs that need to be flushed to disk. This check is done by the log flusher.<br/>log-preallocate -> (bool)<br/>Should pre allocate file when create new segment? This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.preallocate] setting. Deprecated. Feature useless for Yandex Cloud.<br/>log-retention-bytes -> (int)<br/>Partition size limit; Kafka will discard old log segments to free up space if 'delete' [TopicConfig3.cleanup_policy] is in effect. This setting is helpful if you need to control the size of a log due to limited disk space. This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_bytes] setting.<br/>log-retention-hours -> (int)<br/>The number of hours to keep a log segment file before deleting it.<br/>log-retention-minutes -> (int)<br/>The number of minutes to keep a log segment file before deleting it. If not set, the value of [log_retention_hours] is used.<br/>log-retention-ms -> (int)<br/>The number of milliseconds to keep a log segment file before deleting it. If not set, the value of [log_retention_minutes] is used. This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_ms] setting.<br/>log-segment-bytes -> (int)<br/>The maximum size of a single log file. This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.segment_bytes] setting.<br/>message-max-bytes -> (int)<br/>The largest record batch size allowed by Kafka. Default value: 1048588.<br/>num-partitions -> (int)<br/>Default number of partitions per topic on the whole cluster<br/>offsets-retention-minutes -> (int)<br/>Offset storage time after a consumer group loses all its consumers. Default: 10080.<br/>replica-fetch-max-bytes -> (int)<br/>The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.<br/>sasl-enabled-mechanisms -> ([]int)<br/>The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].<br/>socket-receive-buffer-bytes -> (int)<br/>The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.<br/>socket-send-buffer-bytes -> (int)<br/>The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.<br/>ssl-cipher-suites -> ([]string)<br/>A list of cipher suites.<br/>kafka-config-4 -> (struct)<br/>Configuration of an Apache Kafka® 4.x broker.<br/>auto-create-topics-enable -> (bool)<br/>Enable auto creation of topic on the server<br/>compression-type -> (enum<COMPRESSION_TYPE_GZIP\|COMPRESSION_TYPE_LZ4\|COMPRESSION_TYPE_PRODUCER\|COMPRESSION_TYPE_SNAPPY\|COMPRESSION_TYPE_UNCOMPRESSED\|COMPRESSION_TYPE_ZSTD>)<br/>Cluster topics compression type.<br/>default-replication-factor -> (int)<br/>Default replication factor of the topic on the whole cluster<br/>log-flush-interval-messages -> (int)<br/>The number of messages accumulated on a log partition before messages are flushed to disk. This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_messages] setting.<br/>log-flush-interval-ms -> (int)<br/>The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk. If not set, the value of [log_flush_scheduler_interval_ms] is used. This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig4.flush_ms] setting.<br/>log-flush-scheduler-interval-ms -> (int)<br/>The frequency of checks (in milliseconds) for any logs that need to be flushed to disk. This check is done by the log flusher.<br/>log-retention-bytes -> (int)<br/>Partition size limit; Kafka will discard old log segments to free up space if 'delete' [TopicConfig4.cleanup_policy] is in effect. This setting is helpful if you need to control the size of a log due to limited disk space. This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_bytes] setting.<br/>log-retention-hours -> (int)<br/>The number of hours to keep a log segment file before deleting it.<br/>log-retention-minutes -> (int)<br/>The number of minutes to keep a log segment file before deleting it. If not set, the value of [log_retention_hours] is used.<br/>log-retention-ms -> (int)<br/>The number of milliseconds to keep a log segment file before deleting it. If not set, the value of [log_retention_minutes] is used. This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig4.retention_ms] setting.<br/>log-segment-bytes -> (int)<br/>The maximum size of a single log file. This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig4.segment_bytes] setting.<br/>message-max-bytes -> (int)<br/>The largest record batch size allowed by Kafka. Default value: 1048588.<br/>num-partitions -> (int)<br/>Default number of partitions per topic on the whole cluster<br/>offsets-retention-minutes -> (int)<br/>Offset storage time after a consumer group loses all its consumers. Default: 10080.<br/>replica-fetch-max-bytes -> (int)<br/>The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.<br/>sasl-enabled-mechanisms -> ([]int)<br/>The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].<br/>socket-receive-buffer-bytes -> (int)<br/>The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.<br/>socket-send-buffer-bytes -> (int)<br/>The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.<br/>ssl-cipher-suites -> ([]string)<br/>A list of cipher suites.<br/>kafka-ui-config -> (struct)<br/>Configuration of Kafka UI.<br/>enabled -> (bool)<br/>Is Kafka UI enabled for this cluster.<br/>kraft -> (struct)<br/>Configuration and resource allocation for KRaft-controller hosts.<br/>resources -> (struct)<br/>Resources allocated to KRaft controller hosts.<br/>disk-size -> (int)<br/>Volume of the storage available to a host, in bytes. Must be greater than 2 * partition segment size in bytes * partitions count, so each partition can have one active segment file and one closed segment file that can be deleted.<br/>disk-type-id -> (string)<br/>Type of the storage environment for the host.<br/>resource-preset-id -> (string)<br/>ID of the preset for computational resources available to a host (CPU, memory, etc.). All available presets are listed in the documentation.<br/>patch-version -> (string)<br/>Patch or release version ex. 3.9.1, 4.0.1 etc<br/>rest-api-config -> (struct)<br/>Configuration of REST API.<br/>enabled -> (bool)<br/>Is REST API enabled for this cluster.<br/>schema-registry -> (bool)<br/>Enables managed schema registry on cluster<br/>unmanaged-topics -> (bool)<br/>Allows to manage topics via AdminAPI Deprecated. Feature enabled permanently.<br/>version -> (string)<br/>Version of Apache Kafka® used in the cluster. Possible values: '2.8', '3.0', '3.1', '3.2', '3.3', '3.4', '3.5', '3.6'.<br/>zone-id -> ([]string)<br/>IDs of availability zones where Kafka brokers reside.<br/>zookeeper -> (struct)<br/>Configuration and resource allocation for ZooKeeper hosts.<br/>resources -> (struct)<br/>Resources allocated to ZooKeeper hosts.<br/>disk-size -> (int)<br/>Volume of the storage available to a host, in bytes. Must be greater than 2 * partition segment size in bytes * partitions count, so each partition can have one active segment file and one closed segment file that can be deleted.<br/>disk-type-id -> (string)<br/>Type of the storage environment for the host.<br/>resource-preset-id -> (string)<br/>ID of the preset for computational resources available to a host (CPU, memory, etc.). All available presets are listed in the documentation.|
|`--deletion-protection`|Deletion Protection inhibits deletion of the cluster|
|`--description`|<b>`string`</b><br/>Description of the Apache Kafka® cluster.|
|`--disk-encryption-key-id`|<b>`string`</b><br/>ID of the key to encrypt cluster disks.|
|`--environment`|<b>`enum`</b><br/>Deployment environment of the Apache Kafka® cluster. Possible Values: 'production', 'prestable'|
|`--folder-id`|<b>`string`</b><br/>ID of the folder to create the Apache Kafka® cluster in. To get the folder ID, make a [yandex.cloud.resourcemanager.v1.FolderService.List] request.|
|`--host-group-ids`|<b>`strings`</b><br/>Host groups to place VMs of cluster on.|
|`--labels`|<b>`stringToString`</b><br/>Custom labels for the Apache Kafka® cluster as 'key:value' pairs. For example, "project": "mvp" or "source": "dictionary".|
|`--maintenance-window`|<b>`shorthand/json`</b><br/>Window of maintenance operations.<br/>Shorthand Syntax:<br/>{<br/>policy = anytime={} \| weekly-maintenance-window={<br/>day = MON\|TUE\|WED\|THU\|FRI\|SAT\|SUN,<br/>hour = int<br/>}<br/>}<br/>JSON Syntax:<br/>"{<br/>"policy": {<br/>"anytime": {},<br/>"weekly-maintenance-window": {<br/>"day": "MON\|TUE\|WED\|THU\|FRI\|SAT\|SUN",<br/>"hour": "int"<br/>}<br/>}<br/>}"<br/>Fields:<br/>policy -> (oneof<anytime\|weekly-maintenance-window>)<br/>Oneof policy field<br/>anytime -> (struct)<br/>weekly-maintenance-window -> (struct)<br/>day -> (enum<FRI\|MON\|SAT\|SUN\|THU\|TUE\|WED>)<br/>hour -> (int)<br/>Hour of the day in UTC.|
|`--name`|<b>`string`</b><br/>Name of the Apache Kafka® cluster. The name must be unique within the folder.|
|`--network-id`|<b>`string`</b><br/>ID of the network to create the Apache Kafka® cluster in.|
|`--security-group-ids`|<b>`strings`</b><br/>User security groups|
|`--subnet-id`|<b>`strings`</b><br/>IDs of subnets to create brokers in.|
|`--topic-specs`|<b>`shorthand/json`</b><br/>One or more configurations of topics to be created in the Apache Kafka® cluster.<br/>Shorthand Syntax:<br/>[<br/>{<br/>name = str,<br/>partitions = int,<br/>replication-factor = int,<br/>topic-config = topic-config-2-8={<br/>cleanup-policy = CLEANUP_POLICY_DELETE\|CLEANUP_POLICY_COMPACT\|CLEANUP_POLICY_COMPACT_AND_DELETE,<br/>compression-type = COMPRESSION_TYPE_UNCOMPRESSED\|COMPRESSION_TYPE_ZSTD\|COMPRESSION_TYPE_LZ4\|COMPRESSION_TYPE_SNAPPY\|COMPRESSION_TYPE_GZIP\|COMPRESSION_TYPE_PRODUCER,<br/>delete-retention-ms = int,<br/>file-delete-delay-ms = int,<br/>flush-messages = int,<br/>flush-ms = int,<br/>max-message-bytes = int,<br/>min-compaction-lag-ms = int,<br/>min-insync-replicas = int,<br/>preallocate = bool,<br/>retention-bytes = int,<br/>retention-ms = int,<br/>segment-bytes = int<br/>} \| topic-config-3={<br/>cleanup-policy = CLEANUP_POLICY_DELETE\|CLEANUP_POLICY_COMPACT\|CLEANUP_POLICY_COMPACT_AND_DELETE,<br/>compression-type = COMPRESSION_TYPE_UNCOMPRESSED\|COMPRESSION_TYPE_ZSTD\|COMPRESSION_TYPE_LZ4\|COMPRESSION_TYPE_SNAPPY\|COMPRESSION_TYPE_GZIP\|COMPRESSION_TYPE_PRODUCER,<br/>delete-retention-ms = int,<br/>file-delete-delay-ms = int,<br/>flush-messages = int,<br/>flush-ms = int,<br/>max-message-bytes = int,<br/>min-compaction-lag-ms = int,<br/>min-insync-replicas = int,<br/>preallocate = bool,<br/>retention-bytes = int,<br/>retention-ms = int,<br/>segment-bytes = int<br/>} \| topic-config-4={<br/>cleanup-policy = CLEANUP_POLICY_DELETE\|CLEANUP_POLICY_COMPACT\|CLEANUP_POLICY_COMPACT_AND_DELETE,<br/>compression-type = COMPRESSION_TYPE_UNCOMPRESSED\|COMPRESSION_TYPE_ZSTD\|COMPRESSION_TYPE_LZ4\|COMPRESSION_TYPE_SNAPPY\|COMPRESSION_TYPE_GZIP\|COMPRESSION_TYPE_PRODUCER,<br/>delete-retention-ms = int,<br/>file-delete-delay-ms = int,<br/>flush-messages = int,<br/>flush-ms = int,<br/>max-message-bytes = int,<br/>min-compaction-lag-ms = int,<br/>min-insync-replicas = int,<br/>preallocate = bool,<br/>retention-bytes = int,<br/>retention-ms = int,<br/>segment-bytes = int<br/>}<br/>}, ...<br/>]<br/>JSON Syntax:<br/>"[<br/>{<br/>"name": "str",<br/>"partitions": "int",<br/>"replication-factor": "int",<br/>"topic-config": {<br/>"topic-config-2-8": {<br/>"cleanup-policy": "CLEANUP_POLICY_DELETE\|CLEANUP_POLICY_COMPACT\|CLEANUP_POLICY_COMPACT_AND_DELETE",<br/>"compression-type": "COMPRESSION_TYPE_UNCOMPRESSED\|COMPRESSION_TYPE_ZSTD\|COMPRESSION_TYPE_LZ4\|COMPRESSION_TYPE_SNAPPY\|COMPRESSION_TYPE_GZIP\|COMPRESSION_TYPE_PRODUCER",<br/>"delete-retention-ms": "int",<br/>"file-delete-delay-ms": "int",<br/>"flush-messages": "int",<br/>"flush-ms": "int",<br/>"max-message-bytes": "int",<br/>"min-compaction-lag-ms": "int",<br/>"min-insync-replicas": "int",<br/>"preallocate": "bool",<br/>"retention-bytes": "int",<br/>"retention-ms": "int",<br/>"segment-bytes": "int"<br/>},<br/>"topic-config-3": {<br/>"cleanup-policy": "CLEANUP_POLICY_DELETE\|CLEANUP_POLICY_COMPACT\|CLEANUP_POLICY_COMPACT_AND_DELETE",<br/>"compression-type": "COMPRESSION_TYPE_UNCOMPRESSED\|COMPRESSION_TYPE_ZSTD\|COMPRESSION_TYPE_LZ4\|COMPRESSION_TYPE_SNAPPY\|COMPRESSION_TYPE_GZIP\|COMPRESSION_TYPE_PRODUCER",<br/>"delete-retention-ms": "int",<br/>"file-delete-delay-ms": "int",<br/>"flush-messages": "int",<br/>"flush-ms": "int",<br/>"max-message-bytes": "int",<br/>"min-compaction-lag-ms": "int",<br/>"min-insync-replicas": "int",<br/>"preallocate": "bool",<br/>"retention-bytes": "int",<br/>"retention-ms": "int",<br/>"segment-bytes": "int"<br/>},<br/>"topic-config-4": {<br/>"cleanup-policy": "CLEANUP_POLICY_DELETE\|CLEANUP_POLICY_COMPACT\|CLEANUP_POLICY_COMPACT_AND_DELETE",<br/>"compression-type": "COMPRESSION_TYPE_UNCOMPRESSED\|COMPRESSION_TYPE_ZSTD\|COMPRESSION_TYPE_LZ4\|COMPRESSION_TYPE_SNAPPY\|COMPRESSION_TYPE_GZIP\|COMPRESSION_TYPE_PRODUCER",<br/>"delete-retention-ms": "int",<br/>"file-delete-delay-ms": "int",<br/>"flush-messages": "int",<br/>"flush-ms": "int",<br/>"max-message-bytes": "int",<br/>"min-compaction-lag-ms": "int",<br/>"min-insync-replicas": "int",<br/>"preallocate": "bool",<br/>"retention-bytes": "int",<br/>"retention-ms": "int",<br/>"segment-bytes": "int"<br/>}<br/>}<br/>}, ...<br/>]"<br/>Fields:<br/>name -> (string)<br/>Name of the topic.<br/>partitions -> (int)<br/>The number of the topic's partitions.<br/>replication-factor -> (int)<br/>Amount of copies of a topic data kept in the cluster.<br/>topic-config -> (oneof<topic-config-2-8\|topic-config-3\|topic-config-4>)<br/>Oneof topic-config field<br/>topic-config-2-8 -> (struct)<br/>cleanup-policy -> (enum<CLEANUP_POLICY_COMPACT\|CLEANUP_POLICY_COMPACT_AND_DELETE\|CLEANUP_POLICY_DELETE>)<br/>Retention policy to use on old log messages.<br/>compression-type -> (enum<COMPRESSION_TYPE_GZIP\|COMPRESSION_TYPE_LZ4\|COMPRESSION_TYPE_PRODUCER\|COMPRESSION_TYPE_SNAPPY\|COMPRESSION_TYPE_UNCOMPRESSED\|COMPRESSION_TYPE_ZSTD>)<br/>The compression type for a given topic.<br/>delete-retention-ms -> (int)<br/>The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.<br/>file-delete-delay-ms -> (int)<br/>The time to wait before deleting a file from the filesystem.<br/>flush-messages -> (int)<br/>The number of messages accumulated on a log partition before messages are flushed to disk. This setting overrides the cluster-level [KafkaConfig2_8.log_flush_interval_messages] setting on the topic level.<br/>flush-ms -> (int)<br/>The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk. This setting overrides the cluster-level [KafkaConfig2_8.log_flush_interval_ms] setting on the topic level.<br/>max-message-bytes -> (int)<br/>The largest record batch size allowed in topic.<br/>min-compaction-lag-ms -> (int)<br/>The minimum time in milliseconds a message will remain uncompacted in the log.<br/>min-insync-replicas -> (int)<br/>This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write to be considered successful (when a producer sets acks to "all").<br/>preallocate -> (bool)<br/>True if we should preallocate the file on disk when creating a new log segment. This setting overrides the cluster-level [KafkaConfig2_8.log_preallocate] setting on the topic level.<br/>retention-bytes -> (int)<br/>The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the 'delete' [cleanup_policy] is in effect. It is helpful if you need to control the size of log due to limited disk space. This setting overrides the cluster-level [KafkaConfig2_8.log_retention_bytes] setting on the topic level.<br/>retention-ms -> (int)<br/>The number of milliseconds to keep a log segment's file before deleting it. This setting overrides the cluster-level [KafkaConfig2_8.log_retention_ms] setting on the topic level.<br/>segment-bytes -> (int)<br/>This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention. This setting overrides the cluster-level [KafkaConfig2_8.log_segment_bytes] setting on the topic level.<br/>topic-config-3 -> (struct)<br/>cleanup-policy -> (enum<CLEANUP_POLICY_COMPACT\|CLEANUP_POLICY_COMPACT_AND_DELETE\|CLEANUP_POLICY_DELETE>)<br/>Retention policy to use on old log messages.<br/>compression-type -> (enum<COMPRESSION_TYPE_GZIP\|COMPRESSION_TYPE_LZ4\|COMPRESSION_TYPE_PRODUCER\|COMPRESSION_TYPE_SNAPPY\|COMPRESSION_TYPE_UNCOMPRESSED\|COMPRESSION_TYPE_ZSTD>)<br/>The compression type for a given topic.<br/>delete-retention-ms -> (int)<br/>The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.<br/>file-delete-delay-ms -> (int)<br/>The time to wait before deleting a file from the filesystem.<br/>flush-messages -> (int)<br/>The number of messages accumulated on a log partition before messages are flushed to disk. This setting overrides the cluster-level [KafkaConfig3.log_flush_interval_messages] setting on the topic level.<br/>flush-ms -> (int)<br/>The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk. This setting overrides the cluster-level [KafkaConfig3.log_flush_interval_ms] setting on the topic level.<br/>max-message-bytes -> (int)<br/>The largest record batch size allowed in topic.<br/>min-compaction-lag-ms -> (int)<br/>The minimum time in milliseconds a message will remain uncompacted in the log.<br/>min-insync-replicas -> (int)<br/>This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write to be considered successful (when a producer sets acks to "all").<br/>preallocate -> (bool)<br/>True if we should preallocate the file on disk when creating a new log segment. This setting overrides the cluster-level [KafkaConfig3.log_preallocate] setting on the topic level.<br/>retention-bytes -> (int)<br/>The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the 'delete' [cleanup_policy] is in effect. It is helpful if you need to control the size of log due to limited disk space. This setting overrides the cluster-level [KafkaConfig3.log_retention_bytes] setting on the topic level.<br/>retention-ms -> (int)<br/>The number of milliseconds to keep a log segment's file before deleting it. This setting overrides the cluster-level [KafkaConfig3.log_retention_ms] setting on the topic level.<br/>segment-bytes -> (int)<br/>This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention. This setting overrides the cluster-level [KafkaConfig3.log_segment_bytes] setting on the topic level.<br/>topic-config-4 -> (struct)<br/>cleanup-policy -> (enum<CLEANUP_POLICY_COMPACT\|CLEANUP_POLICY_COMPACT_AND_DELETE\|CLEANUP_POLICY_DELETE>)<br/>Retention policy to use on old log messages.<br/>compression-type -> (enum<COMPRESSION_TYPE_GZIP\|COMPRESSION_TYPE_LZ4\|COMPRESSION_TYPE_PRODUCER\|COMPRESSION_TYPE_SNAPPY\|COMPRESSION_TYPE_UNCOMPRESSED\|COMPRESSION_TYPE_ZSTD>)<br/>The compression type for a given topic.<br/>delete-retention-ms -> (int)<br/>The amount of time in milliseconds to retain delete tombstone markers for log compacted topics.<br/>file-delete-delay-ms -> (int)<br/>The time to wait before deleting a file from the filesystem.<br/>flush-messages -> (int)<br/>The number of messages accumulated on a log partition before messages are flushed to disk. This setting overrides the cluster-level [KafkaConfig4.log_flush_interval_messages] setting on the topic level.<br/>flush-ms -> (int)<br/>The maximum time in milliseconds that a message in the topic is kept in memory before flushed to disk. This setting overrides the cluster-level [KafkaConfig4.log_flush_interval_ms] setting on the topic level.<br/>max-message-bytes -> (int)<br/>The largest record batch size allowed in topic.<br/>min-compaction-lag-ms -> (int)<br/>The minimum time in milliseconds a message will remain uncompacted in the log.<br/>min-insync-replicas -> (int)<br/>This configuration specifies the minimum number of replicas that must acknowledge a write to topic for the write to be considered successful (when a producer sets acks to "all").<br/>preallocate -> (bool)<br/>True if we should preallocate the file on disk when creating a new log segment. This setting overrides the cluster-level [KafkaConfig4.log_preallocate] setting on the topic level.<br/>retention-bytes -> (int)<br/>The maximum size a partition can grow to before Kafka will discard old log segments to free up space if the 'delete' [cleanup_policy] is in effect. It is helpful if you need to control the size of log due to limited disk space. This setting overrides the cluster-level [KafkaConfig4.log_retention_bytes] setting on the topic level.<br/>retention-ms -> (int)<br/>The number of milliseconds to keep a log segment's file before deleting it. This setting overrides the cluster-level [KafkaConfig4.log_retention_ms] setting on the topic level.<br/>segment-bytes -> (int)<br/>This configuration controls the segment file size for the log. Retention and cleaning is always done a file at a time so a larger segment size means fewer files but less granular control over retention. This setting overrides the cluster-level [KafkaConfig4.log_segment_bytes] setting on the topic level.|
|`--user-specs`|<b>`shorthand/json`</b><br/>Configurations of accounts to be created in the Apache Kafka® cluster.<br/>Shorthand Syntax:<br/>[<br/>{<br/>name = str,<br/>password = str,<br/>permissions = [<br/>{<br/>allow-hosts = str,...,<br/>role = ACCESS_ROLE_PRODUCER\|ACCESS_ROLE_CONSUMER\|ACCESS_ROLE_ADMIN\|ACCESS_ROLE_TOPIC_ADMIN\|ACCESS_ROLE_TOPIC_PRODUCER\|ACCESS_ROLE_TOPIC_CONSUMER\|ACCESS_ROLE_SCHEMA_READER\|ACCESS_ROLE_SCHEMA_WRITER,<br/>topic-name = str<br/>}, ...<br/>]<br/>}, ...<br/>]<br/>JSON Syntax:<br/>"[<br/>{<br/>"name": "str",<br/>"password": "str",<br/>"permissions": [<br/>{<br/>"allow-hosts": [<br/>"str", ...<br/>],<br/>"role": "ACCESS_ROLE_PRODUCER\|ACCESS_ROLE_CONSUMER\|ACCESS_ROLE_ADMIN\|ACCESS_ROLE_TOPIC_ADMIN\|ACCESS_ROLE_TOPIC_PRODUCER\|ACCESS_ROLE_TOPIC_CONSUMER\|ACCESS_ROLE_SCHEMA_READER\|ACCESS_ROLE_SCHEMA_WRITER",<br/>"topic-name": "str"<br/>}, ...<br/>]<br/>}, ...<br/>]"<br/>Fields:<br/>name -> (string)<br/>Name of the Kafka user.<br/>password -> (string)<br/>Password of the Kafka user.<br/>permissions -> ([]struct)<br/>Set of permissions granted to the user.<br/>allow-hosts -> ([]string)<br/>Lists hosts allowed for this permission. Only ip-addresses allowed as value of single host. When not defined, access from any host is allowed. Bare in mind that the same host might appear in multiple permissions at the same time, hence removing individual permission doesn't automatically restricts access from the [allow_hosts] of the permission. If the same host(s) is listed for another permission of the same principal/topic, the host(s) remains allowed.<br/>role -> (enum<ACCESS_ROLE_ADMIN\|ACCESS_ROLE_CONSUMER\|ACCESS_ROLE_PRODUCER\|ACCESS_ROLE_SCHEMA_READER\|ACCESS_ROLE_SCHEMA_WRITER\|ACCESS_ROLE_TOPIC_ADMIN\|ACCESS_ROLE_TOPIC_CONSUMER\|ACCESS_ROLE_TOPIC_PRODUCER>)<br/>Access role type to grant to the user.<br/>topic-name -> (string)<br/>Name or prefix-pattern with wildcard for the topic that the permission grants access to. With roles SCHEMA_READER and SCHEMA_WRITER: string that contains set of schema registry subjects, separated by ';'. To get the topic name, make a [TopicService.List] request.|
|`--async`|Display information about the operation in progress, without waiting for the operation to complete.|

#### Global Flags

| Flag | Description |
|----|----|
|`--profile`|<b>`string`</b><br/>Set the custom profile.|
|`--region`|<b>`string`</b><br/>Set the region.|
|`--debug`|Debug logging.|
|`--debug-grpc`|Debug gRPC logging. Very verbose, used for debugging connection problems.|
|`--no-user-output`|Disable printing user intended output to stderr.|
|`--pager`|<b>`string`</b><br/>Set the custom pager.|
|`--format`|<b>`string`</b><br/>Set the output format: text, yaml, json, table, json-rest.|
|`--retry`|<b>`int`</b><br/>Enable gRPC retries. By default, retries are enabled with maximum 5 attempts.<br/>Pass 0 to disable retries. Pass any negative value for infinite retries.<br/>Even infinite retries are capped with 2 minutes timeout.|
|`--timeout`|<b>`string`</b><br/>Set the timeout.|
|`--token`|<b>`string`</b><br/>Set the IAM token to use.|
|`--impersonate-service-account-id`|<b>`string`</b><br/>Set the ID of the service account to impersonate.|
|`--no-browser`|Disable opening browser for authentication.|
|`--query`|<b>`string`</b><br/>Query to select values from the response using jq syntax|
|`-h`,`--help`|Display help for the command.|
