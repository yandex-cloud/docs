# Возможные проблемы

Эксплуатация и реагирование на экстренные ситуации.

## Проблемы синхронизации часов {#clock_issues}

При недостаточной синронизации часов на узлах может происходить замедление выполнения транзакций на величину расхождения времени, могут происходить слишком раннее или позднее срабатывание дедлайнов.
При расхождении времени больше чем на 30 секунд перестают выполняться транзакции над данными.

Увидеть расхождение времени между узлами можно в отчете соединений.

## Проблемы планирования мощностей {#capacity_planning_issues}

При планировании мощностей вы можете столкнуться со следующими проблемами:

* полная утилизация CPU может быть причиной ухудшения производительности;

* полная утилизация ОЗУ на узле вызывает Linux ООM или использование swap, что приводит к потере работоспособнсти или падению производительости;

* использование 100% места на диске может приводить к невозможности использования этого диска;

* выполнение большого количества операций чтения/записи на блочных устройствах может приводить ухудшению времени выполнения запросов вплоть до полной остановки;

* работа с сильно загруженной сетью может приводить ухудшению времени выполнения запросов вплоть до полной остановки.

YDB позволяет следить за состоянием системы при помощи таких метрик как:

* **CPU Usage** — суммарное потребление CPU на всех узлах. (1'000'000 = 1CPU);

* **Memory Usage** — потребление оперативной памяти по узлам;

* **Disk Space Usage** — потребление дискового пространства по узлам;

* **SelfPing** — наибольшее за интервал измерений фактическое время доставки отложенных сообщений в актор-системе. Измеряется для сообщений с отложенной на 10 мс доставкой. Рост данной величины может быть признаком мироберстов нагрузки, высокой утилизации cpu, вытесения процесса YDB с ядер процессора другими процессами.

## Проблемы с дисковой подсистемой {#storage_issues}

При исчерпании места на дисках база данных может отвечать ошибками на все запросы. Для сохранения работоспособности рекомендуется удалить часть данных или расширить кластер блочными устройствами.

Ниже приведены инструкции которые могут помочь добавить или освободить место на дисках.

### Дефрагменировать вдиск

В ходе эксплуатации возникает внутренняя фрагментация вдиска. Узнать степень фрагментации можно на странице мониторинга вдиска. Дефрагментация дисков, фрагментированных на 20 и менее процентов не рекомендуется.

По модели отказа кластер переживает потерю двух вдисков одной группы без потери данных. Если в группе все вдиски работоспособны, нет вдисков в состоянии ошибки или репликации, удаление данных с одного из вдисков приведет к восстановлению вдиском данных в компактном виде. Следует понимать, что избыточность хранения данных будет снижена до завершения автоматической репликации данных.

В процессе репликации данных нагрузка на все вдиски группы будет увеличена, возможно ухудшение времени отклика.

1. Посмотреть коэффициент фрагментации на странице вдиска во вьювере (ссылка).

   Если значение превышает 20%, то дефрагментация позволит освободить место на диске.

2. Проверить состояние группы в которую входит вдиск. В группе не должно быть недосупных вдисков, вдисков в состоянии ошибки или репликации.

    Посмотреть состояние группые можно во вьювере (ссылка).

3. Выполнить команду wipe для вдиска.

    Все данные хранимые вдиском будут необратимо удалены, после чего вдиск начнет восстанавливать данные читая их с остальных вдисков группы.

    ```bash
    kikimr admin blobstorage group reconfigure wipe --domain <Номер домена> --node <ID узла> --pdisk <ID ПДиска> --vslot <Номер слота>
    ```

    Посмотреть нужную информацию для команды можно во вьювере (ссылка).

В случае заканчивающегося места на блочном устройстве, можно применить дефрагментацию на все устрйоство.

1. Проверить состояние групп в кластере. Не должно быть проблемных групп которые находятся на том же узле, что и проблемное устройство.

1. Зайти по ssh на узел где находится этот диск

1. Проверить, можно ли перезапустить процесс (ссылка на файл maintanence)

1. Остановить процесс

    ```bash
    sudo systemctl stop kikimr
    ```

1. Форматировать диск

    ```bash
    sudo kikimr admin blobstorage disk obliterate <путь до партлейбла устройства>
    ```

1. Запустить процесс

    ```bash
    sudo systemctl start kikimr
    ```

### Разложить вдиски равномерно по устройствам

В случае, если вдиски расположены на блочных устройствах не равномерно, можно [перевезти их](#moving_vdisks) по одному с перегруженных устройств.

### Распределить нагрузку равномерно по группам

(добавить инструкцию про хайв и перевоз групп через хайв)

## Проблемы с оперативной памятью {#memory_issues}

Если процесс на узле отказал без сообщений об ошибках в логах, то возможно он отказал из-за ООМ.

Проверить это можно, наприер, зайдя на хост и выполнив команду

```bash
sudo dmesg -Е | grep -iC 3 "kikimr"
```

Если предположение об ООМ верное, то можно будет увидеть сообщение следующего вида.

```bash
[<Дата и время>] Out of memory: Kill process <Процесс> (kikimr) score <scope> or sacrifice child
```

Историю потребления памяти можно посмотреть на дашборде "General/sample dashboard" в "Memory Usage"

## Проблемы с репликацией {#replication_issues}

Репликация данных инициируется вдиском при его запуске и установлении соединения с другими вдисками группы.
Вдиск опрашивает соседей по группе и формирует представление о данных, которые он должен хранить. Все данные, которые вдиск должен хранить, но по какой-либо причине не хранит, вдиск реплицирует с других вдисков группы.

В мониторинге узлов, вдиски выполняющие репликацию окрашиваются в синий цвет.

В некоторых случаях при недоступности или неработоспособности части вдисков группы ранее удаленные с части вдисков данные может быть невозможно корректно идентифицировать как требующие удаления на осталвшихся вдисках до восстановления работоспособности и доступности всех вдисков группы. В этих случаях процесс репликации не завершится до восстановления работоспособности всех вдисков группы.

## Проблемы работоспособности кластера {#cluster_liveness_issues}

### В группе перестали работать сразу 2 диска {#storage_group_lost_two_disk}

По модели отказа потери данных не происходит при отсутствии 2 вдисков. Но любой следующий отказ уже угрожает потерей данных.

1. По возможности вернуть один из дисков, после чего перевезти второй вдиск.

2. Если один из дисков может вернуться спустя час, а на другом данные навсегда потерены, то лучше начать перевозить вдиск без данных.

3. В случае если на двух дисках данные потеряны, рекомендуется заменить сначала один диск, дождаться окончания репликации и после этого заменить второй.

### В группе перестали работать сразу 3 диска или больше {#storage_group_lost_three_disk}

Доступность и работоспособность системы может быть нарушена. Необходимо восстановить работоспособность хотя бы одного из дисков без потери хранившихся на нем данных.
