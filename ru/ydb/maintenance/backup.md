## Важная информация. Перед тем как начинать бекап. {#important-information-before-starting-backup}
MR.1. Бекап можно сделать только для datashards.

MR.2. Бекап рекомендуется делать только для копии таблицы, так как процесс бекапа останавливает исполнение других транзакций над таблицей.

MR.3. Бекап способен вызвать затруднения в работе сервиса, куда копируется бекап.

MR.4. Бекап может использовать много меж-ДЦ трафика.

MR.5. Бекап влияет на производительность любых других операций на кластере.

MR.6. Бекап имеет только один flow-control - одновременно бекапится 2 datashards на ноде. 2 - настройка по-умолчанию, эта настройка может быть изменена в конфигурации кластера.

MR.7. Бекап делает бесконечное количество попыток, пока не завершится успешно (если в команде бекапа не указано иное).

MR.8. Инкрементального бекапа нет.

MR.9. После того как бекап завершен, важно проверить корректность бекапа доступными средствами.

## Пошаговый TODO {#step-by-step-todo}
Пусть у вас есть кластер kikimr с названием big_kikimr. Пусть у вас есть таблица `/Root/deduper/Data`. Пусть вы хотите сделать бекап этой таблицы.

_TODO.1._ Поместите в файл copy-deduper.proto команду копирования исходной таблицы, например, вот с таким содержимым:
```
ModifyScheme {
    WorkingDir : '/Root/deduper'
    OperationType : ESchemeOpCreateTable
    CreateTable : {
        Name : 'Data.copy.2017-05-22'
        CopyFromTable: '/Root/deduper/Data'
    }
}
```
_TODO.1.NOTE.1._ Добавьте в название новой копии метаинформацию, которую можно использовать для понимания содержимого таблицы. Например, полезно добавить дату и время создания копии.

_TODO.2._ Запустите создание копии:
```
$ /path/to/kikimr -s kikimr0202.search.yandex.net db schema execute copy-deduper.proto
```
kikimr0202.search.yandex.net - это одна из машинок кластера big_kikimr. Пробуфные команды вы можете отправлять на любую из машинок кластера.

_TODO.2.NOTE.1._ Копирование таблицы это распределенная транзакция, которая исполняется на всех даташардах условно одновременно. Во время исполнения этой транзакции могут быть трудности в обработке полезной нагрузки на ваш кластер.
_TODO.2.NOTE.2._ При копировании таблицы фактического копирования данных не происходит. Условно, вы можете считать, что создаётся консистентный снепшот состояния базы данных.
_TODO.2.NOTE.3._ Консистентность скопированных данных гарантируется только для тех даташардов, которые затронуты командой копирования таблицы (см. copy-deduper.proto).

_TODO.3._ Используя вьюер (http://kikimr0202.search.yandex.net:8765/viewer/), убедитесь, что таблица зарегистрирована в системе.

_TODO.4._ Закажите квоту на одном из кластеров yt. Получите токен, для работы с кластером. На странице https://wiki.yandex-team.ru/yt/gettingstarted/ есть краткое описание того, как начать работу с yt. На странице http://locke.yt.yandex.net/auth/ можно получить токен для работы с yt.

_TODO.5._ Выберете название таблицы, в которой вы хотите разместить бекап. Убедитесь, что такой таблицы не существует. Например,
`//home/kikimr/percolator/DataBackup-2017-05-22`.
_TODO.5.NOTE.1._ Разместите метаинформацию в названии таблицы (см. TODO.1.NOTE.1.)

_TODO.6._ Поместите в файл backup-deduper.proto команду запуска бекапа, например, с таким содержимым:

<span style="color:red;">WARNING: в поле Token нужно записать свой token</span>
```
ModifyScheme {
    WorkingDir: '/Root/deduper'
    OperationType: ESchemeOpBackup
    Backup: {
        TableName: 'Data.copy.2017-05-22'
        BackupToYTSettings: {
            BrokerHost: 'hahn.yt.yandex.net'
            BrokerPort: 80
            DestinationTablePattern: '<append=true>//home/kikimr/percolator/DataBackup-2017-05-22'
            Token: 'QQIUH-Asdsalkdjfal-fdiudsfldjsf'
        }
    }
}
```
_TODO.7._ Используя описание схемы во вьюере kikimr, создайте в yt таблицу со схемой, например, этой командой:
```
$ yt create table //home/kikimr/percolator/DataBackup --recursive --attributes '{schema = [{name = UrlHash1; type = uint64}; {name = UrlHash2; type = uint64}; {name = Rank; type = uint64}; {name = SimHash; type = uint64}; {name = GroupSimHash; type = uint64}; {name = HostTitleHash; type = uint64}; {name = Version; type = uint64}]; optimize_for = scan}'
```
Note: собрать ((https://wiki.yandex-team.ru/yt/userdoc/forbeginners/ YT command line tool)) можно так
```
$ ya make --checkout contrib/python/yt/bin/yt
```
_TODO.8._ Убедитесь, что созданная вами таблица существует.

_TODO.9._ Запустите бекап следующей командой:
```
$ /path/to/kikimr -s kikimr0202.search.yandex.net db schema execute backup-deduper.proto
```
_TODO.10._ Откройте график в соломоне https://solomon.yandex-team.ru/?project=kikimr&cluster=kikimr_big&service=tablets&l.host=cluster&l.subsystem=store_to_yt&l.sensor=Bytes&graph=auto&b=1h&e= , и наблюдайте, как происходит прогресс бекапа. На графике отображается скорость передачи данных в yt.

_TODO.11._ По завершении бекапа, убедитесь, что в системе завершена транзакция бекапа. Откройте ссылку http://kikimr0202.search.yandex.net:8765/tablets/db?TabletID=72075186232623600&TableID=2 и убедитесь, что в системе нет активных схемных транзакций, то есть в таблице на странице нет записей.

_TODO.12._ Доступными вам методами, убедитесь, что система скопировала все данные корректно. Степень достаточной уверенности в корректности бекапа вы выбираете сами.

## Бекап внутри работает примерно так {#backup-inside-works-like-this}
- Бекап запускает схемную распределённую транзакцию над таблицей. В этой транзакции участвуют schemeshard и все datashard таблицы. Бекап сохраняется в процессе исполнения транзакции.
- datashard создаёт объект TBackupScan, в который помещает все найстройки бекапа
- При запуске исполнения бекапной схемной транзакции datashard отправляет в Compaction Broker запрос на запуск бекапа в очереди бекапа. По умолчанию, брокер позволяет исполняться 2-ум бекапам на одной ноде.
- Когда брокер отправляет даташарду ответ, что тот может начать бекап
- Даташард собирает все парты с данными пользотельской таблицы в TTableCompactionRequest.
- Даташард создаёт FullScan актор в батч-пуле с ссылкой на TTableCompactionRequest
- FullScan актор инициализует старт бекапа в TBackupScan, итерируется по всем записям в даташарде и передаёт каждую запись в TBackupScan
- TBackupScan создаёт актор THTTPStreamToYTActor, который по http присоединяется к yt-прокси
- TBackupScan трансформирует записи в yson, и блоками по несколько килобайт передаёт их в THTTPStreamToYTActor
- Если в одном из акторов произошла ошибка, то сообщение об ошибке отправляется в даташард, и там принимается решение либо сделать повторную попытку, либо закончить копирование бекапа.
