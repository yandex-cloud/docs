PQ-таблетка – специализированная таблетка на базе [KV-таблетки](tablet_key_value.md), реализующая абстракцию персистентной очереди и предназначенная для хранения данных [LogBroker over KiKiMR](https://wiki.yandex-team.ru/logbroker/persistent-queue/).

### Назначение PQ-таблетки
PQ-таблетка – это надстройка над KV-таблеткой, имеющая свою специфичную бизнес-логику. PQ-таблетка обеспечивает надёжное сохранение данных и метаданных и защиту от повторной записи SeqNo. Подтверждения успешной записи данных (и вообще ответы на модифицирующие запросы) производятся только после успешной надёжной записи в BlobStorage через KV-интерфейс. Операции, требующие изменения нескольких блобов, производятся транзакционно. Каждая таблетка обслуживает несколько партиций, принадлежащих одному топику LogBroker'a. PQ-таблетка состоит из актора KV-таблетки и отдельных акторов для каждой партиции, которые обрабатывают пользовательские запросы.

Все таблетки, живущие на конкретной ноде, используют общий кэш блобов, [описанный тут](https://wiki.yandex-team.ru/logbroker/persistent-queue/persqueue-node-cache/).

### Организация и формат данных
Устройство:

* каждый `sourceId` целиком лежит в одной партиции,
* на одной таблетке живёт несколько партиций,
* каждая партиция живёт целиком на одной таблетке,
* внутри партиции сообщения имеют сквозную нумерацию по полю `offset`, возрастающую по порядку записи.
* `offset` первого сообщения в партиции может быть любым; при удалении старых сообщений из очереди (с начала очереди - меньшего `offset`) оставшиеся сообщения не перенумеровываются,
Каждое клиентское сообщение однозначно идентифицируется двумя уникальными парами: идентификатором в рамках SourceId (SourceId, SeqNo) и идентификатором в рамках партиции (PartId, offset), содержащей его SourceId.

Данные хранятся в блобах, которые надёжно сохраняются в KV-хранилище. Блобы одной партиции строго упорядочены по ключам. Каждый блоб содержит некоторое количество последовательно идущих сообщений одной партиции. Ключ блоба содержит номер партиции в топике, номер первого сообщения в блобе и количество сообщений в блобе. Каждый блоб содержит только последовательные сообщения из одной партиции. Алгоритм компакшена объединяет последовательно идущие блобы так, чтобы максимально приблизить их размер к 8Mb (константа определяется устройством BlobStorage). В результате данные партиции логически делятся на две части: произвольно большое число последовательных «больших» блобов (близких к 8Mb) и небольшое число «маленьких» блобов («голова»). Суммарный размер блобов головы меньше 8Mb. Когда суммарный размер головы приближается к 8Mb, происходит компакшен головы (см. описание запроса на запись).

Кроме того, есть отдельные служебные ключи, содержащие максимальный seqNo успешно записанного сообщения данного sourceID, и Offset, по которому это сообщение находится.

При сбоях восстанавливается состояние обработчиков партиций по данным в KV-таблетке.

Состояние обработчика партиции состоит из:

* метаинформации (StartOffset и EndOffset партиции, сколько всего байт занято и т.д.)
* списка больших блобов 
* содержимого блобов с головы
* мапа SourceId->{MaxSeqNo, offset}
* Флага состояния [idle|writing]

PQ-таблетка получает клиентские запросы, преобразует их в запросы к конкретным обработчикам партиций и перенаправляет им запросы. Далее описана обработка запросов записи и чтения конкретным обработчиком партиции. (Более детально ((/logbroker/persistent-queue/backend-api API взаимодействия LogBroker и PQ-таблетки описано тут)).)

### Запрос на запись

* Запрос на запись добавляется во входящую очередь
* Если обработчик находится в состоянии Idle, то он переходит к записи, иначе запись начнется автоматически после завершения текущей и перехода в состояние Idle
* Обработчик достает из входящей очереди порцию клиентских сообщений (батч), добавляет их к голове. EndOffset не сдвигается, таким образом параллельные чтения эти данные пока не видят. Если среди сообщений есть те, у которых `SeqNo` меньше `SourceId->MaxSeqNo`, эти записи отбрасываются (**дедупликация**).
* если голова превысила PartitionConfig.LowWatermark (дефолт – 6Мб), происходит компакшен головы: создаётся новый большой блоб, содержащий данные всех блобов головы – или, если сразу пришло больше 8Мб, то несколько блобов, кратных 8Мб, а остаток формирует новую голову (один маленький блоб),
* в противном случае батч записывается новым блобом в голову,
* Формируется батч-команда к KV-таблетке на запись:

  * записать свежесозданные блобы,
  * удалить старые блобы головы, если голова компактилась,
  * записать новые MaxSeqNo в метаданные тех SourceId, в которые происходила запись.

* Переходит в состояние Writing и ждет выполнения команды KV-таблеткой.
* Команда применятся транзакционно - все записи/удаления применятся только вместе. 
* Проверяется результат: 
  * если все ок, то подтверждает запись клиентам, изменяет свое состояние (добавляет новый большой блоб к состоянию, изменяет голову и EndOffset - теперь данные могут быть прочитаны); 
  * если нет - откатывает изменения (удаляет конец головы) и отвечает клиенту ошибкой. Все остальные запросы на запись во входящей очереди также фейлятся: там могут быть записи по тем же SourceId, и если они запишутся, то только что зафейленные уже никогда не могут быть записаны, т.к. дедупликация запрещает писать с меньшим SeqNo.

* Продолжает обработку входящей очереди, если она не пустая, или переходит в состояние Idle.

Если последовательно идущие батчи имеют размер `N * 8Mb + delta`, где `LowWatermark <= delta < 8Mb`, то по этому алгоритму они сразу записываются в большие блобы и не подвергаются компакшенам. LogBroker буферизирует данные на своей стороне и присылает их батчами подходящего размера, так что при достаточно большом потоке входящих данных в системе LogBroker + KiKiMR компакшенов практически не происходит.

Если же, наоборот, данные приходят очень маленькими порциями, в таблетке включаются дополнительные уровни компакшена, чтобы количество блобов в голове всегда было небольшим.

### Запрос на чтение

* По запросу формируется набор больших блобов для чтения и кэшируется затрагиваемая часть головы
* Большие блобы запрашиваются у KV-таблетки или достаются из кэша.
* Когда все блобы получены, ответ формируется и отправляется клиенту.

Данные становятся доступными на чтение только после записи в KV-таблетку. Это гарантирует, что на запрос на чтение по одному и тому же offset всегда будут одни и те же данные (за исключением ошибок чтения).

Старые данные удаляются в соответствии с политиками хранения данных, настроенными для топика (по времени или по факту прочтения сконфигурированными "важными клиентами"). Метаинформация по SourceId удаляется, когда в партиции не остаётся данных, принадлежащих этому SourceId (простая проверка, что offset, соответствующий max_seqno из данного SourceId, стал меньше, чем StartOffset партиции).

### Переполнение партиций

Поскольку политики хранения данных исключают произвольное удаление данных, объём данных в партиции может сильно вырасти. Если партиция переполнилась, она отвечает соответствующей ошибкой на любую попытку записи. Переполнение может произойти в двух случаях:

* превышены лимиты по количеству или объёму сообщений, указанные в конфиге топика,
* диски BS-группы, на которой живёт таблетка, физически близки к переполнению.

В обоих случаях место может через какое-то время освободиться: если важные клиенты прочитают данные или пройдёт время, указанное в настройках (во втором случае также можно перевезти таблетку на другую BS-группу). Также проблема может быть решена на стороне конечного клиента сменой SourceId и, соответственно, партиции.

### Управление PQ-таблетками

PQ-таблетки создаются не напрямую, а через создание в [SchemeShard-е](tablet_schemeshard.md) особой сущности PersQueue group, соответствующей топику в Логброкере. В конфигах PQ group указывается количество партиций, а количество таблеток неявным образом вычисляется из количества партиций. Интерфейс SchemeShard позволяет увеличивать количество партиций в группе (и тогда создаются новые таблетки), а уменьшать их не позволяет.