Диагностика Кластера
===

Эксплуатация и реагирование на экстренные ситуации.

## Проблемы аутентификации

При запуске кластера в docker'е безо всего, база данных работает без авторизации.

## Проблемы синхронизации часов

При недостаточной синронизации часов на узлах можно наблюдать замедление выполнения транзакций на величину расхождения времени.
Так же могут происходить слишком раннее или позднее срабатывание дедлайнов.
При расхождении времени больше чем на 30 секунд перестают выполняться дата транзакции.

Чтобы увидеть на сколько сильно время расходится между узлами можно посмотреть в отчете соединений.

## Проблемы планирования мощностей

Здесь указаны несколько ввозможных проблем с которыми вы можете столкнуться во время планирования мощностей:

* Полная утилизация CPU может быть причиной ухудшения производительности

* Полная утилизация оперативной памяти на узле вызывает Linux ООM или использование swap, что в результате приводит к ухудшению производительности и работоспособности.

* Использование 100% памяти предоставляемым хранилищем может приводить к отказу работы системы в целом

* Упирание в операции чтения/записи на блочных устройствах приводит ухудшению времени обслуживания

* Работа с полностью загруженной сетью может приводит к плохому времени реакции между базой данных и клиентом

В Grafana можно смотреть на дашборд "General/sample dashboard" для планирования.

В нем отображены следующие метрики:

* **CPU Usage** - суммарное потребление CPU по всем пулам на всех узлах. (1'000'000 = 1CPU)

* **Memory Usage** - потребление оперативной памяти по узлам.

* **Disk Space Usage** - потребление дискового пространства по узлам.

* **SelfPing** - показывает насколько хорошо чувствует себя акторсистема.

    В случае резких изменений может показывать об остром голодании по cpu или вытесении с ядер другими процессами.

## Проблемы с дисковой подсистемой

При достижении лимита использования ресурсов база данных может начать отвечать ошибками на все запросы. В данном случае надо экстренно удалить не нужные данные либо расширить кластер блочными устрйоствами.

Ниже приведены инструкции которые помогут краковременно освободить память и дать время для принятия решений.

### Wipe отдельного VDisk'а

1. Убедиться что данный вдиск не находится в группе где уже есть -1

2. Зайти на любой узел кластера

3. Выполнить команду

    ```bash
    ./Berkanavt/kikimr/bin/kikimr admin blobstorage group reconfigure wipe --domain <domain-num> --node <node-num> --pdisk <pdisk-num> --vslot <vslot-num>
    ```

### Неожиданно стало заканчиваться место (форматирование диска)

1. Определить диск с наибольшим заполнением места

2. Зайти на узел где находится этот диск

3. Проверить, разрешит ли cms перезапусить процесс

    ```bash
    /Berkanavt/kikimr/bin/kikimr cms request restart host {node_id} --user {user} --duration 60 --dry --reason 'format disk'
    ```

    При разрешение выведет `ALLOW`

4. Остановить процесс

    ```bash
    sudo systemctl stop kikimr
    ```

5. Форматировать диск

    ```bash
    sudo /Berkanavt/kikimr/bin/kikimr admin blobstorage disk obliterate <disk-partlabel>
    ```

6. Запустить процесс

    ```bash
    sudo systemctl start kikimr
    ```

### Неожиданно стало заканчиваться место и форматирование не помогло

1. Найти самые большие вдиски на пдисках с заканчивающейся памятью

2. Зайти на любой узел кластера

3. Выполнить перевоз диска

    ```bash
    ./Berkanavt/kikimr/bin/kikimr admin bs config invoke --proto 'Command { ReassignGroupDisk { GroupId: <groupId> GroupGeneration: <groupGeneration> FailRealmIdx: <failRealmIdx> FailDomainIdx: <failDomainIdx> VDiskIdx: <vdiskIdx> } }'
    ```

## Проблемы с оперативной памятью

Если узел упал без сообщений об ошибках в логах, то возможно он упал из-за ООМ.

Чтобы проверить надо зайти на хост упавшего узла и посмотреть команду

```bash
sudo dmesg -Е | grep -iC 3 "kikimr"
```

Если предположение об ООМ верное то можно будет увидеть сообщение следующего вида.

```bash
[<datetime>] Out of memory: Kill process <process> (kikimr) score <scope> or sacrifice child
```

Историю потребления памяти можно посмотреть на дашборде "General/sample dashboard" в "Memory Usage"

## Проблемы с репликацией

Репликация начинается во время старта вдиска.
Вдиск спрашивает соседей по группе о данных, которые должны были хранится у него.
Если вдиск не находит у себя каких-то данных, то он старается их восстановить.

В мониторинге узлов, вдиски с репликацией окрашиваются в синий цвет.

В некоторых случаях при отсутствии вдиска могут появиться фантомные блобы.
Это блобы которые могли бы быть восстановлены если в отсутствующем диске хранится недостающая часть данных.
Такие ситуации решаются возвращением диска, либо перевозом сломанного вдиска в случае если вы уверены в непревышении модели отказа.

## Проблемы работоспособности узлов кластера

### SelfHeal

В процессе работы кластеров могут выходить из строя отдельные блочные устройства, на которых работает ydb, либо узлы целиком. Для сохранения работоспособности и отказоустойчивости кластера в условиях, когда оперативная починка вышедших из строя узлов или железок невозможна, используется механизм SelfHeal.

Механизм SelfHeal работает из двух частей. Детектирование неисправных дисков и перевоз их в щадящем режиме не допуская потери данных и развала групп хранения.

По умолчанию SelfHeal включен.  
Ниже инструкция по включению в случае если он выключен, аналогично SelfHeal можно выключить.

1. Включение детектирования

    Открыть сртраницу

    ```http://localhost:8765/cms#show=config-items-25```

    Можно включить через viewer -> Cluster Management System -> CmsConfigItems

    Поле Status: Enable

    Или через cli

    * Составить файл с измененными конфигами

        Пример файла config.txt

        ```bash
        Actions {
            AddConfigItem {
                ConfigItem {
                    UsageScope {
                        TenantAndNodeTypeFilter {
                            Tenant: "<tenant>"
                        }
                    }
                    Config {
                        CmsConfig {
                            SentinelConfig {
                                Enable: true
                            }
                        }
                    }
                }
            }
        }
        ```

    * Обновить конфиг на кластере

        ```bash
        kikimr -s <endpoint> admin console configs update config.txt
        ```

3. Включение перевоза

    ```bash
    kikimr -s <endpoint> admin bs config invoke --proto 'Command{EnableSelfHeal{Enable: true}}'
    ```

### Перевезти вдиски со сломанного/отсутствующего устройства

В случае если SelfHeal выключен или не перевозит вдиски, данную операцию придется выполнить вручную.

1. Убедиться в мониторинге, что диск действительно в нерабочем состоянии.  

    Записать fqdn узла, ic-port, путь до диска, pdiskId

2. Зайти на любой узел кластера

3. Выполнить перевоз диска

    ```bash
    ./Berkanavt/kikimr/bin/kikimr admin bs config invoke --proto 'Command { UpdateDriveStatus { HostKey: { Fqdn: "<fqdn>" IcPort: <ic-port>} Path: "<partlabel-path>" PDiskId: <pdiskId> Status: BROKEN } }'
    ```

### Заменили/починили диск, нужно его вернуть в работу

1. Убедиться в мониторинге, что диск в рабочем состоянии  

    Записать fqdn узла, ic-port, путь до диска, pdiskId

2. Зайти на любой узел кластера

3. Вернуть диск

    ```bash
    ./Berkanavt/kikimr/bin/kikimr admin bs config invoke --proto 'Command { UpdateDriveStatus { HostKey: { Fqdn: "<fqdn>" IcPort: <ic-port>} Path: "<partlabel-path>" PDiskId: <pdiskId> Status: ACTIVE } }'
    ```

### Отсутствует узел больше часа

Выполнить перевоз каждого диска этого узла.

### Обноление кластера

(уточнить у Максима)

### Замена оборудования

Так же убедится в возможности вывода узла через CMS.  
При длительном отсутствии стоит перед этим перевезти вдиски с данного узла и дождаться окончания репликации.

### В группе перестал работать 1 диск

В основном такими ситуациями занимается SelfHeal.  
SelfHeal перевозит диски спустя 1 час неработоспособности.
В случае если SelfHeal не работает или выключен то стоит развести вдиски со сломанного диска.

### В группе перестали работать сразу 2 диска

По моделе отказа потери данных не происходит при отсутствии 2 вдисков. Но любой следующий отказ уже угрожает потерей данных.

1. По возможности вернуть один из вдисков, и попытаться перевезти отсутствующий.

2. Если один из дисков может вернуться спустя час, а на другом данные навсегда потерены, то стоит начать перевозить вдиск без данных.

3. В случае если данные потеряны у двух дисков, то следует развести сначала один диск, дождаться окончания репликации и после этого перевозить другой.

### В группе перестали работать сразу 3 диска

Случилась катастрофа, произошла потеря данных. Нужно срочно возвращать диски для восстановления работоспособности.

## Использование мониторинга для диагностирования кластера

### Страница всех узлов кластера

```
http://<endpoint>:8765/monitoring/cluster/nodes
```

На ней можно увидеть:

* nodeId
* адрес хоста
* прослушиваемые порты
* версия
* аптайм
* использование оперативной памяти
* загруженность пуллов в акторсистеме
* загруженность хоста по CPU

### Страница списка тенантов

```
http://<endpoint>:8765/monitoring/cluster/tenants
```

Кликнув на теннант можно перейти на его страницу в котором представлена подробная информация.

### Страница корневого тенанта

```
http://<endpoint>:8765/monitoring/tenant/healthcheck?name=/root
```

Страница корневого тенанта, показывает состояние всей системы

Имеет несколько основных вкладок:

1. **HealthCheck** - показывает сообщения о проблемах кластера в случае их наличия.
2. **Storage** - список групп хранения, показывает какие вдиски на каких узлах и устройствах работают.
3. **Compute** - список вычислительных ресурсов, показвает схожую информацию как и список всех узлов, но к дополнению к это показывает таблетки живущие на узлах.
4. **Schema** - схема базы, просмотр таблицы, выполнение YQL запросов, проосмотр самых медленных запросов.
5. **Network** - состояние сети кластера.

### Отчет об состояния соединений между нодами

```
http://<endpoint>:8765/actors/interconnect/overview
```

Показывает для каждого другого узла:

* пинг
* разницу системных часов
* наличие соединения
* последняя зарегистрированная ошибка

## Логи

### Details

Все логи выводятся (уточнить у Максима)

### Logging channels

Существуют следующие уровни логгирования

| Уровень | Значение
|---|--------|
| TRACE | Очень детальная отладочная информация
| DEBUG | Отладочная информация для разработчиков
| INFO | Отладочная информация для сбора статистики/информации
| NOTICE | Произошло существенное для системы или пользователя событие
| WARN | Предупреждение, если носит не временный характер то стоит реагировать и исправлять
| ERROR | Некритическая ошибка
| CRIT | Критическое состояние
| ALERT | Система как минимум деградировала. Возможно какой-то компонент вышел из строя
| EMERG | Системой пользоваться нельзя, кластер отказал |
