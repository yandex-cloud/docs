На каждом узле KiKiMR работает HTTP-мониторинг (порт по умолчанию 8765).
Индексная страница может содержать следующие ссылки:

 * **Counters** -- счетчики для Соломона, туда смотреть не надо, это уходит в Соломон
 * **Actors** -- страницы мониторинга акторов, запущенных на узле (PDisk, VDisk, BlobstorageProxy)
 * **NALF-alloc stats** -- статистика NALF аллокатора, туда скорее всего смотреть не надо
 * **MessageBus** -- страница мониторинга MessageBus
 * **Version** -- вывод команды kikimr -V
 * **Tracing** -- управление LWTrace https://wiki.yandex-team.ru/development/poisk/arcadia/library/lwtrace/
 * **Tablets** -- системные таблетки кластера
 * **Node Tablet Monitor** -- узлы кластера и все замеченные на этих узлах таблетки

## Проверка состояние кластера

G1. Выбрать первый попавшийся узел, зайти на его страницу HTTP мониторинга.

Например: http://lbk01h.search.yandex.net:8765

Если мониторинг на узле не отвечает, изучать логи KiKiMR на узле, искать VERIFY, сегфолты (`grep 'VERIFY\|SIGSEG' /Berkanavt/kikimr/logs/kikimr.start`, если найдено, вероятно, найдена ошибка в коде KiKiMR), проверять, не убивал ли KiKiMR oom-killer, убедиться, что KiKiMR вообще пытается запускаться на узле и т.д.


G2. Зайти в /Tablets/HIVE/ и посмотреть на Uptime

Если страница не открывается, возникли какие-то проблемы при запуске Hive (или он просто не успел загрузиться). Перейти к пункту H1.

Если Uptime подозрительно маленький, обновить страницу, убедиться, что Hive не рестартует. Если Hive рестартует, смотреть логи Hive на этом узле (`grep HIVE /Berkanavt/kikimr/logs/kikimr.debug` и `grep 72057594037968897 /Berkanavt/kikimr/logs/kikimr.debug` где 72057594037968897 - TabletId Hive, который можно видеть в файле настроек boot.txt).


G3. Зайти в /Tablets/HIVE/App, посмотреть на Uptime подключенных к Hive узлов, убедиться, что все узлы подключены к Hive (неподключенные - серого цвета).

Если узлы не подключены к Hive, вероятно, KiKiMR на узлах не работает или проблемы с сетью. Проверить, запущен ли там KiKiMR и работает ли сеть между узлом, на котором запущен Hive (NodeID в /Tablets/HIVE), и узлом, не подключившимся к Hive.


G4. Зайти в /Tablets/HIVE/App, посмотреть, все ли таблетки запущены (Tablets: 100%, внимательно посмотреть на цифры справа), убедиться, что в таблице ниже в колонках Unknown и Starting только нули.

Если не все таблетки запущены, но постепенно запускаются, вероятно, система еще не развернулась после (пере)запуска или идет процесс перезапуска таблеток после каких-то проблем.

Если таблетки скачут из состояния Starting в Running и обратно, вероятно, у них какие-то проблемы и они рестартуют. Стоит посмотреть логи на узле со скачущими таблетками. Если таблетки пишут об ошибке Blob Storage в логе и известен идентификатор GroupID группы blob storage с проблемами, перейти к пункту D1.

Если все хорошо, то с большой вероятностью кластер в полном порядке и все работает как надо.


H1. Hive мог не стартовать из-за проблем Blob Storage. Нужно убедиться, что работает достаточное для выбранного режима erasure количество узлов kikimr  (можно пройти по списку ссылок в /Node Tablet Monitor).

Если мониторинг ноды не отвечает - см. пункт G1


H2. Посмотреть на файл конфигурации статической части Blob Storage (bs.txt), там должны быть перечислены все PDisk-и и VDisk-и, входящие в состав статической группы. Пройти по страницам мониторинга этих PDisk-ов /Actors/PDisks/PDisk00XXX где XXX - номер PDisk-а на страницах мониторинга соответствующих узлов. Посмотреть на Current State (таблица из колонок Component / State), убедиться, что PDisk имеет состояние Normal. Пройти по страницам мониторинга соответствующих VDisk-ов /Actors/VDisks/VDisk00XXX_00000 где XXX - номер PDisk-а. Посмотреть на таблицу из колонок Component / State (на панельке Skeleton), убедиться, что Skeleton в состоянии Normal и DbLocalRecovery в Done.

Если PDisk показывает, что он загружен, а VDisk-и читают лог, можно посмотреть, как много чанков лога всего необходимо вычитать (панелька Log Chunk Details, количество строк = количество чанков лога). За прогрессом вычитки лога можно следить глядя на значения sensor=YardReadLogResults и sensor=YardReadLogs.

D1. Зайти на страницу /Tablets/BS_CONTROLLER и посмотреть на Uptime

Если страница не открывается, возникли какие-то проблемы при запуске Blob Storage Controller (или он просто не успел загрузиться). Перейти к пункту H1, заменяя по смыслу Hive на Blob Storage Controller.

Если Uptime подозрительно маленький, обновить страницу, убедиться, что BSController не рестартует. Если BSController рестартует, смотреть на узле, на котором запущен BSController (NodeID в /Tablets/BS_CONTROLLER) логи BSController (`grep BS_CONTROLLER /Berkanavt/kikimr/logs/kikimr.debug` и `grep 72057594037932033 /Berkanavt/kikimr/logs/kikimr.debug` где 72057594037932033 - TabletID BSController, который можно видеть в файле настроек boot.txt).

D2. Зайти в /Tablets/BS_CONTROLLER/App, посмотреть на списки дисков и групп. Для проблемной группы найти перечень входящих в ее состав дисков вида 
```
[{[n1p5v10]}{[n2p11v10]}{[n3p17v10]}{[n4p23v10]}{[n5p29v10]}{[n6p35v10]}{[n7p41v10]}{[n8p47v10]}] 
```
и посетить их страницы мониторинга на соответствующих узлах. Формат записи: n номер-узла p номер-pdisk v номер-слота. Для каждой записи - выполнить пункт H2.
