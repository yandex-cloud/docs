Актор - минимальная сущность, в рамках которой может быть написан пользовательский код.


#### Мотивация и модель 

Современные базы данных - запутанный гетерогенный программный комплекс, отдельные части которого действуют независимо, взаимодействуют асинхронно, должны эффективно и прогнозируемо утилизировать доступные ресурсы - как отдельной массивно-многопроцессорной машины, так и кластера из сотен и тысяч узлов. Что ставит вопрос - а в какой собственно парадигме необходимо разрабатывать код, так что бы при таких вводных сохранить разум разработчиков.

С точки зрения производительности - выбрана модель явного message-passing-а, а в качестве реализации - акторы с возможностью явного выделения конечного автомата и поакторным mailbox. Библиотека затачивалась под разработку KiKiMR, но в конечном результате получилось сбалансированное, эффективное решение, которое можно смело рекомендовать как базу для построения сложных асинхронных программ, особенно настоятельно - если логика программы не укладывается в фиксированный линейный pipeline.

#### Сообщения и ActorID 

Единица работы актора - обработка одиночного сообщения из ??входящей очереди??.

В рамках обработки сообщения которого актор может:

  * изменить собственное состояние (условно - помодифицировать структуры).
  * изменить функцию реакции на следующее ??событие??.
  * послать сообщение другому актору, адрес которого ему известен.
  * создать новый актор.
  * умереть (только сам актор может решить умереть, невозможно убить актор снаружи).
  * взаимодействовать с внешней средой (например, передать обработку сторонней библиотеке).

Для актора гарантируется обработка не более одного события одновременно (т.е. с точки зрения отдельного актора - обработка однопоточная) и упорядоченность обработки (любое сообщение отправленное позже завершения отправки предыдущего - не будет обработано в обратном порядке).

Адресуются акторы с помощью структуры `TActorID`. С точки зрения внешнего наблюдателя - это адрес, который используется для адресации актора. Назначается при регистрации нового актора в ??акторсистеме?? (и никогда не должен создаваться пользователем "из-воздуха"). Внутри содержит несколько полей:

  * `node-id` - число-номер ноды, на котором запущен данный актор. Может использоваться пользователем для определения локальности/расположения удаленного адресата (необходимо, например, при взаимодействия с подписками интерконнекта нод для детектирования ??разрывов??).
  * `local-id` - уникальное в рамках ноды число. Назначается при регистрации актора и не переиспользуется в рамках той же ноды. Обычно не нужна пользователю, но может использоваться вместо ??полного адреса?? для идентификации локальных акторов. Послать сообщение зная только node-id и actor-id невозможно. ??Сообщение можно послать зная...??
  * `hint` - используется актор-системой для нахождения mailbox, к которому привязан актор (фактически - индекс в двухмерном массиве всех выделенных на ноде mailbox). Может переиспользоваться системой, для пользователя не несёт никакого смысла и не должна использоваться.

В комплексе - ??actor-id?? является глобально уникальным в рамках одной инсталляции actorlib (local-id - уникален в рамках ноды, добавление node-id делает его глобально уникальным).

Актору собственный actor-id передается в каждом вызове обработки сообщения (как часть структуры `TActorContext`), так же actor-id новосозданного актора возвращается из функции регистрации актора (таким образом владелец актора может запомнить его для дальнейшего взаимодействия или идентификации).

#### ServiceID 

Особый случай - это адреса ??сервисов??. Фактически - это тот же actor-id, но сформированный по особому правилу - вместо уникального local-id используется ??заданная?? бинарная строка длиной 12 байт. Вместе с node-id это позволяет адресовать сервисы в кластере, а при использовании специально node-id равного 0 - адресовать локальные сервисы, недоступные с других нод.

Строго говоря - service-id не является actor-id-ом, т.к. к нему не привязан никакой актор, но можно зарегистрировать (при создании акторсистемы или во время работы) трансляцию в фактический actor-id. Логика обработки следующая - при посылке по service-id, если node-id указан ненулевой и несоответствующий текущей ноде - сообщение форвардится на интерконнект, если же нулевой или соответствующий текущей ноде - выполняется поиск в таблице локальных зарегистрированных сервисов и при нахождении - адрес получателя перезаписывается с исходного service-id на фактический actor-id. Такая трансляция осуществляется не более одного раза (т.е. нельзя зарегистрировать service-id как другой service-id).

Основное предназначение - связывание сервисов. Например таким образом осуществляется доступ к локальным проксям блобстораджа, стейтстораджа.

#### Сообщения и мейлбоксы 

Актор-система оперирует объектами `IEventHandle`, которые уже внутри содержат:

  * actorid адресата.
  * actorid отправителя.
  * число типа event.
  * число флагов event.
  * неинтерпретируемое число-cookie.
  * объект-наследник IEventBase или буфер с сериализованным сообщением.

При посылке сообщения по actor-id адресата находится mailbox, к которому привязан искомый актор (с возможной перезаписью если исходный actorid является serviceid) или для нелокальных actor-id-ов - соответствующий ??актор интерконнекта??. Сообщение (инстанс IEventHandle) помещается во входящую очередь mailbox, а id mailbox, если уже не активирован, помещается в ??очередь активации??.

При несуществовании запрошенного mailbox (или невозможности разыменовать service-id) - сообщение или выбрасывается, или

  * если выставлено правило форварда - переадресуется указанному актору
  * иначе если выставлен флаг отслеживания доставки - сообщение выбрасывается и отправителю отсылается сообщение-нотификация о недоставке от имена адресата.
  * иначе сообщение просто выбрасывается.

Фактическая обработка event произойдет позже, когда рабочий поток thread pool акторсистемы извлечёт сообщение из очереди. Будет совершена попытка найти на mailbox привязанный актор с требуемым local-id (его может не быть если к моменту обработки сообщения актор уже умер) и при нахождении - вызвана текущая установленная функция обработки сообщений. При ненахождении - логика обработки аналогична логике обработки ненайденного мейлбокса.

Существует возможность регистрации на один mailbox нескольких акторов. Сделать это можно только находясь внутри обработки сообщения актором и только на собственный mailbox. Созданные таким образом акторы разделяют общий mailbox, для них правило однопоточной обработки расширяется до всех акторов на одном mailbox (и как следствие - становятся возможными прямые вызовы между акторами, при сохранении раздельных уникальных адресов для посылки/отправки сообщения). ??Вот тут не очень понятно. Расширяется. Все акторы могут работать одновременно или в один момент времени работает один из акторов???

При создании актора можно выбрать на каком типе mailbox будет создан актор. На данный момент доступно два типа

  * Simple (`TMailboxType::EType::Simple`) - максимально облегченный mailbox, оптимизированный под минимальную цену посылки сообщения при отсутствии contention.
  * Revolving (`TMailbox::EType::Revolving`) - гарантирующий wait-free добавление сообщения в очередь ценой большей стоимости посылки/чтения. Следует использовать если предполагается существенный трафик на mailbox от лица разных отправителей.

В обоих типах mailbox писатели и читатель разведены и никогда не блокируют друг друга.

В рамках одной ноды сообщения не сериализуются и передаются as-is, как поле Event хендла. При необходимости межнодовой передачи - сообщение сериализуется в интерконнекте вызовом виртуальной функции IEventBase::Serialize. Десериализация буфера в сообщение акторсистемой никогда не производится, при необходимости - это должен осуществить принимающий актор определив тип сообщения по полю Type хендла. Рекомендуемый способ - использовать макросы HFunc, CFunc и иже с ними из actorlib/hfunc.h и определить статическую функцию Load.

#### Декларация ивентов и назначение идентификатора типа 

Непосредственно сама актор-система не накладывает ограничений на способ декларации ивента (кроме того что он должен быть наследником IEventBase) или назначение чиселки Type. Но удобно выделить для семейства ивентов диапазон непересекающихся с соседями идентификаторов (см. макросы EventSpaceBegin/EventSpaceBegin и их применение в коде). Для самых распространенных случаев реализовано два хелпера

  * TEventLocal из actorlib/event_local.h - для событий, которые не должны покидать одну ноду, не определяют функции сериализации.
  * TEventPB из actorlib/event_pb.h - для событий, тело которых определено как protobuf-message. Основной метод для потенциально меж-нодового трафика.
Для особых случаев возможна частная реализация, метод сериализации никак не ограничивается со стороны библитеки.

#### Тред-пулы 

Сами акторы - это пассивная сущность, выполнение обеспечивается запуском обработки сообщений в контексте рабочих тредов тредпула. Каждый мейлбокс (а с ним - и актор) привязан к конкретному тредпулу и не может мигрировать в процессе жизни (но можно из актора одного тредпула создать актор на соседнем тредпуле). Возможны разные варианты реализации, в имеющейся - количество тредов задаётся при старте и не меняется в процессе жизни, обработка активаций условно упорядочена (примерно одновременно активированные мейлбоксы будут примерно одновременно обработаны), привязки мейлбоксов к тредам выполнения не осуществляется и мейлбоксы не приоритезируются. Возможны другие реализации.

Больше одного тредпула необходимо создавать при существенном перекосе характера нагрузки, например длительные batch-операции необходимо отселять в отдельный пул от rt-like запросов.

Базовый (basic-) тредпул позволяет настраивать количество работающих тредов и время которое поток проводит в активном ожидании работы, прежде чем уснуть.

#### Шедулер 

Важным для реализации эффективного асинхронного кода является работа с временем и задержками. В акторлибе шедулинг сообщений реализован через отложенную посылку сообщений. Основной сценарий - зашедулить посылку сообщения таймаута самому себе. Из коробки возможности отменить посылку сообщения нет (из соображений производительности), но возможно проигнорировать сообщение (в том числе и заранее, см. ISchedulerCookie).