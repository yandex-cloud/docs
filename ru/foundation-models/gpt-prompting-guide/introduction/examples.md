# Примеры промтов

В этом разделе мы рассмотрим больше примеров использования промтов для выполнения различных задач с помощью {{ yagpt-name }} и познакомимся с ключевыми концепциями. Часто лучший способ изучить концепции — это пройти через примеры. Примеры ниже иллюстрируют, как можно использовать хорошо продуманные промты для более продуктивной работы с моделью {{ yagpt-name }}.

Типы задач, которые мы разберем на этой странице:

* [Краткий пересказ текста](#text-summarization)
* [Извлечение информации](#information-extraction)
* [Ответы на вопросы](#question-answering)
* [Классификация текста](#text-classification)
* [Разговор](#conversation)
* [Логические рассуждения](#reasoning)

## Краткий пересказ текста {#text-summarization}

Одной из стандартных задач в области генерации естественного языка является краткий пересказ, или суммаризация текста. Суммаризация текста может охватывать множество различных форматов и областей. Одним из самых перспективных применений языковых моделей является возможность суммаризовать статьи и концепции в быстрые и легкие для чтения резюме. Попробуем выполнить базовую задачу суммаризации с помощью промтов:

**Промт**

```text
Антибиотики — это тип лекарств, используемых для лечения бактериальных инфекций. Они работают, убивая бактерии или предотвращая их размножение, что позволяет иммунной системе организма бороться с инфекцией. Антибиотики обычно принимаются внутрь в виде таблеток, капсул или жидких растворов, а иногда вводятся внутривенно. Они не эффективны против вирусных инфекций, и их неправильное использование может привести к устойчивости к антибиотикам.

Объясни вышеуказанное в одном предложении:
```

**Ответ**

```text
Антибиотики — это лекарства, используемые для лечения бактериальных инфекций, убивая бактерии или предотвращая их размножение, но они не эффективны против вирусов, и их чрезмерное использование может привести к устойчивости к антибиотикам.
```

Модель попыталась суммаризовать абзац в одно предложение. Попробуйте поэкспериментировать с инструкциями, чтобы улучшить результаты.

## Извлечение информации {#information-extraction}

Хотя языковые модели обучены выполнять задачи генерации естественного языка и связанные с ними задачи, они также способны выполнять классификацию и ряд других задач обработки естественного языка (natural language processing, NLP). Рассмотрим промт, который извлекает информацию из текста:

**Промт**

```text
В заявлениях об авторском вкладе и благодарностях в научных статьях следует четко и конкретно указывать, использовали ли авторы и в какой степени технологии ИИ, такие как YandexGPT, при подготовке своей рукописи и анализа. Они также должны указывать, какие LLM использовались. Это позволит редакторам и рецензентам более тщательно проверять рукописи на предмет возможных предвзятостей, неточностей и неправильного указания источников. Аналогично, научные журналы должны быть прозрачны в отношении использования LLM, например, при выборе представленных рукописей.

Укажите продукт на базе большой языковой модели, упомянутый в абзаце выше:
```

**Ответ**

```text
Продукт на базе большой языковой модели, упомянутый в абзаце выше, — это YandexGPT.
```

Существует множество способов улучшить результаты выше, но даже такие простые запросы могут решить множество задач.

## Ответы на вопросы {#question-answering}

Один из лучших способов заставить модель отвечать на конкретные вопросы — улучшить формат промта. Это можно сделать с помощью[элементов](elements.md) промта, которые сочетают инструкции, контекст, ввод и индикаторы вывода для получения улучшенных результатов. Они не являются обязательными, но позволяют значительно конкретизировать инструкции для модели. Например:

**Промт**

```text
Ответьте на вопрос на основе приведенного ниже контекста. Держите ответ коротким и лаконичным. Ответьте "Не уверен в ответе", если не уверены в ответе.

Контекст: Теплизумаб берет свое начало в фармацевтической компании Ortho Pharmaceutical в Нью-Джерси. Там ученые создали раннюю версию антитела, названную OKT3. Изначально полученное от мышей, это молекула могла связываться с поверхностью Т-клеток и ограничивать их способность убивать клетки. В 1986 году оно было одобрено для предотвращения отторжения органов после пересадки почки, став первым терапевтическим антителом, разрешенным для использования у людей.

Вопрос: Откуда изначально было получено OKT3?
```

**Ответ**

```text
От мышей.
```


## Классификация текста {#text-classification}

До сих пор вы использовали простые инструкции, которых будет недостаточно для сложных случаев. Для задач классификации могут понадобиться конкретные примеры:

**Промт**

```text
Классифицируйте текст как нейтральный, негативный или позитивный.

Текст: Я думаю, что еда была нормальной.
Настроение:
```

**Ответ**

```text
Нейтральное
```

Модель ответила верно, но предположим, что мы хотим получить ответ со строчной буквы. Существует несколько способов сделать это. Важна конкретность, поэтому чем больше информации вы можете предоставить в промте, тем лучше результаты. Попробуем добавить в запрос пример:

**Промт**

```text
Классифицируйте текст как нейтральный, негативный или позитивный.

Текст: Я думаю, что отпуск был нормальным.
Настроение: нейтральное

Текст: Я думаю, что еда была нормальной.
Настроение: 
```

**Ответ**

```text
нейтральное
```

На этот раз модель вернула конкретную метку «нейтральное». Приведенный пример помог модели быть конкретной в своем ответе.

## Разговор {#conversation}

Одной из самых интересных вещей, которые вы можете достичь с помощью промт-инжиниринга, является указание системе LLM, как себя вести, каковы ее намерения и идентичность. Это особенно полезно при создании разговорных систем, таких как чат-боты для обслуживания клиентов.

Например, создадим разговорную систему, которая способна генерировать более технические и научные ответы на вопросы. Обратите внимание, как через инструкцию модели задается нужный стиль ответов. Это иногда называют *ролевым промтингом*. Например:

**Промт**

```text
Следующий диалог происходит с ИИ-ассистентом по исследованиям. Тон ассистента технический и научный.

Человек: Привет, кто ты?
ИИ: Приветствую! Я ИИ-ассистент по исследованиям. Как я могу помочь вам сегодня?
Человек: Можешь рассказать мне о создании черных дыр?
ИИ:
```

**Ответ**

```text
Конечно! Черные дыры — это области пространства-времени, где гравитационная сила настолько сильна, что ничто, даже свет, не может из нее вырваться. Они образуются, когда очень массивная звезда умирает и ее ядро коллапсирует, образуя сингулярность бесконечной плотности. Интенсивная гравитация сингулярности притягивает всю материю и излучение вокруг нее, создавая черную дыру.
```

Если полученные ответы кажутся слишком сложными, можно попробовать их упростить:

**Промт**

```text
Следующий диалог происходит с ИИ-ассистентом по исследованиям. Ответы ассистента должны быть понятны даже ученикам начальной школы.

Человек: Привет, кто ты?
ИИ: Приветствую! Я ИИ-ассистент по исследованиям. Как я могу помочь вам сегодня?
Человек: Можешь рассказать мне о создании черных дыр?
ИИ:
```

**Ответ**

```text
Конечно! Черные дыры образуются, когда очень массивная звезда заканчивает свое топливо и коллапсирует. Гравитация звезды настолько сильна, что ничто, даже свет, не может вырваться из ее притяжения. Это создает точку в пространстве-времени с интенсивной гравитационной силой, называемую черной дырой.
```

Заметен прогресс. Если вы добавите больше примеров, вы можете получить результаты.

## Логические рассуждения {#reasoning}

Одними из самых сложных задач для LLM сегодня являются те, которые требуют какой-либо формы рассуждений. Логические рассуждения — одна из самых интересных областей из-за типов сложных приложений, которые могут возникнуть из LLM. Существующие модели до сих пор испытывают трудности с выполнением задач, требующих рассуждений, поэтому это требует еще более [продвинутых техник](llm-settings.md) инженерии промтов. Рассмотрим базовый пример из арифметики:

**Промт**

```text
Нечетные числа в этой группе складываются в четное число: 15, 32, 5, 13, 82, 7, 1.

**Ответ**
```text
Нет, нечетные числа в этой группе складываются в нечетное число: 119.
```

Модель ответила неверно. Попробуем улучшить промт дополнительной инструкцией:

**Промт**

```text
Нечетные числа в этой группе складываются в четное число: 15, 32, 5, 13, 82, 7, 1.

Решите, разбив проблему на шаги. Сначала определите нечетные числа, сложите их и укажите, является ли результат четным или нечетным.
```

**Ответ**

```text
Нечетные числа: 15, 5, 13, 7, 1
Сумма: 41
41 — нечетное число.
```

Теперь ответ верный, но модель все еще может ошибиться на других примерах. Если вы предоставите подробные инструкции в сочетании с примерами, это может помочь получить более точные результаты.

#### См. также {#see-also}

* [{#T}](./llm-settings.md)
* [{#T}](../../prompts/yandexgpt/index.md)