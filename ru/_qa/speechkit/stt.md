# Распознавание речи (STT)

#### Некорректные ударения и произношение {#stt-stress-pronunciation}

Создайте обращение и приложите примеры, чтобы разработчики могли внести корректировки к следующим релизам модели синтеза.


#### Плохое качество распознавания при 8кГц {#at-8khz}

Если проблема систематическая (десятки процентов от общей доли запросов), создайте обращение и приложите примеры для исследования. Чем больше примеров вы пришлете, тем вероятнее разработчики обнаружат проблему.


#### Форма обратной связи по качеству распознавания {#feedback}



При возникновении проблем обратитесь в [службу поддержки]({{ link-console-support }}) с файлами и описанием.


#### Шумы, гудки, тишина воспроизводится как странная речь {#strange-speech}

Попробуйте использовать [другую модель](../../speechkit/stt/models.md#tags) распознавания, например, `general:rc`. Для потокового распознавания есть [настройка](../../speechkit/stt/api/streaming-api.md#additional-settings), уменьшающая чувствительность распознавания фонового шума.


#### Два канала распознались в один / Как распознать каждый канал отдельно {#two-channels}

Проверьте формат вашей записи.

Для LPCM используйте параметр [config.specification.audioChannelCount](../../speechkit/stt/api/transcribation-api.md#sendfile-params) равный 2.

Указывать параметр для OggOpus не нужно, поскольку информация о количестве каналов содержится в файле. Файл автоматически распределится на две записи.

Распознанный текст в ответе разделяется параметром [channelTag](../../speechkit/stt/api/transcribation-api.md#get-result-response).

#### Можно ли распознавать 2 и более голосов с разделением на дикторов? {#separate-speaker}

Во время распознавания текст не разделяется по голосу, но вы можете разместить голоса в разных каналах и разделить распознанный текст в ответе параметром [channelTag](../../speechkit/stt/api/transcribation-api.md#get-result-response).

Количество каналов можно указать в запросе с помощью параметра [config.specification.audioChannelCount](../../speechkit/stt/api/transcribation-api.md#sendfile-params).

#### Неполное распознавание аудио {#incomplete}

Если вы распознаете потоковое аудио, попробуйте использовать разные версии API: [API v1](../../speechkit/stt/api/streaming-api.md) или [API v3](../../speechkit/stt-v3/api-ref/grpc/). 

Для распознавания аудиофайлом попробуйте разные [модели](../../speechkit/stt/models.md).


#### Файл короче чем лимит, но при распознавании возникает ошибка {#multi-channel-limits}

Если файл многоканальный, то учитывайте суммарное время записи всех каналов. С деталями вы можете ознакомиться в документации в разделе [Квоты и лимиты в {{ speechkit-short-name }}](../../speechkit/concepts/limits.md#speechkit-limits).

#### Ошибка Internal Server Error {#internal-server-err}

Убедитесь, что [формат](../../speechkit/stt/api/request-api.md#body_params), указываемый в запросе, и реальный формат файла соответствуют друг другу. Если ошибку исправить не получается, пришлите нам примеры аудиофайлов, которые не удается распознать.

#### Когда высылается ответ при распознавании? {#when-response}

При синхронном и асинхронном распознавании ответ присылается один раз — после обработки запроса.

При потоковом режиме распознавания вы можете настроить поведение сервера. По умолчанию сервер возвращает ответ только после распознавания всей переданный фразы. С помощью параметра [partialResults](../../speechkit/stt/api/streaming-api.md#specification-msg) можно настроить распознавание так, чтобы сервер возвращал также и промежуточные результаты распознавания.

Получение промежуточных результатов позволит быстрее реагировать на распознаваемую речь, не дожидаясь окончания фразы.

#### Пример скрипта для распознавания аудиофайлов {#script}

Примеры асинхронного распознавания файлов в форматах [LPCM](../../speechkit/stt/api/transcribation-lpcm.md) и [OggOpus](../../speechkit/stt/api/transcribation-ogg.md) доступны в документации.

#### Можно ли использовать POST для потокового распознавания? {#post}

Потоковое распознавание работает только через API gRPC, использовать POST не получится.

При использовании [заголовка](../../speechkit/stt/api/request-api.md#http_request) `Transfer-Encoding: chunked` во время синхронного распознавания можно присылать аудиопоток, не закрывая текущее соединение.

#### Обрывается / завершается сессия потокового распознавания {#broken-session}

Если сервис [потокового распознавания](../../speechkit/stt/streaming.md#session-restrictions) не получает данные для распознавания в течение 5 секунд, сессия обрывается. Этот параметр изменить нельзя.

Потоковое распознавание работает в режиме реального времени. Вы можете отправлять на распознавание «тишину», чтобы сервис не закрыл соединение.

#### Как определяется конец фразы и длительность сессии распознавания {#utterance-end}

Конец фразы определяется по «тишине» после фразы автоматически.

[Максимальная длительность сессии](../../speechkit/stt/streaming.md#session-restrictions) — 5 минут.

#### Ошибка OutOfRange desc = Exceeded maximum allowed stream duration {#duration-exceeded}

Эта ошибка означает, что превышена максимально допустимая длительность сессии распознавания.

Для потокового распознавания [максимальная длительность сессии](../../speechkit/concepts/limits.md#speechkit-limits) — 5 минут.

Это техническое ограничение, обусловленное особенностями архитектуры {{ yandex-cloud }}, изменить его нельзя.

#### Из чего складывается стоимость использования? {#stt-cost}

Примеры расчета стоимости использования, правила тарификации и актуальные цены смотрите в [документации](../../speechkit/pricing.md).
