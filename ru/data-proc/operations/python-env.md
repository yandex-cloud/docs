# Подготовка и использование виртуальных окружений Python

При использовании PySpark в кластере {{ dataproc-name }} часто бывает нужно установить или обновить пакеты Python. При этом изменение основного окружения Python в кластере может оказаться слишком трудоемким и нецелесообразным. В качестве альтернативы при запуске каждого задания можно использовать изолированные виртуальные окружения:

1. [Подготовьте виртуальное окружение](#prepare).

    Для обеспечения совместимости подготовка виртуального окружения выполняется на временном кластере {{ dataproc-name }}. Затем виртуальное окружение помещается в архив, который сохраняется в бакете {{ objstorage-name }}.

1. [Используйте виртуальное окружение](#launch) из архива при запуске заданий в кластерах {{ dataproc-name }}.

    Виртуальное окружение Python можно использовать:

    * [При обычном запуске PySpark-заданий](#launch-common).
    * [При запуске PySpark-заданий в кластере {{ dataproc-name }}, интегрированного с {{ ml-platform-full-name }}](#launch-datasphere).
    * [При запуске PySpark-заданий в ноутбуке Zeppelin](#launch-zeppelin).

## Подготовка виртуального окружения Python {#prepare}

1. Если у вас нет сервисного аккаунта с ролью `dataproc.agent`, [создайте](../../iam/operations/sa/create.md) его.
1. В {{ objstorage-name }} [создайте бакет](../../storage/operations/buckets/create.md) для хранения логов кластера и архива с виртуальным окружением.
1. [Настройте ACL](../../storage/operations/buckets/edit-acl.md) бакета, предоставив сервисному аккаунту с ролью `dataproc.agent` разрешение `READ и WRITE`.
1. [Создайте](./cluster-create.md) временный кластер {{ dataproc-name }}. При создании укажите:

    * Версию {{ dataproc-name }}, такую же, как у кластера, на котором планируется использовать окружение. Это необходимо для обеспечения совместимости.
    * Компоненты:
        * `SPARK`;
        * `YARN`.
    * Бакет для хранения логов.
    * Сервисный аккаунт с доступом к бакету.
    * (Опционально) Публичный доступ к подкластеру с управляющим хостом.

    Настройки ресурсов хостов рекомендуется указать минимальными.

1. [Подключитесь по SSH](./connect.md#data-proc-ssh) к временному кластеру {{ dataproc-name }}.
1. Запустите встроенный инструмент [Virtualenv](https://spark.apache.org/docs/latest/api/python/user_guide/python_packaging.html#using-virtualenv) для работы с виртуальными окружениями:

    ```bash
    python -m venv pyspark_venv && \
    source pyspark_venv/bin/activate
    ```

1. Установите `venv-pack` и другие необходимые вам модули окружения Python:

    ```bash
    pip install venv-pack <список модулей>
    ```

    Пример:

    ```bash
    pip install venv-pack pyarrow pandas catboost
    ```

1. Упакуйте сформированное окружение в архив с помощью команды `venv-pack`:

    ```bash
    venv-pack -o <имя архива>.tar.gz
    ```

1. Отправьте архив с окружением в подготовленный ранее бакет {{ objstorage-short-name }}:

    ```bash
    hdfs dfs -copyFromLocal <имя архива>.tar.gz s3a://<имя бакета>/
    ```

1. [Удалите](./cluster-delete.md) временный кластер {{ dataproc-name }}, чтобы за него не списывалась плата.

## Использование виртуального окружения {#launch}

Чтобы использовать подготовленное виртуальное окружение в кластере {{ dataproc-name }}, предоставьте сервисному аккаунту кластера доступ на чтение из бакета, в котором хранится архив. Это можно сделать двумя способами:

* [Отредактируйте ACL бакета](../../storage/operations/objects/edit-acl.md), выдав сервисному аккаунту кластера права на чтение (`READ`).
* [Назначьте](../../iam/operations/roles/grant.md#access-to-sa) сервисному аккаунту роль `storage.viewer`.

### Использование виртуального окружения при обычном запуске PySpark-заданий {#launch-common}

При [создании задания PySpark](https://cloud.yandex.ru/docs/data-proc/operations/jobs-pyspark#create) укажите следующие значения для [свойств Spark](https://spark.apache.org/docs/latest/configuration.html) на уровне задания:

* `spark.submit.deployMode=cluster` — режим размещения драйвера.

    Запуск заданий должен выполняться в режиме `cluster`, чтобы виртуальное окружение было правильно подготовлено. Подробнее о режиме размещения драйвера см. в разделе [{#T}](../concepts/spark-sql.md#resource-management).

* `spark.yarn.dist.archives='s3a://<имя бакета>/<имя архива>.tar.gz#<псевдоним>'` — путь к архиву с подготовленным окружением.

    После символа `#` укажите псевдоним окружения, он может быть любым. Псевдоним будет служить именем подкаталога, в который будет распакован архив.

* `spark.yarn.appMasterEnv.PYSPARK_PYTHON=./<псевдоним>/bin/python` — переопределение команды запуска интерпретатора Python для процесса YARN Application Master.
* `spark.yarn.appMasterEnv.PYSPARK_DRIVER_PYTHON=./<псевдоним>/bin/python` — переопределение команды запуска интерпретатора Python для драйвера задания.

В результате входящие в состав виртуального окружения зависимости будут доступны при выполнении задания.

### Использование виртуального окружения в интеграции кластера {{ dataproc-name }} с {{ ml-platform-full-name }} {#launch-datasphere}

Интеграция {{ ml-platform-full-name }} и {{ dataproc-name }} основана на использовании компонента [Apache Livy](https://livy.apache.org/) в составе {{ dataproc-name }}. Подробнее о настройке интеграции с {{ ml-platform-full-name }} см. в разделе [Интеграция с сервисом {{ ml-platform-full-name }}](../tutorials/datasphere-integration.md).

Чтобы использовать виртуальные окружения Python в интеграции с {{ ml-platform-full-name }}, выполните дополнительные настройки:

1. На стороне кластера {{ dataproc-name }} установите режим размещения драйвера `cluster`. Для этого при [изменении кластера](./cluster-update.md) передайте значение [свойства компонента](../concepts/settings-list.md) `livy:livy.spark.deploy-mode=cluster`.

    Подробнее о режиме размещения драйвера см. в разделе [{#T}](../concepts/spark-sql.md#resource-management).

1. На стороне сервиса {{ ml-platform-full-name }} [создайте сессию Livy](../../datasphere/concepts/data-proc.md#session) со следующими настройками:

    ```livy
    %create_livy_session \
        --cluster <кластер {{ dataproc-name }}> --id <ID сессии Livy> \
        --conf spark.yarn.dist.archives=s3a://<имя бакета>/<имя архива>.tar.gz#<псевдоним> \
        --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=./<псевдоним>/bin/python \
        --conf <прочие параметры контекста Spark> ...
    ```

    Где:

    * `<кластер {{ dataproc-name }}>` — имя или идентификатор используемого в интеграции кластера {{ dataproc-name }}.
    * `<ID сессии Livy>` — произвольная строка, идентификатор сессии Livy в рамках кластера.
    * `<имя бакета>` — бакет, в котором лежит архив с окружением.
    * `<имя архива>` — подготовленный архив с окружением Python.
    * `<псевдоним>` — псевдоним окружения, может быть любым. Псевдоним будет служить именем подкаталога, в который будет распакован архив.
    * `<прочие параметры контекста Spark>` задаются при необходимости. Полный список параметров приведен в [документации Spark](https://spark.apache.org/docs/latest/configuration.html#available-properties).

Укажите созданную сессию [при запуске кода Python в кластере](../../datasphere/concepts/data-proc.md#run-code). Зависимости, включенные в состав виртуального окружения, будут доступны для использования.

### Использование виртуального окружения в ноутбуке Zeppelin {#launch-zeppelin}

Чтобы использовать виртуальные окружения Python при работе в ноутбуке Zeppelin:

1. В интерфейсе Zeppelin перейдите в настройки интерпретатора (**Interpreter**) и отредактируйте блок **spark**, установив режим работы контекста Spark в значения `Per Note` и `Isolated`. Таким образом разные ноутбуки смогут задействовать разные виртуальные окружения.
1. Создайте новую ячейку `%spark.conf` и передайте в ней переменные для сессии Spark:

    ```spark
    %spark.conf
    spark.submit.deployMode cluster
    spark.yarn.dist.archives s3a://<имя бакета>/<имя архива>.tar.gz#<псевдоним>
    spark.yarn.appMasterEnv.PYSPARK_PYTHON ./<псевдоним>/bin/python
    spark.pyspark.python ./<псевдоним>/bin/python
    ```

    Где:

    * `spark.submit.deployMode cluster` — режим размещения драйвера.

        Запуск заданий должен выполняться в режиме `cluster`, чтобы виртуальное окружение было правильно подготовлено. Подробнее о режиме размещения драйвера см. в разделе [{#T}](../concepts/spark-sql.md#resource-management).

    * `spark.yarn.dist.archives 's3a://<имя бакета>/<имя архива>.tar.gz#<псевдоним>'` — путь к архиву с подготовленным окружением.

        После символа `#` укажите псевдоним окружения, он может быть любым. Псевдоним будет служить именем подкаталога, в который будет распакован архив.

    * `spark.yarn.appMasterEnv.PYSPARK_PYTHON ./<псевдоним>/bin/python` — переопределение команды запуска интерпретатора Python для процесса YARN Application Master.
    * `spark.pyspark.python ./<псевдоним>/bin/python` — переопределение команды запуска интерпретатора Python для драйвера задания.

    При выполнении следующей ячейки, использующей Spark (например, ячейки в режимах `%spark.pyspark` или `%spark.sql`) будет выполнено создание сессии Spark с указанными настройками. В этой сессии будут доступны зависимости, включенные в состав виртуального окружения.
