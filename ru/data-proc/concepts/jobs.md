# Задания в {{ dataproc-name }}

В кластере {{ dataproc-name }} можно создавать и выполнять задания (jobs). Это позволяет, например, на регулярной основе загружать набор данных из [бакета {{ objstorage-name }}](../../storage/concepts/bucket.md), использовать их в расчетах и формировать аналитику.

Поддерживаются задания следующих типов:

* [Hive](https://cwiki.apache.org/confluence/display/HIVE#Home-HiveDocumentation),
* [MapReduce](https://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html),
* [PySpark](https://spark.apache.org/docs/latest/api/python/index.html),
* [Spark](https://spark.apache.org/docs/latest/).

При создании задания указываются:

* _Аргументы_ — значения, используемые основным исполняемым файлом задания.
* _Свойства_ — пары <q>ключ:значение</q>, задающие настройки [компонентов образа](./environment.md).

Для размещения и [запуска задания](../operations/jobs.md):

* Воспользуйтесь интерфейсами {{ yandex-cloud }}. Подробнее см. в [базовых примерах](../solutions/job-overview.md#jobs-basic-tutorials) работы с заданиями.


* Подключитесь напрямую к узлу кластера. Подробнее см. пример в разделе [{#T}](../solutions/remote-run-job.md).

Для успешного выполнения задания:

* Предоставьте доступ к нужным бакетам {{ objstorage-name }} для сервисного аккаунта кластера.

    Рекомендуется использовать минимум два бакета:
    * Бакет с правами только на чтение для хранения исходных данных и файлов, необходимых для запуска задания.
    * Бакет с правами на чтение и запись для хранения результатов выполнения заданий. Укажите его при создании кластера.

* Передайте при создании задания все необходимые для его работы файлы.

Если в кластере достаточно вычислительных ресурсов, несколько созданных заданий будут выполняться параллельно. В противном случае из заданий будет сформирована очередь.

## Логи заданий {#logs}

Логи заданий сохраняются в сервисе {{ cloud-logging-full-name }}. Подробнее см. в разделе [{#T}](../operations/logging.md).
