# Взаимосвязь ресурсов сервиса {{ dataproc-name }}

Сервис {{ dataproc-name }} позволяет реализовать распределенное хранение и обработку данных с помощью сервисов из экосистемы [Apache Hadoop](http://hadoop.apache.org).

## Ресурсы

Основная сущность сервиса — _кластер_. Кластер объединяет все ресурсы, доступные Hadoop: вычислительные мощности и хранилище.

Каждый кластер состоит из _подкластеров_. Подкластеры объединяют _хосты_, выполняющие идентичные функции:

* Подкластер с управляющими хостами (например, NameNode для HDFS или ResourceManager для YARN).

  {% note info %}

  В каждом кластере может быть не больше 1 подкластера с управляющими хостами.

  {% endnote %}

* Подкластеры для хранения данных (например, DataNode для HDFS).
* Подкластеры для обработки данных (например, NodeManager для YARN).

Подкластеры каждого кластера должны находиться в одной [облачной сети](../../vpc/concepts/network.md#network) и в одной [зоне доступности](../../overview/concepts/geo-scope.md).

Хосты в каждом подкластере создаются с вычислительной мощностью, соответствующей указанному _классу хостов_. Список доступных классов хостов и их характеристики см. в разделе [{#T}](instance-types.md).

Виртуальные машины, соответствующие хостам кластера, могут размещаться:

* На _стандартных хостах_ {{ yandex-cloud }}.

    Это физические серверы для размещения виртуальных машин кластера. Такие хосты выбираются случайным образом из пула доступных хостов, удовлетворяющих выбранной конфигурации подкластеров.


* На _выделенных хостах_ {{ yandex-cloud }}.

    Это физические серверы для размещения исключительно ваших виртуальных машин. Эти виртуальные машины обеспечивают как работу кластера, так и работу других ваших сервисов, которые поддерживают выделенные хосты. Такие хосты выбираются из _групп выделенных хостов_, указанных при создании кластера.

    При таком варианте размещения обеспечивается физическая изоляция виртуальных машин. Кластер {{ dataproc-name }}, использующий выделенные хосты, обладает всеми возможностями обычных кластеров.

    Подробнее см. в [документации {{ compute-full-name }} по выделенным хостам](../../compute/concepts/dedicated-host.md).


О сетевой конфигурации и сетевом доступе к кластеру см. раздел [{#T}](network.md).

## Безопасность {#security}

Так как кластер Data Proc имеет функцию запуска заданий без непосредственного доступа к кластеру по SSH, то для удобства пользователя кластер пишет журнал выполнения заданий в S3-бакет. Запись в бакет происходит под сервисным аккаунтом, указанным во время создания кластера. Более подробно с концепцией можно ознакомиться на странице [Сервисные аккаунты](../../iam/concepts/users/service-accounts.md).

Для Data Proc кластера рекомендуется использовать хотя бы два разных S3 бакета:

1. Для исходных данных, где сервисный аккаунт имеет права только на чтение.
1. Для журналов и результатов операций — сервисный аккаунт имеет полный доступ.

Это необходимо для уменьшения рисков непредвиденных модификаций и удаления исходных данных.
