# Взаимосвязь ресурсов сервиса {{ dataproc-name }}

Сервис {{ dataproc-name }} позволяет реализовать распределенное хранение и обработку данных с помощью сервисов из экосистемы [Apache Hadoop](http://hadoop.apache.org).

## Ресурсы {#resources}

Основная сущность сервиса — _кластер_. Кластер объединяет все ресурсы, доступные Hadoop: вычислительные мощности и хранилище.

Каждый кластер состоит из _подкластеров_. Подкластеры объединяют _хосты_, выполняющие идентичные функции:

* Подкластер с управляющим хостом (`Мастер` или `masternode`). Например, NameNode для HDFS или ResourceManager для YARN.

  {% note info %}

  В каждом кластере может быть не больше одного подкластера с управляющим хостом.

  {% endnote %}

* Подкластеры для хранения данных (`Data` или `datanode`). Например, DataNode для HDFS.
* Подкластеры для обработки данных (`Compute` или `computenode`). Например, NodeManager для YARN.

Подкластеры каждого кластера должны находиться в одной [облачной сети](../../vpc/concepts/network.md#network) и в одной [зоне доступности](../../overview/concepts/geo-scope.md).

Хосты в каждом подкластере создаются с вычислительной мощностью, соответствующей указанному _классу хостов_. Список доступных классов хостов и их характеристики см. в разделе [{#T}](instance-types.md).



Виртуальные машины, соответствующие хостам кластера, могут размещаться:

* На _стандартных хостах_ {{ yandex-cloud }}.

    Это физические серверы для размещения виртуальных машин кластера. Такие хосты выбираются случайным образом из пула доступных хостов, удовлетворяющих выбранной конфигурации подкластеров.

* На _выделенных хостах_ {{ yandex-cloud }}.

    Это физические серверы для размещения исключительно ваших виртуальных машин. Эти виртуальные машины обеспечивают как работу кластера, так и работу других ваших сервисов, которые поддерживают выделенные хосты. Такие хосты выбираются из _групп выделенных хостов_, указанных при создании кластера.

    При таком варианте размещения обеспечивается физическая изоляция виртуальных машин. Кластер {{ dataproc-name }}, использующий выделенные хосты, обладает всеми возможностями обычных кластеров.

    Подробнее о выделенных хостах см. в [документации {{ compute-full-name }}](../../compute/concepts/dedicated-host.md).


О сетевой конфигурации и сетевом доступе к кластеру см. раздел [{#T}](network.md).

{% include [dedicated-hosts-edit-restrictions](../../_includes/data-proc/note-vm-edit-restrictions.md) %}

## Легковесные кластеры {#light-weight-clusters}

Начиная с [версии образа](./environment.md) `2.0.39` доступна легковесная (LightWeight) конфигурация кластера — без HDFS и подкластеров для хранения данных. Такие кластера могут включать в себя, например, только YARN и SPARK. Они создаются быстрее и эффективней используют вычислительные ресурсы хостов. Легковесные кластеры рекомендуются для запуска единичных заданий для обработки данных в Spark или PySpark.

Преимущества легковесных кластеров:

* Spark Driver запускается на подкластере с управляющими хостами. Это позволяет выдавать разные ресурсы для подкластера с управляющими хостами, где будет запущен Spark Driver, и подкластеров для обработки данных, где будут запущены Spark Executors.

* В обычных кластерах на каждом подкластере для обработки данных запускается как минимум по одному экземпляру Spark Driver и Spark Executor. В легковесных кластерах Spark Driver может использовать все свободные ресурсы подкластера с управляющими хостами, а Spark Executors — все свободные ресурсы подкластеров для обработки данных. Это повышает эффективность работы хостов.

Требования для использования легковесных кластеров:

* Не выбран компонент HDFS.
* В кластере не используются подкластеры для хранения данных.
* Кластер содержит один или несколько подкластеров для обработки данных.
* В настройках кластера указан бакет в {{ objstorage-full-name }}.

Подробнее о распределении ресурсов см. в разделе [Задания Spark](./spark-sql.md#resource-management).

## Безопасность {#security}

Так как кластер {{ dataproc-name }} имеет функцию запуска заданий без непосредственного доступа к кластеру по [SSH](../../glossary/ssh-keygen.md), то для удобства пользователя кластер пишет журнал выполнения заданий в S3-бакет. Запись в бакет происходит под сервисным аккаунтом, указанным во время создания кластера. Более подробно с концепцией можно ознакомиться на странице [Сервисные аккаунты](../../iam/concepts/users/service-accounts.md).

Для кластера {{ dataproc-name }} рекомендуется использовать хотя бы два отдельных бакета S3:

1. Для исходных данных, где сервисный аккаунт имеет права только на чтение.
1. Для журналов и результатов операций — сервисный аккаунт имеет полный доступ.

Это необходимо для уменьшения рисков непредвиденных модификаций и удаления исходных данных.
