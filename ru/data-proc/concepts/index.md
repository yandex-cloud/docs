# Взаимосвязь ресурсов сервиса {{ dataproc-name }}

Сервис {{ dataproc-name }} позволяет реализовать распределенное хранение и обработку данных с помощью сервисов из экосистемы [Apache Hadoop](http://hadoop.apache.org).

Основная сущность сервиса — _кластер_. Кластер объединяет все ресурсы, доступные Hadoop: вычислительные мощности и хранилище.

Каждый кластер состоит из _подкластеров_. Подкластеры объединяют _хосты_, выполняющие идентичные функции:

* Подкластер с управляющими хостами (например, NameNode для HDFS или ResourceManager для YARN).

  {% note info %}

  В каждом кластере может быть не больше 1 подкластера с управляющими хостами.

  {% endnote %}

* Подкластеры для хранения данных (например, DataNode для HDFS).
* Подкластеры для обработки данных (например, NodeManager для YARN).

Подкластеры каждого кластера должны находиться в одной облачной сети и в одной зоне доступности. [Подробнее о географии {{ yandex-cloud }}](../../overview/concepts/geo-scope.md).

Хосты в каждом подкластере создаются с вычислительной мощностью, соответствующей указанному _классу хостов_. Список доступных классов хостов и их характеристики см. в разделе [{#T}](instance-types.md).

О сетевой конфигурации и сетевом доступе к кластеру см. раздел [{#T}](network.md).

## Безопасность {#security}

Так как кластер Data Proc имеет функцию запуска заданий без непосредственного доступа к кластеру по SSH,
то для удобства пользователя кластер пишет журнал выполнения заданий в S3-бакет. Запись в бакет происходит
под сервисным аккаунтом, указанным во время создания кластера. Более подробно с концепцией можно ознакомиться на странице [Сервисные аккаунты](../../iam/concepts/users/service-accounts.md).

Для Data Proc кластера рекомендуется использовать хотя бы два разных S3 бакета:

1. Для исходных данных, где сервисный аккаунт имеет права только на чтение
2. Для журналов и результатов операций — сервисный аккаунт имеет полный доступ.

Это необходимо для уменьшения рисков непредвиденных модификаций и удаления исходных данных.
