---
title: Большая языковая модель (LLM)
description: Большая языковая модель (LLM) — это нейросеть, которая с помощью продвинутых алгоритмов и машинного обучения на больших текстовых данных способна решать различные текстовые задачи.
keywords:
  - LLM
  - Большая языковая модель
---

# Большая языковая модель (LLM)

Большая языковая модель (_Large language model, LLM_) — продвинутая вычислительная модель, способная анализировать и генерировать тексты на любую тематику. Она работает по принципу нейронных сетей и может образовывать сложные шаблоны и взаимосвязи между изученными языковыми данными.

## История возникновения LLM {#history}

Первые языковые модели появились еще в 1990-х годах и могли работать только над лексическим переводом, выравниванием порядка слов в предложениях и другими относительно несложными задачами. Работа над полноценными LLM началась в начале 2010-х годов, когда нейронные сети хорошо зарекомендовали себя в работе с изображениями.

Уже к 2016 году переводчик Google начал работать на основе нейронной сети. В 2017 году исследователи компании представили архитектуру [Transformer](https://ru.wikipedia.org/wiki/Трансформер_(модель_машинного_обучения)), которая легла в основу всех популярных LLM. В 2018 OpenAI создали GPT-1, но она не стала особо популярной. GPT-2, выпущенную годом позже, компания отказалась делать общедоступной из-за опасений по поводу ее злонамеренного использования.

К 2022 году OpenAI пересмотрела свое отношение и представила миру ChatGPT (GPT 3.5), которая стала первой большой языковой моделью, привлекшей огромное внимание. За следующие два года LLM проникли практически во все сферы бизнеса и науки.

## Виды LLM {#types}

Все наиболее популярные большие языковые модели базируются на архитектуре Transformer, но могут быть дополнительно настроены под конкретные задачи, например:

* GPT (Generative Pre-trained Transformer) — наиболее актуальные LLM для генерации текста. Имеют обширную область применения: [чат-боты](chat-bot.md), генерация рекламного контента, написание программ и другое.
* BERT (Bidirectional Encoder Representation Transformers) – модель, которая распознает текст как слева направо, так справа налево. Используется для генерации релевантной поисковой выдачи, переводов и других задач, завязанных на контекстуальном анализе текста.
* T5 (Text-to-Text Transfer Transformer) — модели, обученные преобразовывать один вид текстовых данных в другой. Например, системы машинного перевода и декодирования.

Не так давно начали появляться модели, основанные на новых архитектурах. Например, рекуррентные нейросети (RNN) и Mamba (модель пространства состояний), которые особенно хорошо справляются с последовательностями слов и событий и требуют меньше ресурсов.

## Принципы работы LLM {#how-work}

Большие языковые модели выполняют свои задачи за доли секунды, однако пользователи не видят, как сложно они устроены внутри. Разберем принцип работы LLM на простом примере:

1. **Запрос** — пользователь обращается к модели. Например, спрашивает: «Какая погода в Москве?»
1. **Токенизация** — модель разбивает запрос на [токены](../foundation-models/concepts/yandexgpt/tokens.md), что позволяет ей лучше понимать естественный язык. Например, {{ gpt-pro }} разобьет наш запрос на пять токенов: «Какая», «погода», «в», «Москве», «?».
1. **Векторизация** — токены преобразуются в векторы, называемые [эмбеддингами](../foundation-models/concepts/embeddings.md). Эти векторы отражают смысловое значение и контекст так, чтобы нейросеть могла применять к ним математические алгоритмы.
1. **Формулирование ответа** — модель пропускает эмбеддинги через многочисленные слои информации, то есть собственную базу знаний. Каждый слой помогает модели лучше понять написанное и дать наиболее точный ответ.
1. **Корректировка** — модель редактирует текст с учетом заложенных в нее фильтров. Например, убирает потенциально опасные призывы, нецензурные слова и прочее.
1. **Декодирование** — ответ модели преобразуется обратно в текст, чтобы человек смог его понять.

На такой простой запрос большинство LLM с легкостью даст релевантный ответ, однако даже самые мощные из них часто не справляются с более сложными запросами, если их плохо сформулировать. Для составления понятных машине запросов существует целая дисциплина — [проектирование _промтов_](../foundation-models/gpt-prompting-guide/about.md) (запросов).

Также пользователю часто доступны дополнительные параметры ответа, такие как его максимальная длина и _температура_. Второй параметр сообщает модели, насколько творчески она может подойти к задаче. С низкими значениями температуры LLM выдаст более детерминированный ответ, что подходит для фактических запросов, а с высокими — будет больше «фантазировать» и напишет, например, более удачную песню или сочинение.

## Примеры использования LLM в разных областях {#examples}

Большие языковые модели позволяют бизнесу автоматизировать многие процессы, повысить качество контента или эффективность работы многих специалистов. Разберем популярные сценарии их использования.

### Анализ настроения клиентов {#marketing}

Стриминговый сервис Netflix [использует](https://medium.com/@imteyazkashif8/using-llms-for-recommendation-systems-a-netflix-use-case-967c007dd173) LLM для формирования персональных рекомендаций контента. Алгоритмы анализируют отзывы пользователей на сайте и в соцсетях, а также их историю просмотров и оценок. Эти данные позволяют определить, какой контент будет наиболее интересен конкретному пользователю. Для обработки такого объёма информации вручную потребовалось бы привлечь тысячи сотрудников, LLM же нужно всего несколько минут. Модель запоминает даже то, какой контент более релевантен для пользователя в определенное время суток.

### Генерация описаний товаров {#content}

Компании Лемана ПРО (Леруа Мерлен) с помощью модели {{ yagpt-name }} [удалось](https://yandex.cloud/ru/blog/posts/2024/10/yandex-gpt-4-0) снизить стоимость написания карточек товаров для дома и ремонта в 95 раз. В ассортименте магазинов более 390 000 товаров, генерировать описания которых вручную — задача колоссального объема.

  Ритейлер также обращается к модели {{ yandexart-name }} для генерации медиаконтента. Модель может органично представить ту или иную вещь в разных интерьерах и экстерьерах, что помогает покупателям упростить выбор, а магазину — увеличить продажи.

### Автоматизация процесса обработки заказов {#sales}

Разработчик Макс Бродер-Урбас [поделился](https://betterprogramming.pub/placing-30-000-customer-orders-with-llms-f1f73872e2eb) опытом обработки более 30 000 ежегодных заказов компании по оптовой продаже алкогольной продукции с помощью LLM. Заказы осуществляются по электронной почте и каждый из них — отдельная головоломка, потому что нужно рассчитать скидку, проверить доступность товара на складе и добавить к заказу недостающую информацию.

Процесс был реализован в три этапа: обработка электронной почты, поиск недостающей для заказа информации и отправка нового письма с корректно оформленным заказом, который останется только принять. До внедрения LLM обработка заказов требовала времени множества сотрудников и была самым уязвимым местом компании для масштабирования.

### Общение с клиентами {#chat}

Производителю обуви Ralf Ringer с помощью {{ yagpt-name }} [удалось](https://vc.ru/services/1659960-kak-s-pomoshyu-yandexgpt-avtomaticheski-otvechat-na-60-voprosov-i-otzyvov-opyt-ralf-ringer) наполовину автоматизировать обработку обращений в клиентскую поддержку. За день модель успевает «пообщаться» более чем с 2 000 пользователей.

Модель специально дообучили под бренд на парах «вопрос — ответ». Каждый новый качественный ответ также заносится в базу данных для дообучения. В качестве тестирования продавцам предложили сравнить ответы оператора и модели: 65% выбрали модель. Правда, негативные отзывы ей пока не доверяют — модель самостоятельно выявляет тональность сообщения и передает его оператору, если она негативная.

### Постановка диагнозов {#medicine}

Если обучить модель на больших массивах медицинских данных, она [способна](https://www.johnsnowlabs.com/the-impact-of-medical-llms-on-disease-diagnosis-and-treatment/) анализировать и интерпретировать сложную медицинскую информацию, складывая в одну картину множество фактов из анамнеза пациента. Медицина — та область, в которой потенциал LLM огромен.

Модели могут подмечать закономерности, которые невооруженным взглядом не увидит даже опытный диагност. Помимо индивидуальной помощи пациентам, большие языковые модели используются в исследованиях болезней и разработке лекарств.

Чтобы подробнее ознакомиться с примерами использования LLM см. [Библиотека промтов {{ yagpt-full-name }}](../foundation-models/prompts/yandexgpt/index.md).

## Проблемы LLM {#disadvantages}

Несмотря на позитивную динамику развития LLM, перед разработчиками все еще стоит ряд вызовов:

* **Галлюцинации** — модели склонны генерировать фактически неверную, нарушающую логику или несоответствующую контексту информацию. Зачастую сложно найти причины такого поведения — это может быть некорректный промт, проблемы с данными для обучения, несовершенство архитектуры и многое другое.

* **Этические проблемы** — создатели LLM иногда закладывают в модели свои собственные или обусловленные законами страны ценности и предубеждения. Это может сделать модель необъективной. Например, на какой-то сложный запрос она выдаст предвзятый ответ или вовсе откажется отвечать.

* **Ограниченные рассуждения** — LLM все еще плохо справляются с задачами, требующими долгих размышлений. Без дообучения они представляют собой эрудированного на первый взгляд сотрудника, все знания которого оказываются поверхностными, если попробовать углубиться в тему.

* **Однотипные и неуместные ответы** — модель иногда чрезмерно ориентируется на конкретный результат. Например, если стимулировать модель давать безвредные ответы, она может добавлять предостерегающие дисклеймеры там, где это не нужно. «Не ешьте слишком много яблок», — может добавить LLM к ответу на безобидный запрос о сортах этого фрукта.

* **Интерпретация контекста** — в сложных текстах модели могут не понимать, как согласуются между собой те или иные их части. Особенно это заметно в задачах, где нужно распознать отношения между сущностями.

* **Эмерджентность** — LLM могут проявлять поведение, которое не закладывалось разработчиками. Например, модель Bard научилась переводить с бенгальского языка, хотя ее этому не обучали. Умение модели самостоятельно искать информацию может быть полезно, но многие исследователи считают это поводом насторожиться — поведение нейросетей трудно предсказать.

* **Нарушение авторских прав** — нейросети обучаются на информации из интернета, но многие не заинтересованы в передаче им своих материалов. Законодательства многих стран пока не приспособились к новой реальности, что служит почвой для судебных разбирательств.

* **Ресурсозатратность** — чем больше модель, тем большие вычислительные мощности ей нужны. Только один центр обработки данных потребляет энергию, которой хватило бы для годового энергообеспечения 50 000 домов.

## LLM в сервисах {{ yandex-cloud }} {#llm-yc}

Для работы с большими языковыми моделями {{ yandex-cloud }} предлагает следующие инструменты:

* Сервис [{{ foundation-models-full-name }}](../foundation-models/), включающий:
  * [Модели](../foundation-models/concepts/yandexgpt/models.md) генерации текста.
  * [Классификаторы](../foundation-models/concepts/classifier/index.md) на базе {{ yagpt-name }}.
* [{{ ml-platform-full-name }}](../datasphere/) — сервис, позволяющий создавать новые модели, а также дообучать фундаментальные, чтобы они точнее отвечали на ваши запросы.
* [{{ speechsense-full-name }}](../speechsense/) — сервис для организации аналитики контактных центров, использующий технологии {{ speechkit-name }} и {{ yagpt-name }}.

Для продвинутой работы с запросами к большим языковым моделям вы также можете изучить [Руководство по проектированию промтов](../foundation-models/gpt-prompting-guide/about.md).

#### См. также {#see-also}

* [{#T}](ml-models.md)
* [{#T}](chat-bot.md)
