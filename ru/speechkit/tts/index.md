# Синтез речи

_Синтез речи_ в {{ speechkit-full-name }} позволяет озвучить любой текст на нескольких языках.

Голосовые модели {{ speechkit-name }} используют технологию глубоких нейронных сетей. При синтезе речи модель обращает внимание на большое количество деталей исходного голоса. Перед началом синтеза модель оценивает весь текст целиком, а не отдельные предложения. Благодаря этому синтезированный голос звучит чисто и естественно, без электронных искажений, и воспроизводит уместные интонации, присущие речи живого человека.


## Возможности синтеза {#features}

{% include [api-concepts](../../_includes/speechkit/api-concepts.md) %}

Синтез {{ speechkit-name }} имеет два API — [API v1](request.md) (REST) и [API v3](../tts-v3/api-ref/grpc/) (gRPC).

|                                                    | API v1 | API v3                                      |
|----------------------------------------------------|---|---------------------------------------------|
| Спецификация                                       | REST | gRPC                                        |
| Выбор голоса                                       | Параметр `voice` | Параметр `hint: voice`                      |
| Выбор языка                                        | Зависит от голоса </br>Параметр `lang` | Зависит от голоса, в запросе явно не указан |
| Задание амплуа                                     | Зависит от голоса </br>Параметр `emotion` | Зависит от голоса </br>Параметр `hint: role` |
| [Управление произношением](#markup)                | SSML </br> TTS | TTS                                         |
| [Скорость произношения](#speed)                    | Параметр `speed` | Параметр `hint: speed`                      |
| [Настройка громкости](#volume)                     | Нет | Параметр `loudness_normalization_type`      |
| [Формат результирующего аудио](#format)            | Параметр `format` | Параметр `output_audio_spec`                |
| Задание параметров [LPCM](../formats.md#lpcm)      | Параметр `sampleRateHertz` | Параметр `output_audio_spec: raw_audio`|
| [Синтез по шаблону](brand-voice/index.md#adaptive) | Нет | Параметр ` text_template`                   |
| [Способ тарификации](../pricing.md#rules-tts)      | Суммарное количество символов в запросах | По запросам   |
| Автоматическое разбиение длинных фраз              | Не требуется | Параметр `unsafe_mode`  |


## Языки и голоса {#langs}

Вы можете выбрать голос, который будет озвучивать ваш текст. Каждый голос соответствует модели, обученной на речи диктора. Голоса отличаются тембром, полом и языком говорящего. Список голосов и их характеристики см. в разделе [{#T}](voices.md). 

Если ни один голос не подходит вашему бизнесу, {{ speechkit-name }} может создать уникальный — специально для вас. Подробнее об этом — в разделе [{#T}](brand-voice/index.md).

{{ speechkit-name }} может синтезировать речь на разных языках. Каждый голос предназначен для синтеза речи на определенном языке. Голоса могут произносить и текст на <q>иностранном</q> языке, однако в этом случае качество синтезированной речи будет хуже: <q>диктор</q>> будет говорить с акцентом, а слова могут быть синтезированы с ошибками. 

### Амплуа {#role}

Синтезированная речь будет звучать по-разному в зависимости от выбранного амплуа. Амплуа — это характер произношения для одного и того же диктора. Для разных голосов доступны разные наборы амплуа. Попытка использовать амплуа, которого нет у выбранного голоса, вызовет ошибку сервиса.

## Управление произношением {#markup}

Чтобы контролировать произношение в синтезированной речи, явно размечайте исходный текст. {{ speechkit-name }} может синтезировать речь из текста, размеченного по правилам [Speech Synthesis Markup Language](https://en.wikipedia.org/wiki/Speech_Synthesis_Markup_Language) (SSML) или TTS-разметки. Эти способы разметки позволяют настроить длительность пауз, произношение отдельных звуков и многое другое. SSML и TTS-разметка отличаются параметрами передачи данных:

* SSML поддерживается только в запросах API v1. Чтобы передать текст в формате SSML, укажите параметр `ssml` в теле запроса, а текст оберните в тег `<speak>`. Подробнее о тегах SSML читайте в разделе [{#T}](ssml.md).
* TTS-разметка поддерживается в API v1 и API v3. В запросах API v1 передавайте текст, размеченный по правилам TTS, в параметре `text` в теле запроса. API v3 не требует специальных параметров и считает любой переданный текст размеченным по правилам TTS. Подробнее об использовании TTS-разметки читайте в разделе [{#T}](tts-markup.md).

## Настройки синтеза {#settings} 

Вы можете настраивать не только произношение, но и технические характеристики синтезируемой речи.

### Скорость синтезированной речи {#speed}

Скорость синтезируемой речи влияет на восприятие информации. Слишком быстрое или слишком медленное произношение звучит неестественно, но может быть полезно в рекламе, где каждая секунда эфира стоит дорого.

По умолчанию скорость генерируемой речи соответствует средней скорости речи человека.

### Нормализация громкости {#volume}

В запросах [API v3](../tts-v3/api-ref/grpc/) вы можете задать тип и уровень нормализации громкости. Это может потребоваться, если вы используете синтез {{ speechkit-name }} вместе с другими источниками звука. Например, чтобы громкость голосового ассистента не отличалась от уведомлений телефона. 

{{ speechkit-name }} поддерживает два типа нормализации:
* [Пиковая нормализация](https://ru.wikipedia.org/wiki/Нормализация_звука#Пиковая_нормализация) `MAX_PEAK`, при которой уровень звукового сигнала поднимается до максимально возможного значения для цифрового звука без появления искажений. 
* Нормализация `LUFS` — взвешенная нормализация на основе стандарта [EBU R 128](https://en.wikipedia.org/wiki/EBU_R_128), в соответствии с которым нормализация громкости производится относительно цифровой полной шкалы. 

Тип нормализации можно задать в параметре `loudness_normalization_type`.  По умолчанию {{ speechkit-name }} использует тип LUFS.

Уровень нормализации задается параметром `hint: volume`. Возможные значения зависят от типа нормализации:
* для `MAX_PEAK` параметр может принимать значения в интервале `(0;1]`, значение по умолчанию — `0.7`;
* для `LUFS` параметр изменяется в интервале `[-149;0)`, значение по умолчанию — `-19`.

Если значение уровня нормализации не попадает в интервал, поддерживаемый уровнем нормализации, сервер {{ speechkit-name }} вернет ошибку `InvalidArgument`.

### Формат синтезированного аудиофайла {#format}

Вы можете выбрать формат аудиофайлов, в котором {{ speechkit-name }} будет синтезировать речь.

Полный список доступных форматов и их характеристики см. в разделе [{#T}](../formats.md).

#### См. также {#see-also}


* Попробуйте синтез речи с помощью демо на [странице сервиса](https://cloud.yandex.ru/services/speechkit#demo).
* Ознакомьтесь с параметрами метода [API v1](request.md) и запросов [API v3](../tts-v3/api-ref/grpc/).
* Посмотрите примеры использования API {{ speechkit-name }}:
  * [{#T}](api/tts-ogg.md)
  * [{#T}](api/tts-wav.md)
  * [{#T}](api/tts-ssml.md)


