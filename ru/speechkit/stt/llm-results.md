# Обработка результатов распознавания с помощью LLM

{{ speechkit-name }} API v3 позволяет не только распознавать аудио, но и обрабатывать результаты распознавания с помощью больших генеративных моделей. Таким образом можно автоматизировать обработку результатов распознавания речи, например, сразу же получить краткий пересказ распознанного аудио, на основе аудио заполнить определенные поля в CRM-системе или перевести диалог на английский язык.

Чтобы использовать возможности генеративных моделей при распознавании аудио, в конфигурации запроса заполните блок `summarization`. Вы можете указать только текстовую инструкцию (_[промпт](../../ai-studio/concepts/index.md#prompt)_) для модели или задать структуру ответа в виде JSON. Подробнее про структуру ответа см. в документации [{{ foundation-models-name }}](../../ai-studio/concepts/generation/structured-output.md). Чтобы использовать возможности генеративных моделей в {{ speechkit-name }} API v3, понадобится роль `ai.languageModels.user` или [выше](../../ai-studio/security/index.md#service-roles).

{% list tabs %}

- Простой ответ

  ```json
  {
  ...
    "summarization": {
      "modelUri": "gpt://<идентификатор_каталога>/<название_модели>",
      "properties": [
        {
          "instruction": "Промпт для модели"
        }
      ]
    }
    ...
  }
  ```

- Произвольный JSON

  ```json
  {
  ...
    "summarization": {
      "modelUri": "gpt://<идентификатор_каталога>/<название_модели>",
      "properties": [
        {
          "instruction": "Промпт для модели, требующий структурированного ответа",
          "jsonObject": true
        }
      ]
    }
    ...
  }
  ```

- Строгая схема JSON

  ```json
  {
  ...
    "summarization": {
      "modelUri": "gpt://<идентификатор_каталога>/<название_модели>",
      "properties": [
        {
          "instruction": "Промпт для модели, требующий структурированного ответа",
          "jsonSchema": {
            // Заданная схема вывода 
            "schema": "<json-схема>"
          }
        }
      ]
    }
    ...
  }
  ```

{% endlist %}

Где: 
* `modelUri` — [модель](../../ai-studio/concepts/generation/models.md), доступная для работы _в синхронном режиме_.
* `instruction` — промпт модели («Выдели основные тезисы», «Переведи на английский»). Рекомендации по созданию промптов доступны в разделе [{#T}](../../ai-studio/gpt-prompting-guide/about.md), примеры эффективных промптов см. в [библиотеке промптов {{ yagpt-name }}](../../ai-studio/prompts/yandexgpt/index.md).
* `jsonObject` — при значении `true` задает вывод модели в виде JSON произвольного формата.
* `jsonSchema` — схема для строго форматированного JSON-вывода.


Результаты работы модели вернутся в объекте `summarization`:

```json

{
...
  "result": {
    "summarization": {
      "results": [
        {
          "response": "Текст от LLM-модели"
        },
        {
          "response": "JSON от LLM-модели"
        }
      ],
      "contentUsage": {
        "inputTextTokens": 150,    // Токены запроса
        "completionTokens": 80,    // Токены ответа
        "totalTokens": 230         // Суммарное потребление
      }
    }
  }
...
}
```

Поле `contentUsage` содержит детализацию расходов [токенов](../../ai-studio/concepts/generation/tokens.md). Стоимость использования зависит от выбранной модели и рассчитывается по тарифам сервиса [{{ foundation-models-name }}](../../ai-studio/pricing.md) на основе суммарного количества токенов в вопросе и ответе (поле `totalTokens`).