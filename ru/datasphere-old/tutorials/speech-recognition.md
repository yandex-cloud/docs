# Голосовая биометрия

{% include [link-on-new-ui-datasphere-in-old-ui](../../_includes/datasphere/datasphere-old-note.md) %}

{{ ml-platform-full-name }} позволяет строить модели машинного обучения, используя интерфейс {{ jlab }} Notebook. Познакомьтесь с решением задачи распознавания спикера по голосу с помощью моделирования речевых сигналов числовыми признаками:

1. [Установите зависимости](#satisfy-dependencies).
1. [Выполните загрузку данных и извлечение признаков](#load-dataset).
1. [Обучите модель на голосовых данных](#model-fit).
1. [Получите результаты предсказания признаков на тестовых данных](#model-test).

## Перед началом работы {#before-you-begin}

1. [Создайте проект](../operations/projects/create) в **{{ ml-platform-name }}** и откройте его.
1. [Склонируйте](../operations/projects/work-with-git.md#clone) Git-репозиторий, в котором находится подготовленный ноутбук с набором данных:

    ```text
    https://github.com/yandex-cloud/examples
    ```

    Дождитесь завершения клонирования, это может занять некоторое время. После завершения операции в блоке **File Browser** появится каталог склонированного репозитория.

1. Откройте каталог **examples/datasphere/** и ознакомьтесь с содержимым ноутбука **speech-recognition.ipynb**. В начале ноутбука кратко изложены основные принципы моделирования речевого сигнала аудиопризнаками.

    {% include [safe-state-warn](../../_includes/datasphere/safe-state.md) %}

## Установите зависимости {#satisfy-dependencies}

1. Выделите все ячейки с кодом в разделе **Установка и импорт необходимых пакетов**, удерживая **Shift** и нажимая слева от нужных ячеек:

    ```python
    %pip install numba==0.48.0
    %pip install librosa
    %pip install cffi==1.14.2
    %pip show numba
    import time
    import os
    from tqdm import tqdm
    ...
    ```

1. Запустите выделенные ячейки, выбрав в меню **Run → Run Selected Cells** (также можно использовать сочетание клавиш **Shift** + **Enter**).
1. Дождитесь завершения операции.
1. Перезапустите ядро, выбрав в меню **Kernel → Restart kernel**.

Часть пакетов уже установлена и импортируется с помощью команды `import`, часть устанавливается с помощью команды `%pip install` и затем импортируется. Полный список предустановленных в {{ ml-platform-name }} пакетов см. в разделе [{#T}](../concepts/preinstalled-packages.md).

## Загрузите набор данных из звуковых файлов {#load-dataset}

Перейдите к разделу **Генерация аудиопризнаков**. В нем выполняются следующие операции:

1. Определяется функция для извлечения аудиопризнаков из набора данных (используется [библиотека `librosa`](https://librosa.org/doc/latest/index.html)).
1. Загружается тестовый набор коротких десятисекундных аудиофрагментов. С помощью этой функции извлекаются аудиопризнаки. Так как данные распределены по папкам, относящимся к разным спикерам, можно однозначно сопоставить набору признаков конкретного спикера.
1. Полученный массив признаков нормируется.

Чтобы выполнить загрузку и обработку данных:

1. Выделите все ячейки с кодом в разделе **Генерация аудиопризнаков** и запустите их.
1. Дождитесь завершения операции.

## Обучите модель на голосовых данных {#model-fit}

Перейдите к ячейке с кодом обучения моделей в разделе **Обучение моделей**. В данной ячейке в цикле по каждому спикеру выполняются следующие операции:

1. Модель обучается на фрагментах его речи.
1. Модуль `pickle` выполняет сохранение объекта обученной модели в файл в папке `./data/speaker-models`.

Чтобы обучить модель:

1. Выделите ячейку с кодом в разделе **Обучение моделей**.
1. Запустите ячейку.
1. Дождитесь завершения операции.

Обратите внимание на первую строку в ячейке с кодом:

```python
#!c1.8

start = time.time()
...
```

Обучение модели — ресурсоемкая операция, и для ее эффективного выполнения [конфигурация вычислительных ресурсов](../concepts/configurations.md) повышается до **c1.8**.

## Получите результаты предсказания признаков на тестовых данных {#model-test}

Перейдите к разделу **Тестирование на тестовом семпле**. В нем выполняются следующие операции:

1. Загружаются обученные модели из файлов `pickle`.
1. Выполняется загрузка и обработка аудиофайлов из тестового набора данных подобно тому, как это делалось [для обучающего набора](#load-dataset).
1. Каждая модель предсказывает спикера по признакам.
1. Наилучший результат предсказания определяет выбор спикера.
1. Отображается точность определения выбранного в тесте спикера.

Чтобы получить результаты тестирования:

1. Выделите ячейку в разделе **Тестирование на тестовом семпле**.
1. Запустите ячейку.
1. Дождитесь завершения операции.
1. Убедитесь, что полученная точность определения спикера не менее 98%.

{% note info %}

Вы можете [поделиться](../operations/projects/publication.md) готовым ноутбуком с расчетами или [экспортировать проект](../operations/projects/export.md) целиком.

{% endnote %}
