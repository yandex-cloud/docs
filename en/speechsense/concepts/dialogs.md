---
title: '{{ speechsense-full-name }} dialogs'
description: In this tutorial, you will learn about dialogs in {{ speechsense-name }}.
---

# {{ speechsense-name }} dialogs

_Dialog_ is a {{ speechsense-name }} object. There are two types of dialogs:

* Audio: Agent's voice conversation with a customer recorded using contact center PBX. As soon as you [upload a conversation's audio](../operations/data/upload-data.md) to {{ speechsense-name }}, it will automatically recognize agent and customer speech.

* Chat: Customer's text chat with an agent or bot. For chats, you need to manually specify message authors before [uploading a chat](../operations/data/upload-chat-text.md) to {{ speechsense-name }}.

There are two dialog directions:

* Outgoing: Initiated by agent.
* Incoming: Initiated by customer.

Analyze dialogs in SpeechSense to evaluate the agents' performance. There are two ways to work with dialogs:

* In the dialog list, [find](../operations/data/manage-dialogs.md) the one you need and view its detailed info.
* [Build a report](../operations/data/manage-reports.md) on dialogs.

## Detailed info about a dialog {#details}

You [can get](../operations/data/manage-dialogs.md#view-dialog) the following information for each dialog:

* Metadata, e.g., full names of agent and customer, call or message date, dialog language, etc. The metadata list is [defined in the connection](../operations/connection/create.md).
* Conversation audio (only for audio).
* Conversation contents.
* [{{ yagpt-name }}](../../foundation-models/concepts/yandexgpt/models.md) analysis.

### Dialog contents {#contents}

On the dialog page, see the **{{ ui-key.yc-ui-talkanalytics.dialogs.dialog }}** tab for the dialog contents:

* For audio: Text transcript of the dialog, automatically generated by [{{ speechkit-full-name }}](../../speechkit/index.yaml).
* For chats: Text messages.

You can [search for a text fragment](../operations/data/manage-dialogs.md#find-dialogs) through an audio text transcript or text chat messages in either the customer's or the agent's channel. The search returns exact matches. The found fragments are highlighted in yellow.

The text is automatically tagged with agent and customer [tags](tags.md). These indicate things like whether the agent greeted the customer, whether the customer was in good humor, etc.

### {{ yagpt-name }} analysis {#yandexgpt}

{% note warning %}

Neuroreports will be discontinued starting February 24, 2025. Use [semantic tags](tags.md#sense-tags) instead.

{% endnote %}

On the dialog page, you can see the **{{ ui-key.yc-ui-talkanalytics.projects.sumarization }}** tab with an autogenerated summary of the dialog based on its semantic analysis. The summary has the following sections:

* **{{ ui-key.yc-ui-talkanalytics.dialogs.analysis }}**: Answers to questions to help evaluate the agent's performance and customer's behavior during the conversation.
* **{{ ui-key.yc-ui-talkanalytics.statements.call_reasons }}**: Why this dialog took place. Examples of reasons:

   * Incoming contact: Customer has issues with a service.
   * Outgoing contact: Agent is advertising a subscription for a service.
* **{{ ui-key.yc-ui-talkanalytics.statements.call_results }}**: The outcome of the conversation. The results are summed up for each of the listed reasons. Examples:

   * Incoming contact: Agent helped to resolve the customer’s issue.
   * Outgoing contact: Customer purchased the subscription.
* **{{ ui-key.yc-ui-talkanalytics.statements.problems }}**: Issues reported by the customer.
* **{{ ui-key.yc-ui-talkanalytics.statements.summary }}**: Reasons for having the conversation and its results. This section also includes information on the evaluation criteria, e.g., the participants’ emotions or objections during the conversation.
* **{{ ui-key.yc-ui-talkanalytics.statements.client_keywords }}**: Keywords in the customer's messages.
* **{{ ui-key.yc-ui-talkanalytics.statements.operator_keywords }}**: Keywords in the agent's messages.
* **{{ ui-key.yc-ui-talkanalytics.statements.theme }}**: What the customer and agent discussed.

To get more accurate analysis results in the future, evaluate them on the **{{ ui-key.yc-ui-talkanalytics.projects.sumarization }}** tab for each dialog. {{ yagpt-name }} learns from your feedback.

When generating a [report](reports/index.md), you can use a [semantic attribute](reports/sense-attributes.md) together with a search query. {{ speechsense-name }} will analyze the dialog against the specified conditions. There are two ways you can use semantic attributes:

* As filters for dialogs. For example, you can create a report only for dialogs on a given topic.
* As an evaluation parameter (only for _Evaluation form_ reports). For example, you can view dialogs with a certain outcome as a proportion of all the dialogs included in the report.

For information on setting up semantic attributes, see [this guide](../operations/data/manage-reports.md#apply-sense-attribute).

## Dialog filtering {#filters}

Filters define the conditions for [searching through dialogs](../operations/data/manage-dialogs.md#filters-dialogs).

There are the following types of filters:

* **{{ ui-key.yc-ui-talkanalytics.dialogs.operator }}**: Agent data.
* **{{ ui-key.yc-ui-talkanalytics.dialogs.client }}**: Customer data.
* **{{ ui-key.yc-ui-talkanalytics.dialogs.bot }}** (only for chats): Bot data.
* **{{ ui-key.yc-ui-talkanalytics.dialogs.speech-statistics }}** (only for audio): Agent and customer speech quality criteria, e.g., speech rate, mutual interruptions, etc.
* **{{ ui-key.yc-ui-talkanalytics.dialogs.common-metadata }}**: Data about the conversation audio or text chat.
* **{{ ui-key.yc-ui-talkanalytics.tags.tags }}**: Classifiers applied to conversation audio recognition results or text messages. To learn more about tags, see [Concepts](tags.md).
* **{{ ui-key.yc-ui-talkanalytics.projects.sumarization }}**: Agent's performance criteria and customer's behavioral characteristics during the dialog, such as whether the agent was polite, whether the customer acted in a rude manner, etc.

For each filter, you can specify one or more filtering conditions. These can be of four types:

* Date: Select a date range from the calendar.
* Text: Enter a line of text. The search will only return exact matches.
* Number: Specify a range of numbers. You can specify either both range boundaries or just one of them. To find a particular value, specify it for both the top and bottom boundaries. The boundary values are included into the filtering range.
* Logic: Select either **{{ ui-key.yc-ui-talkanalytics.common.yes }}** or **{{ ui-key.yc-ui-talkanalytics.common.no }}**.

You can use multiple filters at the same time. They will be combined by the logical `AND` operation to find the dialogs satisfying all the conditions that were specified.

## Related dialogs {#related-dialogs}

In some CRM systems, chats may be grouped by task. For example, you can group together all chats with a customer who has contacted support multiple times with the same request. When [uploading data into {{ speechsense-name }}](../operations/data/upload-chat-text.md), you can specify the additional `ticket_id` parameter to group such chats into _related dialogs_.

In each of the related chats, you will see the ![image](../../_assets/console-icons/link.svg)  button you can use to [navigate](../operations/data/related-dialogs.md#list) to the page of the related dialogs. There you can view the following dialog info:

* Chat metadata at the top of the page.
* Contents of all related chats on the **{{ ui-key.yc-ui-talkanalytics.dialogs.dialog }}** tab. It shows a tag hierarchy for each individual chart. You can use text search within a single chat.
* Chat summaries autogenerated by {{ yagpt-full-name }} based on semantic analysis, on the **{{ ui-key.yc-ui-talkanalytics.projects.sumarization }}** tab.
