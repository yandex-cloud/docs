---
editable: false
sourcePath: en/_cli-ref/cli-ref/managed-services/managed-clickhouse/cluster/update-config.md
---

# yc managed-clickhouse cluster update-config

Update the configuration of a ClickHouse cluster.

#### Command Usage

Syntax: 

`yc managed-clickhouse cluster update-config <CLUSTER-NAME>|<CLUSTER-ID> [Flags...] [Global Flags...]`

#### Flags

| Flag | Description |
|----|----|
|`--id`|<b>`string`</b><br/>ID of the ClickHouse cluster.|
|`--name`|<b>`string`</b><br/>Name of the ClickHouse cluster.|
|`--async`|Display information about the operation in progress, without waiting for the operation to complete.|
|`--set`|<b>`key1=value1[,key2=value2][,"key3=val3a,val3b"]`</b><br/>Set a parameter for a ClickHouse cluster. Can be specified multiple times. Acceptable keys:<br/><ul> <li> <p><code>log_level</code>:     Logging level for the ClickHouse cluster. Possible values: TRACE, DEBUG, INFORMATION, WARNING, ERROR.</p> </li> <li> <p><code>merge_tree.replicated_deduplication_window</code>:     Number of blocks of hashes to keep in ZooKeeper.</p> </li> <li> <p><code>merge_tree.replicated_deduplication_window_seconds</code>:     Period of time to keep blocks of hashes for.</p> </li> <li> <p><code>merge_tree.parts_to_delay_insert</code>:     If table contains at least that many active parts in single partition, artificially slow down insert into table.</p> </li> <li> <p><code>merge_tree.parts_to_throw_insert</code>:     If more than this number active parts in single partition, throw 'Too many parts ...' exception.</p> </li> <li> <p><code>merge_tree.inactive_parts_to_delay_insert</code>:</p> </li> <li> <p><code>merge_tree.inactive_parts_to_throw_insert</code>:</p> </li> <li> <p><code>merge_tree.max_replicated_merges_in_queue</code>:     How many tasks of merging and mutating parts are allowed simultaneously in ReplicatedMergeTree queue.</p> </li> <li> <p><code>merge_tree.number_of_free_entries_in_pool_to_lower_max_size_of_merge</code>:     If there is less than specified number of free entries in background pool (or replicated queue), start to lower maximum size of merge to process.</p> </li> <li> <p><code>merge_tree.max_bytes_to_merge_at_min_space_in_pool</code>:     Maximum in total size of parts to merge, when there are minimum free threads in background pool (or entries in replication queue).</p> </li> <li> <p><code>merge_tree.max_bytes_to_merge_at_max_space_in_pool</code>:</p> </li> <li> <p><code>merge_tree.min_bytes_for_wide_part</code>:     Minimum number of bytes in a data part that can be stored in <strong>Wide</strong> format.</p> <p>More info see in <a href="https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/mergetree/#min_bytes_for_wide_part">ClickHouse documentation</a>.</p> </li> <li> <p><code>merge_tree.min_rows_for_wide_part</code>:     Minimum number of rows in a data part that can be stored in <strong>Wide</strong> format.</p> <p>More info see in <a href="https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/mergetree/#min_bytes_for_wide_part">ClickHouse documentation</a>.</p> </li> <li> <p><code>merge_tree.ttl_only_drop_parts</code>:     Enables or disables complete dropping of data parts where all rows are expired in MergeTree tables.</p> <p>More info see in <a href="https://clickhouse.com/docs/en/operations/settings/settings/#ttl_only_drop_parts">ClickHouse documentation</a>.</p> </li> <li> <p><code>merge_tree.allow_remote_fs_zero_copy_replication</code>:</p> </li> <li> <p><code>merge_tree.merge_with_ttl_timeout</code>:</p> </li> <li> <p><code>merge_tree.merge_with_recompression_ttl_timeout</code>:</p> </li> <li> <p><code>merge_tree.max_parts_in_total</code>:</p> </li> <li> <p><code>merge_tree.max_number_of_merges_with_ttl_in_pool</code>:</p> </li> <li> <p><code>merge_tree.cleanup_delay_period</code>:</p> </li> <li> <p><code>merge_tree.number_of_free_entries_in_pool_to_execute_mutation</code>:</p> </li> <li> <p><code>merge_tree.max_avg_part_size_for_too_many_parts</code>:     The 'too many parts' check according to 'parts_to_delay_insert' and 'parts_to_throw_insert' will be active only if the average part size (in the relevant partition) is not larger than the specified threshold. If it is larger than the specified threshold, the INSERTs will be neither delayed or rejected. This allows to have hundreds of terabytes in a single table on a single server if the parts are successfully merged to larger parts. This does not affect the thresholds on inactive parts or total parts. Default: 1 GiB Min version: 22.10 See in-depth description in <a href="https://github.com/ClickHouse/ClickHouse/blob/f9558345e886876b9132d9c018e357f7fa9b22a3/src/Storages/MergeTree/MergeTreeSettings.h#L80">ClickHouse GitHub</a></p> </li> <li> <p><code>merge_tree.min_age_to_force_merge_seconds</code>:     Merge parts if every part in the range is older than the value of min_age_to_force_merge_seconds. Default: 0 - disabled Min_version: 22.10 See in-depth description in <a href="https://clickhouse.com/docs/en/operations/settings/merge-tree-settings#min_age_to_force_merge_seconds">ClickHouse documentation</a></p> </li> <li> <p><code>merge_tree.min_age_to_force_merge_on_partition_only</code>:     Whether min_age_to_force_merge_seconds should be applied only on the entire partition and not on subset. Default: false Min_version: 22.11 See in-depth description in <a href="https://clickhouse.com/docs/en/operations/settings/merge-tree-settings#min_age_to_force_merge_seconds">ClickHouse documentation</a></p> </li> <li> <p><code>merge_tree.merge_selecting_sleep_ms</code>:     Sleep time for merge selecting when no part is selected. A lower setting triggers selecting tasks in background_schedule_pool frequently, which results in a large number of requests to ClickHouse Keeper in large-scale clusters. Default: 5000 Min_version: 21.10 See in-depth description in <a href="https://clickhouse.com/docs/en/operations/settings/settings#merge_selecting_sleep_ms">ClickHouse documentation</a></p> </li> <li> <p><code>kafka.security_protocol</code>:</p> </li> <li> <p><code>kafka.sasl_mechanism</code>:</p> </li> <li> <p><code>kafka.sasl_username</code>:</p> </li> <li> <p><code>kafka.sasl_password</code>:</p> </li> <li> <p><code>kafka.enable_ssl_certificate_verification</code>:</p> </li> <li> <p><code>kafka.max_poll_interval_ms</code>:</p> </li> <li> <p><code>kafka.session_timeout_ms</code>:</p> </li> <li> <p><code>kafka_topics.name</code>:</p> </li> <li> <p><code>kafka_topics.settings.security_protocol</code>:</p> </li> <li> <p><code>kafka_topics.settings.sasl_mechanism</code>:</p> </li> <li> <p><code>kafka_topics.settings.sasl_username</code>:</p> </li> <li> <p><code>kafka_topics.settings.sasl_password</code>:</p> </li> <li> <p><code>kafka_topics.settings.enable_ssl_certificate_verification</code>:</p> </li> <li> <p><code>kafka_topics.settings.max_poll_interval_ms</code>:</p> </li> <li> <p><code>kafka_topics.settings.session_timeout_ms</code>:</p> </li> <li> <p><code>rabbitmq.username</code>:     <a href="https://clickhouse.com/docs/en/engines/table-engines/integrations/rabbitmq/">RabbitMQ</a> username</p> </li> <li> <p><code>rabbitmq.password</code>:     <a href="https://clickhouse.com/docs/en/engines/table-engines/integrations/rabbitmq/">RabbitMQ</a> password</p> </li> <li> <p><code>rabbitmq.vhost</code>:     <a href="https://clickhouse.com/docs/en/engines/table-engines/integrations/rabbitmq/">RabbitMQ</a> virtual host</p> </li> <li> <p><code>max_connections</code>:     Maximum number of inbound connections.</p> </li> <li> <p><code>max_concurrent_queries</code>:     Maximum number of simultaneously processed requests.</p> </li> <li> <p><code>keep_alive_timeout</code>:     Number of milliseconds that ClickHouse waits for incoming requests before closing the connection.</p> </li> <li> <p><code>uncompressed_cache_size</code>:     Cache size (in bytes) for uncompressed data used by MergeTree tables.</p> </li> <li> <p><code>mark_cache_size</code>:     Approximate size (in bytes) of the cache of &quot;marks&quot; used by MergeTree tables.</p> </li> <li> <p><code>max_table_size_to_drop</code>:     Maximum size of the table that can be deleted using a DROP query.</p> </li> <li> <p><code>max_partition_size_to_drop</code>:     Maximum size of the partition that can be deleted using a DROP query.</p> </li> <li> <p><code>builtin_dictionaries_reload_interval</code>:     The setting is deprecated and has no effect.</p> </li> <li> <p><code>timezone</code>:     The server's time zone to be used in DateTime fields conversions. Specified as an IANA identifier.</p> </li> <li> <p><code>geobase_uri</code>:     Address of the archive with the user geobase in Object Storage.</p> </li> <li> <p><code>query_log_retention_size</code>:     The maximum size that query_log can grow to before old data will be removed. If set to 0, automatic removal of query_log data based on size is disabled.</p> </li> <li> <p><code>query_log_retention_time</code>:     The maximum time that query_log records will be retained before removal. If set to 0, automatic removal of query_log data based on time is disabled.</p> </li> <li> <p><code>query_thread_log_enabled</code>:     Whether query_thread_log system table is enabled.</p> </li> <li> <p><code>query_thread_log_retention_size</code>:     The maximum size that query_thread_log can grow to before old data will be removed. If set to 0, automatic removal of query_thread_log data based on size is disabled.</p> </li> <li> <p><code>query_thread_log_retention_time</code>:     The maximum time that query_thread_log records will be retained before removal. If set to 0, automatic removal of query_thread_log data based on time is disabled.</p> </li> <li> <p><code>part_log_retention_size</code>:     The maximum size that part_log can grow to before old data will be removed. If set to 0, automatic removal of part_log data based on size is disabled.</p> </li> <li> <p><code>part_log_retention_time</code>:     The maximum time that part_log records will be retained before removal. If set to 0, automatic removal of part_log data based on time is disabled.</p> </li> <li> <p><code>metric_log_enabled</code>:     Whether metric_log system table is enabled.</p> </li> <li> <p><code>metric_log_retention_size</code>:     The maximum size that metric_log can grow to before old data will be removed. If set to 0, automatic removal of metric_log data based on size is disabled.</p> </li> <li> <p><code>metric_log_retention_time</code>:     The maximum time that metric_log records will be retained before removal. If set to 0, automatic removal of metric_log data based on time is disabled.</p> </li> <li> <p><code>trace_log_enabled</code>:     Whether trace_log system table is enabled.</p> </li> <li> <p><code>trace_log_retention_size</code>:     The maximum size that trace_log can grow to before old data will be removed. If set to 0, automatic removal of trace_log data based on size is disabled.</p> </li> <li> <p><code>trace_log_retention_time</code>:     The maximum time that trace_log records will be retained before removal. If set to 0, automatic removal of trace_log data based on time is disabled.</p> </li> <li> <p><code>text_log_enabled</code>:     Whether text_log system table is enabled.</p> </li> <li> <p><code>text_log_retention_size</code>:     The maximum size that text_log can grow to before old data will be removed. If set to 0, automatic removal of text_log data based on size is disabled.</p> </li> <li> <p><code>text_log_retention_time</code>:     The maximum time that text_log records will be retained before removal. If set to 0, automatic removal of text_log data based on time is disabled.</p> </li> <li> <p><code>text_log_level</code>:     Logging level for text_log system table. Possible values: TRACE, DEBUG, INFORMATION, WARNING, ERROR.</p> </li> <li> <p><code>opentelemetry_span_log_enabled</code>:</p> </li> <li> <p><code>background_pool_size</code>:</p> </li> <li> <p><code>background_schedule_pool_size</code>:</p> </li> <li> <p><code>background_fetches_pool_size</code>:     Sets the number of threads performing background fetches for tables with <strong>ReplicatedMergeTree</strong> engines. Default value: 8.</p> <p>More info see in <a href="https://clickhouse.com/docs/en/operations/server-configuration-parameters/settings/#background_fetches_pool_size">ClickHouse documentation</a>.</p> </li> <li> <p><code>background_move_pool_size</code>:</p> </li> <li> <p><code>background_distributed_schedule_pool_size</code>:</p> </li> <li> <p><code>background_buffer_flush_schedule_pool_size</code>:</p> </li> <li> <p><code>background_message_broker_schedule_pool_size</code>:</p> </li> <li> <p><code>default_database</code>:     The default database.</p> <p>To get a list of cluster databases, see <a href="https://cloud.yandex.com/en/docs/managed-clickhouse/operations/databases#list-db">Yandex Managed ClickHouse documentation</a>.</p> </li> <li> <p><code>total_memory_profiler_step</code>:     Sets the memory size (in bytes) for a stack trace at every peak allocation step. Default value: <strong>4194304</strong>.</p> <p>More info see in <a href="https://clickhouse.com/docs/en/operations/server-configuration-parameters/settings/#total-memory-profiler-step">ClickHouse documentation</a>.</p> </li> <li> <p><code>total_memory_tracker_sample_probability</code>:</p> </li> <li> <p><code>background_common_pool_size</code>:     The maximum number of threads that will be used for performing a variety of operations (mostly garbage collection) for *MergeTree-engine tables in a background. Default: 8 Min version: 21.11 See in-depth description in <a href="https://clickhouse.com/docs/en/operations/server-configuration-parameters/settings#background_common_pool_size">ClickHouse documentation</a></p> </li> <li> <p><code>background_merges_mutations_concurrency_ratio</code>:     Sets a ratio between the number of threads and the number of background merges and mutations that can be executed concurrently. For example, if the ratio equals to 2 and background_pool_size is set to 16 then ClickHouse can execute 32 background merges concurrently. This is possible, because background operations could be suspended and postponed. This is needed to give small merges more execution priority. You can only increase this ratio at runtime. To lower it you have to restart the server. The same as for background_pool_size setting background_merges_mutations_concurrency_ratio could be applied from the default profile for backward compatibility. Default: 2 Min_version: 21.11 See in-depth description in <a href="https://clickhouse.com/docs/en/operations/server-configuration-parameters/settings#background_merges_mutations_concurrency_ratio">ClickHouse documentation</a></p> </li> <li> <p><code>query_views_log_enabled</code>:     Default: false Min version: 21.9</p> </li> <li> <p><code>query_views_log_retention_size</code>:     Default: 0</p> </li> <li> <p><code>query_views_log_retention_time</code>:</p> </li> <li> <p><code>asynchronous_metric_log_enabled</code>:     Default: false Min version: 20.11</p> </li> <li> <p><code>asynchronous_metric_log_retention_size</code>:     Default: 0</p> </li> <li> <p><code>asynchronous_metric_log_retention_time</code>:</p> </li> <li> <p><code>opentelemetry_span_log_retention_size</code>:     Default: 0 Min version: 20.11</p> </li> <li> <p><code>opentelemetry_span_log_retention_time</code>:</p> </li> <li> <p><code>session_log_enabled</code>:     Default: false Min version: 21.11</p> </li> <li> <p><code>session_log_retention_size</code>:     Default: 0</p> </li> <li> <p><code>session_log_retention_time</code>:</p> </li> <li> <p><code>zookeeper_log_enabled</code>:     Default: false Min version: 21.9</p> </li> <li> <p><code>zookeeper_log_retention_size</code>:     Default: 0</p> </li> <li> <p><code>zookeeper_log_retention_time</code>:</p> </li> <li> <p><code>asynchronous_insert_log_enabled</code>:     Default: false Min version: 22.10</p> </li> <li> <p><code>asynchronous_insert_log_retention_size</code>:     Default: 0</p> </li> <li> <p><code>asynchronous_insert_log_retention_time</code>:<br> geobase_enabled</p> </li> </ul>|

#### Global Flags

| Flag | Description |
|----|----|
|`--profile`|<b>`string`</b><br/>Set the custom configuration file.|
|`--debug`|Debug logging.|
|`--debug-grpc`|Debug gRPC logging. Very verbose, used for debugging connection problems.|
|`--no-user-output`|Disable printing user intended output to stderr.|
|`--retry`|<b>`int`</b><br/>Enable gRPC retries. By default, retries are enabled with maximum 5 attempts.<br/>Pass 0 to disable retries. Pass any negative value for infinite retries.<br/>Even infinite retries are capped with 2 minutes timeout.|
|`--cloud-id`|<b>`string`</b><br/>Set the ID of the cloud to use.|
|`--folder-id`|<b>`string`</b><br/>Set the ID of the folder to use.|
|`--folder-name`|<b>`string`</b><br/>Set the name of the folder to use (will be resolved to id).|
|`--endpoint`|<b>`string`</b><br/>Set the Cloud API endpoint (host:port).|
|`--token`|<b>`string`</b><br/>Set the OAuth token to use.|
|`--impersonate-service-account-id`|<b>`string`</b><br/>Set the ID of the service account to impersonate.|
|`--format`|<b>`string`</b><br/>Set the output format: text (default), yaml, json, json-rest.|
|`-h`,`--help`|Display help for the command.|
