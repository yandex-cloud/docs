---
title: Updating an {{ AF }} cluster
description: After creating a cluster, you can change its basic and advanced settings.
keywords:
  - Updating an {{ AF }} cluster
  - '{{ AF }} cluster'
  - '{{ AF }}'
  - Airflow
---

# Updating an {{ AF }} cluster

After creating a cluster, you can change its basic and advanced settings.

{% list tabs group=instructions %}

- Management console {#console}

    1. Go to the [folder page]({{ link-console-main }}) and select **{{ ui-key.yacloud.iam.folder.dashboard.label_managed-airflow }}**.

    1. Select the cluster and click **{{ ui-key.yacloud.mdb.cluster.overview.button_action-edit }}** in the top panel.

    1. Under **{{ ui-key.yacloud.mdb.forms.section_base }}**, edit the cluster name and description, delete labels, or add new ones.

    1. Under **{{ ui-key.yacloud.airflow.section_accesses }}**, select a service account or [create a new one](../../iam/operations/sa/create.md#create-sa) with the `managed-airflow.integrationProvider` role. Thus the cluster will get the permissions required for working with user resources. For more information, see [Impersonation](../concepts/impersonation.md).
    1. Under **{{ ui-key.yacloud.mdb.forms.section_network-settings }}**, select a [security group](../../vpc/concepts/security-groups.md) for cluster network traffic or create a new group.

       {% include [sg-ui-access](../../_includes/mdb/maf/note-sg-ui-access.md) %}

    1. Under the settings of {{ maf-name }} [components](../concepts/index.md#components), such as **{{ ui-key.yacloud.airflow.section_webserver }}**, **{{ ui-key.yacloud.airflow.section_scheduler }}**, and **{{ ui-key.yacloud.airflow.section_workers }}**, specify the number of instances and resources.

    1. Under **{{ ui-key.yacloud.airflow.section_triggerer }}**, enable or disable the `Triggerer` service. If it is enabled, specify the number of instances and resources.

    1. Under **{{ ui-key.yacloud.airflow.section_dependencies }}**, delete or add names of pip and deb packages.

    1. Under **{{ ui-key.yacloud.airflow.section_storage }}**, select an existing bucket to store DAG files or create a new one. Make sure to [grant permission](../../storage/operations/buckets/edit-acl.md) for `READ` to this bucket.

    1. Under **{{ ui-key.yacloud.mdb.forms.section_additional }}**, enable or disable deletion protection.

    1. Under **{{ ui-key.yacloud.airflow.section_airflow-configuration }}**:

        * Add, edit, or delete [{{ AF }} additional properties](https://airflow.apache.org/docs/apache-airflow/2.2.4/configurations-ref.html), e.g., the `api.maximum_page_limit` key with `150` for its value.

            Populate the fields manually or import a configuration from a file (see [sample configuration file](https://{{ s3-storage-host }}/doc-files/managed-airflow/airflow.cfg)).

        * Enable or disable the **{{ ui-key.yacloud.airflow.field_lockbox }}** option allowing you to use secrets in [{{ lockbox-full-name }}](../../lockbox/concepts/index.md) to [store {{ AF }} configuration data, variables, and connection parameters](../concepts/impersonation.md#lockbox-integration).

            {% include [sa-roles-for-lockbox](../../_includes/managed-airflow/sa-roles-for-lockbox.md) %}

    1. Under **Logging**, enable or disable log writing. If logging is enabled, specify the log group to write logs to and the minimum logging level. Logs generated by {{ AF }} will be sent to {{ cloud-logging-full-name }}.

    1. Click **{{ ui-key.yacloud.mdb.forms.button_edit }}**.

- CLI {#cli}

    {% include [cli-install](../../_includes/cli-install.md) %}

    {% include [default-catalogue](../../_includes/default-catalogue.md) %}

    To change the cluster settings:

    1. View the description of the update cluster CLI command:

        ```bash
        {{ yc-mdb-af }} cluster update --help
        ```

    1. Provide a list of settings to update in the update cluster command:

        ```bash
        {{ yc-mdb-af }} managed-airflow cluster update <cluster_name_or_ID> \
           --new-name <new_cluster_name> \
           --description <cluster_description> \
           --labels <label_list> \
           --service-account-id <service_account_ID> \
           --security-group-ids <security_group_IDs> \
           --webserver count=<number_of_instances>,`
                      `resource-preset-id=<resource_ID> \
           --scheduler count=<number_of_instances>,`
                      `resource-preset-id=<resource_ID> \
           --worker min-count=<minimum_number_of_instances>,`
                   `max-count=<maximum_number_of_instances>,`
                   `resource-preset-id=<resource_ID> \
           --triggerer count=<number_of_instances>,`
                      `resource-preset-id=<resource_ID> \
           --deb-packages <list_of_deb_packages> \
           --pip-packages <list_of_pip_packages> \
           --dags-bucket <bucket_name> \
           --deletion-protection \
           --lockbox-secrets-backend \
           --log-enabled \
           --log-folder-id <folder_ID> \
           --log-min-level <logging_level>
        ```

        {% include [CLI cluster parameters description](../../_includes/mdb/maf/cli/cluster-parameters.md) %}

        You can request the cluster ID and name with a [list of clusters in the folder](../operations/cluster-list.md#list-clusters).

- {{ TF }} {#tf}

    1. Open the current {{ TF }} configuration file with an infrastructure plan.

        For more information about creating this file, see [Creating clusters](cluster-create.md).

    1. To change cluster settings, update the values of the required fields in the configuration file.

        {% note alert %}

        Do not change the cluster name and password using {{ TF }}. This will delete the existing cluster and create a new one.

        {% endnote %}

        {% include [Terraform cluster parameters description](../../_includes/mdb/maf/terraform/cluster-parameters.md) %}

    1. Make sure the settings are correct.

        {% include [terraform-validate](../../_includes/mdb/terraform/validate.md) %}

    1. Confirm updating the resources.

        {% include [terraform-apply](../../_includes/mdb/terraform/apply.md) %}

    For more information, see the [{{ TF }}]({{ tf-provider-maf }}) provider documentation.

- REST API {#api}

    1. [Get an IAM token for API authentication](../api-ref/authentication.md) and put it into the environment variable:

        {% include [api-auth-token](../../_includes/mdb/api-auth-token.md) %}

    1. Create a file named `body.json` and add the following contents to it:

        ```json
        {
          "updateMask": "<list_of_parameters_to_change>",
          "name": "<cluster_name>",
          "description": "<cluster_description>",
          "labels": { <label_list> },
          "configSpec": {
            "airflow": {
              "config": { <list_of_properties> }
            },
            "webserver": {
              "count": "<number_of_instances>",
              "resources": {
                "resourcePresetId": "<resource_ID>"
              }
            },
            "scheduler": {
              "count": "<number_of_instances>",
              "resources": {
                "resourcePresetId": "<resource_ID>"
              }
            },
            "triggerer": {
              "count": "<number_of_instances>",
              "resources": {
                "resourcePresetId": "<resource_ID>"
              }
            },
            "worker": {
              "minCount": "<minimum_number_of_instances>",
              "maxCount": "<maximum_number_of_instances>",
              "resources": {
                "resourcePresetId": "<resource_ID>"
              }
            },
            "dependencies": {
              "pipPackages": [ <list_of_pip_packages> ],
              "debPackages": [ <list_of_deb_packages> ]
            },
            "lockbox": {
              "enabled": <logging_usage>
            }
          },
          "codeSync": {
            "s3": {
              "bucket": "<bucket_name>"
            }
          },
          "networkSpec": {
            "securityGroupIds": [ <list_of_security_group_IDs> ]
          },
          "deletionProtection": <deletion_protection>,
          "serviceAccountId": "<service_account_ID>",
          "logging": {
            "enabled": <logging_usage>,
            "minLevel": "<logging_level>",
            // Specify either `folderId` or `logGroupId`.
            "folderId": "<folder_ID>",
            "logGroupId": "<log_group_ID>",
          }
        }
        ```

        Where:

        * `updateMask`: List of parameters to update as a single string, separated by commas.

            {% note warning %}

            When updating a cluster, all parameters of the object being changed that were not explicitly set in the request will be overridden with their default values. To avoid this, list the settings you want to change in the `updateMask` parameter.

            {% endnote %}

        * `name`: Cluster name.
        * `description`: Cluster description.
        * `labels`: List of labels. Provide labels in `"<key>": "<value>"` format.
        * `config`: Cluster configuration:

            * `airflow.config`: [{{ AF }} additional properties](https://airflow.apache.org/docs/apache-airflow/2.2.4/configurations-ref.html). Provide them in `"<configuration_section>.<key>": "<value>"` format, such as the following:

                ```bash
                "airflow": {
                  "config": {
                    "core.load_examples": "False"
                  }
                }
                ```

            * `webserver`, `scheduler`, `triggerer`, and `worker`: Configuration of {{ maf-name }} [components](../concepts/index.md#components):

                * `count`: Number of instances in the cluster for the web server, scheduler, and trigger.
                * `minCount` and `maxCount`: Minimum and maximum number of instances in the cluster for the worker.
                * `resources.resourcePresetId`: ID of the web server, scheduler, worker, and trigger computing resources. The possible values are:

                    * `c1-m4` for 1 vCPU and 4 GB RAM
                    * `c2-m8` for 2 vCPUs and 8 GB RAM
                    * `c4-m16` for 4 vCPUs and 16 GB RAM
                    * `c8-m32` for 8 vCPUs and 32 GB RAM

            * `dependencies`: Lists of packages enabling you to install additional libraries and applications for running DAG files in the cluster:

                * `pipPackages`: List of pip packages.
                * `debPackages`: List of deb packages.

                If required, you can set version restrictions for the installed packages, for example:

                ```bash
                "dependencies": {
                  "pipPackages": [
                    "pandas==2.0.2",
                    "scikit-learn>=1.0.0",
                    "clickhouse-driver~=0.2.0"
                  ]
                }
                ```

                The package name format and version are defined by the install command: `pip install` for pip packages and `apt install` for deb packages.

            * `lockbox.enabled`: Enables using secrets in [{{ lockbox-full-name }}](../../lockbox/concepts/index.md) to [store {{ AF }} configuration data, variables, and connection parameters](../concepts/impersonation.md#lockbox-integration). The possible values are `true` or `false`.

        * `network.securityGroupIds`: List of security group IDs.

        * `codeSync.s3.bucket`: Name of the bucket to store DAG files in.
        * `deletionProtection`: Enables cluster protection against accidental deletion. The possible values are `true` or `false`.

            With deletion protection enabled, you will still be able to manually connect to the cluster and delete it.

        * `serviceAccountId`: ID of the [previously created](#before-creating) service account.
        * `logging`: Logging parameters:

            * `enabled`: Enables logging. Logs generated by {{ AF }} components will be sent to {{ cloud-logging-full-name }}. The possible values are `true` or `false`.
            * `minLevel`: Minimum logging level. Possible values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, and `FATAL`.
            * `folderId`: Folder ID. Logs will be written to the default [log group](../../logging/concepts/log-group.md) for this folder.
            * `logGroupId`: Custom log group ID.

            You can only specify either `folderId` or `logGroupId`.

    1. Use the [Cluster.update](../api-ref/Cluster/update.md) method and make a request, e.g., via {{ api-examples.rest.tool }}:

        ```bash
        curl \
            --request PATCH \
            --header "Authorization: Bearer $IAM_TOKEN" \
            --url 'https://airflow.api.cloud.yandex.net/managed-airflow/v1/clusters/<cluster_ID>'
            --data '@body.json'
        ```

        You can get the cluster ID with a [list of clusters in the folder](cluster-list.md#list-clusters).

    1. View the [server response](../api-ref/Cluster/update.md#yandex.cloud.operation.Operation) to make sure the request was successful.

- gRPC API {#grpc-api}

    1. [Get an IAM token for API authentication](../api-ref/authentication.md) and put it into the environment variable:

        {% include [api-auth-token](../../_includes/mdb/api-auth-token.md) %}

    1. {% include [grpc-api-setup-repo](../../_includes/mdb/grpc-api-setup-repo.md) %}

    1. Create a file named `body.json` and add the following contents to it:

        ```json
        {
          "cluster_id": "<cluster_ID>",
          "update_mask": "<list_of_parameters_to_change>",
          "name": "<cluster_name>",
          "description": "<cluster_description>",
          "labels": { <label_list> },
          "config_spec": {
            "airflow": {
              "config": { <list_of_properties> }
            },
            "webserver": {
              "count": "<number_of_instances>",
              "resources": {
                "resource_preset_id": "<resource_ID>"
              }
            },
            "scheduler": {
              "count": "<number_of_instances>",
              "resources": {
                "resource_preset_id": "<resource_ID>"
              }
            },
            "triggerer": {
              "count": "<number_of_instances>",
              "resources": {
                "resource_preset_id": "<resource_ID>"
              }
            },
            "worker": {
              "min_count": "<minimum_number_of_instances>",
              "max_count": "<maximum_number_of_instances>",
              "resources": {
                "resource_preset_id": "<resource_ID>"
              }
            },
            "dependencies": {
              "pip_packages": [ <list_of_pip_packages> ],
              "deb_packages": [ <list_of_deb_packages> ]
            },
            "lockbox": {
              "enabled": <logging_usage>
            }
          },
          "code_sync": {
            "s3": {
              "bucket": "<bucket_name>"
            }
          },
          "network_spec": {
            "security_group_ids": [ <list_of_security_group_IDs> ]
          },
          "deletion_protection": <deletion_protection>,
          "service_account_id": "<service_account_ID>",
          "logging": {
            "enabled": <logging_usage>,
            "min_level": "<logging_level>",
            // Specify either `folderId` or `logGroupId`.
            "folder_id": "<folder_ID>",
            "log_group_id": "<log_group_ID>",
          }
        }
        ```

        Where:

        * `cluster_id`: Cluster ID. You can retrieve it with a [list of clusters in a folder](cluster-list.md#list-clusters).
        * `update_mask`: List of parameters to update as an array of `paths[]` strings.

            {% cut "Format for listing settings" %}

            ```yaml
            "update_mask": {
                "paths": [
                    "<setting_1>",
                    "<setting_2>",
                    ...
                    "<setting_N>"
                ]
            }
            ```

            {% endcut %}

            {% note warning %}

            When updating a cluster, all parameters of the object being changed that were not explicitly set in the request will be overridden with their default values. To avoid this, list the settings you want to change in the `update_mask` parameter.

            {% endnote %}

        * `name`: Cluster name.
        * `description`: Cluster description.
        * `labels`: List of labels. Provide labels in `"<key>": "<value>"` format.
        * `config_spec`: Cluster configuration:

            * `airflow.config`: [{{ AF }} additional properties](https://airflow.apache.org/docs/apache-airflow/2.2.4/configurations-ref.html). Provide them in `"<configuration_section>.<key>": "<value>"` format, such as the following:

                ```bash
                "airflow": {
                  "config": {
                    "core.load_examples": "False"
                  }
                }
                ```

            * `webserver`, `scheduler`, `triggerer`, and `worker`: Configuration of {{ maf-name }} [components](../concepts/index.md#components):

                * `count`: Number of instances in the cluster for the web server, scheduler, and trigger.
                * `min_count` and `max_count`: Minimum and maximum number of instances in the cluster for the worker.
                * `resources.resource_preset_id`: ID of the web server, scheduler, worker, and trigger computing resources. The possible values are:

                    * `c1-m4` for 1 vCPU and 4 GB RAM
                    * `c2-m8` for 2 vCPUs and 8 GB RAM
                    * `c4-m16` for 4 vCPUs and 16 GB RAM
                    * `c8-m32` for 8 vCPUs and 32 GB RAM

            * `dependencies`: Lists of packages enabling you to install additional libraries and applications for running DAG files in the cluster:

                * `pip_packages`: List of pip packages.
                * `deb_packages`: List of deb packages.

                If required, you can set version restrictions for the installed packages, for example:

                ```bash
                "dependencies": {
                  "pip_packages": [
                    "pandas==2.0.2",
                    "scikit-learn>=1.0.0",
                    "clickhouse-driver~=0.2.0"
                  ]
                }
                ```

                The package name format and version are defined by the install command: `pip install` for pip packages and `apt install` for deb packages.

            * `lockbox.enabled`: Enables using secrets in [{{ lockbox-full-name }}](../../lockbox/concepts/index.md) to [store {{ AF }} configuration data, variables, and connection parameters](../concepts/impersonation.md#lockbox-integration). The possible values are `true` or `false`.

        * `network_spec.security_group_ids`: List of security group IDs.
        * `code_sync.s3.bucket`: Name of the bucket to store DAG files in.
        * `deletion_protection`: Enables cluster protection against accidental deletion. The possible values are `true` or `false`.

            With deletion protection enabled, you will still be able to manually connect to the cluster and delete it.

        * `service_account_id`: ID of the [previously created](#before-creating) service account.
        * `logging`: Logging parameters:

            * `enabled`: Enables logging. Logs generated by {{ AF }} components will be sent to {{ cloud-logging-full-name }}. The possible values are `true` or `false`.
            * `min_level`: Minimum logging level. Possible values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, and `FATAL`.
            * `folder_id`: Folder ID. Logs will be written to the default [log group](../../logging/concepts/log-group.md) for this folder.
            * `log_group_id`: Custom log group ID.

            You can only specify either `folder_id` or `log_group_id`.

    1. Use the [ClusterService/Update](../api-ref/grpc/Cluster/update.md) call and make a request, e.g., via {{ api-examples.grpc.tool }}:

        ```bash
        grpcurl \
            -format json \
            -import-path ~/cloudapi/ \
            -import-path ~/cloudapi/third_party/googleapis/ \
            -proto ~/cloudapi/yandex/cloud/airflow/v1/cluster_service.proto \
            -rpc-header "Authorization: Bearer $IAM_TOKEN" \
            -d @ \
            {{ api-host-airflow }}:{{ port-https }} \
            yandex.cloud.airflow.v1.ClusterService.Update \
            < body.json
        ```

    1. View the [server response](../api-ref/grpc/Cluster/create.md#yandex.cloud.operation.Operation) to make sure the request was successful.

{% endlist %}
