openapi: "3.0"
info:
  title: Title not set.
  description: Description not set.
  version: Version not set.
paths: {}
components:
  schemas:
    HDFSInfo:
      type: object
      properties:
        available:
          type: boolean
          format: boolean
        percentRemaining:
          type: number
          format: double
        used:
          type: string
          format: int64
        free:
          type: string
          format: int64
        totalBlocks:
          type: string
          format: int64
        missingBlocks:
          type: string
          format: int64
        missingBlocksReplicaOne:
          type: string
          format: int64
        liveNodes:
          type: array
          items:
            $ref: '#/components/schemas/HDFSNodeInfo'
        deadNodes:
          type: array
          items:
            $ref: '#/components/schemas/HDFSNodeInfo'
        safemode:
          type: string
        decommissioningNodes:
          type: array
          items:
            $ref: '#/components/schemas/HDFSNodeInfo'
        decommissionedNodes:
          type: array
          items:
            $ref: '#/components/schemas/HDFSNodeInfo'
        requestedDecommissionHosts:
          type: array
          items:
            type: string
    HDFSNodeInfo:
      type: object
      properties:
        name:
          type: string
        used:
          type: string
          format: int64
        remaining:
          type: string
          format: int64
        capacity:
          type: string
          format: int64
        numBlocks:
          type: string
          format: int64
        state:
          type: string
    HbaseInfo:
      type: object
      properties:
        available:
          type: boolean
          format: boolean
        regions:
          type: string
          format: int64
        requests:
          type: string
          format: int64
        averageLoad:
          type: number
          format: double
        liveNodes:
          type: array
          items:
            $ref: '#/components/schemas/HbaseNodeInfo'
        deadNodes:
          type: array
          items:
            $ref: '#/components/schemas/HbaseNodeInfo'
    HbaseNodeInfo:
      type: object
      properties:
        name:
          type: string
        requests:
          type: string
          format: int64
        heapSizeMb:
          type: string
          format: int64
        maxHeapSizeMb:
          type: string
          format: int64
    HiveInfo:
      type: object
      properties:
        available:
          type: boolean
          format: boolean
        queriesSucceeded:
          type: string
          format: int64
        queriesFailed:
          type: string
          format: int64
        queriesExecuting:
          type: string
          format: int64
        sessionsOpen:
          type: string
          format: int64
        sessionsActive:
          type: string
          format: int64
    HiveJob:
      type: object
      allOf:
      - type: object
        properties:
          properties:
            description: A mapping of property names to values, used to configure
              Hive.
            type: object
            additionalProperties:
              type: string
          continueOnFailure:
            description: Whether to continue executing queries if a query fails.
            type: boolean
            format: boolean
          scriptVariables:
            description: Mapping of query variable names to values.
            type: object
            additionalProperties:
              type: string
          jarFileUris:
            description: Jar file URIs to add to the CLASSPATHs of the Hive driver
              and tasks.
            type: array
            items:
              type: string
      - title: query_type
        type: object
        maxProperties: 1
        properties:
          queryFileUri:
            description: URI of the script that contains Hive queries.
            type: string
          queryList:
            $ref: '#/components/schemas/QueryList'
    Info:
      type: object
      properties:
        hdfs:
          $ref: '#/components/schemas/HDFSInfo_in_Info_hdfs'
        yarn:
          $ref: '#/components/schemas/YarnInfo_in_Info_yarn'
        hive:
          $ref: '#/components/schemas/HiveInfo_in_Info_hive'
        zookeeper:
          $ref: '#/components/schemas/ZookeeperInfo_in_Info_zookeeper'
        hbase:
          $ref: '#/components/schemas/HbaseInfo_in_Info_hbase'
        oozie:
          $ref: '#/components/schemas/OozieInfo_in_Info_oozie'
        reportCount:
          description: |-
            Report count is incremented every time report is sent by Dataproc Agent.
            So Worker can use this property to make sure that Dataproc Agent got data sent by Worker through Dataproc Manager
            for synchronization purposes
          type: string
          format: int64
        livy:
          $ref: '#/components/schemas/LivyInfo_in_Info_livy'
    Job:
      description: Data Proc job.
      type: object
      allOf:
      - type: object
        properties:
          id:
            description: |-
              Unique ID of the Data Proc job.
              This ID is assigned by MDB in the process of creating Data Proc job.
            type: string
          clusterId:
            description: ID of the Data Proc cluster.
            type: string
          createdAt:
            description: |-
              The time when the Data Proc job was created.

              String in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) text format.
            type: string
            format: date-time
          startedAt:
            description: |-
              The time when the Data Proc job was started.

              String in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) text format.
            type: string
            format: date-time
          finishedAt:
            description: |-
              The time when the Data Proc job was finished.

              String in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) text format.
            type: string
            format: date-time
          name:
            description: Name of the Data Proc job.
            type: string
          createdBy:
            description: The id of the user who created the job
            type: string
          status:
            $ref: '#/components/schemas/JobStatus'
            description: Status.
      - title: job_spec
        type: object
        maxProperties: 1
        properties:
          mapreduceJob:
            $ref: '#/components/schemas/MapreduceJob'
          sparkJob:
            $ref: '#/components/schemas/SparkJob'
          pysparkJob:
            $ref: '#/components/schemas/PysparkJob'
          hiveJob:
            $ref: '#/components/schemas/HiveJob'
    JobStatus:
      type: string
      enum:
      - PROVISIONING
      - PENDING
      - RUNNING
      - ERROR
      - DONE
    ListJobsResponse:
      type: object
      properties:
        jobs:
          description: Requested list of Data Proc jobs.
          type: array
          items:
            $ref: '#/components/schemas/Job'
        nextPageToken:
          description: |-
            This token allows you to get the next page of results for ListJobs requests,
            if the number of results is larger than `page_size` specified in the request.
            To get the next page, specify the value of `next_page_token` as a value for
            the `page_token` parameter in the next ListClusters request. Subsequent ListClusters
            requests will have their own `next_page_token` to continue paging through the results.
          type: string
    LivyInfo:
      type: object
      properties:
        alive:
          type: boolean
          format: boolean
    MapreduceJob:
      type: object
      allOf:
      - type: object
        properties:
          args:
            description: Optional arguments to the driver.
            type: array
            items:
              type: string
          jarFileUris:
            description: URIs of file to run.
            type: array
            items:
              type: string
          fileUris:
            description: URIs of files to be copied to the working directory of Data
              Proc drivers and distributed tasks.
            type: array
            items:
              type: string
          archiveUris:
            description: URIs of archives to be extracted in the working directory
              of Data Proc drivers and tasks.
            type: array
            items:
              type: string
          properties:
            description: A mapping of property names to values, used to configure
              Data Proc.
            type: object
            additionalProperties:
              type: string
      - title: driver
        type: object
        maxProperties: 1
        properties:
          mainJarFileUri:
            description: The HCFS URI of the jar file containing the main class.
            type: string
          mainClass:
            description: The name of the driver's main class.
            type: string
    OozieInfo:
      type: object
      properties:
        alive:
          type: boolean
          format: boolean
    PysparkJob:
      type: object
      properties:
        args:
          description: Optional arguments to the driver.
          type: array
          items:
            type: string
        jarFileUris:
          description: Jar file URIs to add to the CLASSPATHs of the Data Proc driver
            and tasks.
          type: array
          items:
            type: string
        fileUris:
          description: URIs of files to be copied to the working directory of Data
            Proc drivers and distributed tasks.
          type: array
          items:
            type: string
        archiveUris:
          description: URIs of archives to be extracted in the working directory of
            Data Proc drivers and tasks.
          type: array
          items:
            type: string
        properties:
          description: A mapping of property names to values, used to configure Data
            Proc.
          type: object
          additionalProperties:
            type: string
        mainPythonFileUri:
          description: URI of the main Python file to use as the driver. Must be a
            .py file.
          type: string
        pythonFileUris:
          description: URIs of Python files to pass to the PySpark framework.
          type: array
          items:
            type: string
    QueryList:
      type: object
      properties:
        queries:
          type: array
          items:
            type: string
    ReportReply:
      description: The response message containing the agent commands to apply on
        host.
      type: object
      properties:
        decommissionTimeout:
          type: string
          format: int64
        yarnHostsToDecommission:
          type: array
          items:
            type: string
        hdfsHostsToDecommission:
          type: array
          items:
            type: string
    SparkJob:
      type: object
      properties:
        args:
          description: Optional arguments to the driver.
          type: array
          items:
            type: string
        jarFileUris:
          description: Jar file URIs to add to the CLASSPATHs of the Data Proc driver
            and tasks.
          type: array
          items:
            type: string
        fileUris:
          description: URIs of files to be copied to the working directory of Data
            Proc drivers and distributed tasks.
          type: array
          items:
            type: string
        archiveUris:
          description: URIs of archives to be extracted in the working directory of
            Data Proc drivers and tasks.
          type: array
          items:
            type: string
        properties:
          description: A mapping of property names to values, used to configure Data
            Proc.
          type: object
          additionalProperties:
            type: string
        mainJarFileUri:
          description: The HCFS URI of the jar file containing the main class.
          type: string
        mainClass:
          description: The name of the driver's main class.
          type: string
    UpdateJobStatusResponse:
      type: object
      properties: {}
    YarnInfo:
      type: object
      properties:
        available:
          type: boolean
          format: boolean
        liveNodes:
          type: array
          items:
            $ref: '#/components/schemas/YarnNodeInfo'
        requestedDecommissionHosts:
          type: array
          items:
            type: string
    YarnNodeInfo:
      type: object
      properties:
        name:
          type: string
        state:
          type: string
        numContainers:
          type: string
          format: int64
        usedMemoryMb:
          type: string
          format: int64
        availableMemoryMb:
          type: string
          format: int64
        updateTime:
          type: string
          format: int64
    ZookeeperInfo:
      type: object
      properties:
        alive:
          type: boolean
          format: boolean
    HDFSInfo_in_Info_hdfs:
      type: object
      properties:
        available:
          type: boolean
          format: boolean
        percentRemaining:
          type: number
          format: double
        used:
          type: string
          format: int64
        free:
          type: string
          format: int64
        totalBlocks:
          type: string
          format: int64
        missingBlocks:
          type: string
          format: int64
        missingBlocksReplicaOne:
          type: string
          format: int64
        liveNodes:
          type: array
          items:
            $ref: '#/components/schemas/HDFSNodeInfo'
        deadNodes:
          type: array
          items:
            $ref: '#/components/schemas/HDFSNodeInfo'
        safemode:
          type: string
        decommissioningNodes:
          type: array
          items:
            $ref: '#/components/schemas/HDFSNodeInfo'
        decommissionedNodes:
          type: array
          items:
            $ref: '#/components/schemas/HDFSNodeInfo'
        requestedDecommissionHosts:
          type: array
          items:
            type: string
    YarnInfo_in_Info_yarn:
      type: object
      properties:
        available:
          type: boolean
          format: boolean
        liveNodes:
          type: array
          items:
            $ref: '#/components/schemas/YarnNodeInfo'
        requestedDecommissionHosts:
          type: array
          items:
            type: string
    HiveInfo_in_Info_hive:
      type: object
      properties:
        available:
          type: boolean
          format: boolean
        queriesSucceeded:
          type: string
          format: int64
        queriesFailed:
          type: string
          format: int64
        queriesExecuting:
          type: string
          format: int64
        sessionsOpen:
          type: string
          format: int64
        sessionsActive:
          type: string
          format: int64
    ZookeeperInfo_in_Info_zookeeper:
      type: object
      properties:
        alive:
          type: boolean
          format: boolean
    HbaseInfo_in_Info_hbase:
      type: object
      properties:
        available:
          type: boolean
          format: boolean
        regions:
          type: string
          format: int64
        requests:
          type: string
          format: int64
        averageLoad:
          type: number
          format: double
        liveNodes:
          type: array
          items:
            $ref: '#/components/schemas/HbaseNodeInfo'
        deadNodes:
          type: array
          items:
            $ref: '#/components/schemas/HbaseNodeInfo'
    OozieInfo_in_Info_oozie:
      type: object
      properties:
        alive:
          type: boolean
          format: boolean
    LivyInfo_in_Info_livy:
      type: object
      properties:
        alive:
          type: boolean
          format: boolean
tags:
- name: Job
- name: DataprocManager
  description: Data Proc manager service defifnition
