openapi: "3.0"
info:
  title: Yandex Data Proc API
  description: This API reference is organized by resource. Actions are performed
    by sending HTTP requests to resource URLs or making RPC calls. For more information
    about Yandex.Cloud API architecture, see [API Concepts](/docs/api-design-guide/).
  version: v1
  x-y-docUri: api-ref
  x-y-baseUrl: https://dataproc.api.cloud.yandex.net
paths:
  /dataproc/v1/clusters/{clusterId}:
    get:
      tags:
      - Cluster
      summary: Returns the specified Dataproc cluster.
      operationId: ClusterGet
      parameters:
      - name: clusterId
        in: path
        description: |-
          Required.
          ID of the Dataproc cluster.
          This ID is assigned by Dataproc at creation time.

          The maximum string length in characters is 50.
        required: true
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Cluster'
      x-y-navtitle: get
    delete:
      tags:
      - Cluster
      summary: Deletes the specified Dataproc cluster.
      operationId: ClusterDelete
      parameters:
      - name: clusterId
        in: path
        description: |-
          Required.
          ID of the Dataproc cluster.
          This ID is assigned by Dataproc at creation time.

          The maximum string length in characters is 50.
        required: true
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      x-y-navtitle: delete
      x-y-operation-metadata:
        $ref: '#/components/schemas/DeleteClusterMetadata'
      x-y-operation-response: Empty
    patch:
      tags:
      - Cluster
      summary: Updates configuration of the specified Dataproc cluster.
      operationId: ClusterUpdate
      parameters:
      - name: clusterId
        in: path
        description: |-
          ID of the Dataproc cluster.
          This ID is assigned by Dataproc at creation time.

          The maximum string length in characters is 50.
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateClusterRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      x-y-navtitle: update
      x-y-operation-metadata:
        $ref: '#/components/schemas/UpdateClusterMetadata'
      x-y-operation-response: '[Cluster](/docs/data-proc/api-ref/Cluster#representation)'
  /dataproc/v1/clusters:
    get:
      tags:
      - Cluster
      summary: Retrieves a list of Dataproc clusters.
      operationId: ClusterList
      parameters:
      - name: folderId
        in: query
        description: |-
          Required.
          ID of the folder that the Dataproc cluster belongs to.

          The maximum string length in characters is 50.
        schema:
          type: string
      - name: pageSize
        in: query
        description: |-
          The maximum number of results per page that should be returned. If the number of available
          results is larger than `page_size`, the service returns a `next_page_token` that can be used
          to get the next page of results in subsequent ListClusters requests.
          Acceptable values are 0 to 1000, inclusive. Default value: 100.

          The maximum value is 1000.
        schema:
          type: string
          format: int64
      - name: pageToken
        in: query
        description: |-
          Page token. Set `page_token` to the `next_page_token` returned by a previous ListClusters
          request to get the next page of results.

          The maximum string length in characters is 100.
        schema:
          type: string
      - name: filter
        in: query
        description: |-
          String that describes a display filter.

          The maximum string length in characters is 1000.
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListClustersResponse'
      x-y-navtitle: list
    post:
      tags:
      - Cluster
      summary: Creates a Dataproc cluster.
      operationId: ClusterCreate
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateClusterRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      x-y-navtitle: create
      x-y-operation-metadata:
        $ref: '#/components/schemas/CreateClusterMetadata'
      x-y-operation-response: '[Cluster](/docs/data-proc/api-ref/Cluster#representation)'
  /dataproc/v1/clusters/{clusterId}:start:
    post:
      tags:
      - Cluster
      summary: Start the specified Dataproc cluster.
      operationId: ClusterStart
      parameters:
      - name: clusterId
        in: path
        description: |-
          Required.
          ID of the Dataproc cluster.
          This ID is assigned by Dataproc at creation time.

          The maximum string length in characters is 50.
        required: true
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      x-y-navtitle: start
      x-y-operation-metadata:
        $ref: '#/components/schemas/StartClusterMetadata'
      x-y-operation-response: '[Cluster](/docs/data-proc/api-ref/Cluster#representation)'
  /dataproc/v1/clusters/{clusterId}:stop:
    post:
      tags:
      - Cluster
      summary: Stop the specified Dataproc cluster.
      operationId: ClusterStop
      parameters:
      - name: clusterId
        in: path
        description: |-
          Required.
          ID of the Dataproc cluster.
          This ID is assigned by Dataproc at creation time.

          The maximum string length in characters is 50.
        required: true
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      x-y-navtitle: stop
      x-y-operation-metadata:
        $ref: '#/components/schemas/StopClusterMetadata'
      x-y-operation-response: '[Cluster](/docs/data-proc/api-ref/Cluster#representation)'
  /dataproc/v1/clusters/{clusterId}/operations:
    get:
      tags:
      - Cluster
      operationId: ClusterListOperations
      parameters:
      - name: clusterId
        in: path
        description: |-
          Required.
          ID of the Dataproc cluster.
          This ID is assigned by Dataproc at creation time.

          The maximum string length in characters is 50.
        required: true
        schema:
          type: string
      - name: pageSize
        in: query
        description: |-
          The maximum number of results per page that should be returned. If the number of available
          results is larger than `page_size`, the service returns a `next_page_token` that can be used
          to get the next page of results in subsequent ListOperations requests.
          Acceptable values are 0 to 1000, inclusive. Default value: 100.

          The maximum value is 1000.
        schema:
          type: string
          format: int64
      - name: pageToken
        in: query
        description: |-
          Page token. Set `page_token` to the `next_page_token` returned by a previous ListOperations
          request to get the next page of results.

          The maximum string length in characters is 100.
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListClusterOperationsResponse'
      x-y-navtitle: listOperations
  /dataproc/v1/clusters/{clusterId}/hosts:
    get:
      tags:
      - Cluster
      summary: Retrieves a list of hosts.
      operationId: ClusterListHosts
      parameters:
      - name: clusterId
        in: path
        description: |-
          ID of the Dataproc cluster.
          This ID is assigned by Dataproc at creation time.

          The maximum string length in characters is 50.
        required: true
        schema:
          type: string
      - name: pageSize
        in: query
        description: |-
          The maximum number of results per page that should be returned. If the number of available
          results is larger than `page_size`, the service returns a `next_page_token` that can be used
          to get the next page of results in subsequent ListClusterHosts requests.
          Acceptable values are 0 to 1000, inclusive. Default value: 100.

          The maximum value is 1000.
        schema:
          type: string
          format: int64
      - name: pageToken
        in: query
        description: |-
          Page token. Set `page_token` to the `next_page_token` returned by a previous ListClusterHosts
          request to get the next page of results.

          The maximum string length in characters is 100.
        schema:
          type: string
      - name: filter
        in: query
        description: |-
          String that describes a display filter.

          The maximum string length in characters is 1000.
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListClusterHostsResponse'
      x-y-navtitle: listHosts
  /dataproc/v1/clusters/{clusterId}/jobs:
    get:
      tags:
      - Job
      summary: Retrieves a list of jobs for Dataproc cluster.
      operationId: JobList
      parameters:
      - name: clusterId
        in: path
        description: |-
          Required. ID of the cluster to list Dataproc jobs of.

          The maximum string length in characters is 50.
        required: true
        schema:
          type: string
      - name: pageSize
        in: query
        description: "The maximum number of results per page that should be returned.
          If the number of available\r\nresults is larger than `page_size`, the service
          returns a `next_page_token` that can be used\r\nto get the next page of
          results in subsequent ListJobs requests.\r\nAcceptable values are 0 to 1000,
          inclusive. Default value: 100.\n\nThe maximum value is 1000."
        schema:
          type: string
          format: int64
      - name: pageToken
        in: query
        description: "Page token. Set `page_token` to the `next_page_token` returned
          by a previous ListJobs\r\nrequest to get the next page of results.\n\nThe
          maximum string length in characters is 100."
        schema:
          type: string
      - name: filter
        in: query
        description: |-
          String that describes a display filter.

          The maximum string length in characters is 1000.
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListJobsResponse'
      x-y-navtitle: list
    post:
      tags:
      - Job
      summary: Creates a job for Dataproc cluster.
      operationId: JobCreate
      parameters:
      - name: clusterId
        in: path
        description: |-
          Required. ID of the cluster to create Dataproc job in.

          The maximum string length in characters is 50.
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateJobRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      x-y-navtitle: create
      x-y-operation-metadata:
        $ref: '#/components/schemas/CreateJobMetadata'
      x-y-operation-response: '[Job](/docs/data-proc/api-ref/Job#representation)'
  /dataproc/v1/clusters/{clusterId}/jobs/{jobId}:
    get:
      tags:
      - Job
      summary: Returns the specified Dataproc cluster.
      operationId: JobGet
      parameters:
      - name: clusterId
        in: path
        description: |-
          Required.
          Required. ID of the Dataproc cluster.

          The maximum string length in characters is 50.
        required: true
        schema:
          type: string
      - name: jobId
        in: path
        description: |-
          Required.
          Required. ID of the Dataproc job to return.

          The maximum string length in characters is 50.
        required: true
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Job'
      x-y-navtitle: get
  /dataproc/v1/clusters/{clusterId}/subclusters/{subclusterId}:
    get:
      tags:
      - Subcluster
      summary: Returns the specified Dataproc subcluster resource.
      description: To get the list of available Dataproc subcluster resources, make
        a [list](/docs/data-proc/api-ref/Subcluster/list) request.
      operationId: SubclusterGet
      parameters:
      - name: clusterId
        in: path
        description: |-
          Required.
          ID of the Dataproc cluster to get subcluster from.

          The maximum string length in characters is 50.
        required: true
        schema:
          type: string
      - name: subclusterId
        in: path
        description: |-
          Required.
          ID of the Dataproc subcluster resource to return.
          To get the subcluster ID use a [list](/docs/data-proc/api-ref/Subcluster/list) request.

          The maximum string length in characters is 50.
        required: true
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Subcluster'
      x-y-navtitle: get
    delete:
      tags:
      - Subcluster
      summary: Deletes the specified Dataproc subcluster.
      operationId: SubclusterDelete
      parameters:
      - name: clusterId
        in: path
        description: |-
          Required.
          ID of the Dataproc cluster to delete subcluster from.
          To get the Dataproc cluster ID, use a [list](/docs/data-proc/api-ref/Cluster/list) request.

          The maximum string length in characters is 50.
        required: true
        schema:
          type: string
      - name: subclusterId
        in: path
        description: |-
          Required.
          ID of the Dataproc subcluster resource to delete.

          The maximum string length in characters is 50.
        required: true
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      x-y-navtitle: delete
      x-y-operation-metadata:
        $ref: '#/components/schemas/DeleteSubclusterMetadata'
      x-y-operation-response: Empty
    patch:
      tags:
      - Subcluster
      summary: Updates configuration of the specified Dataproc subcluster.
      operationId: SubclusterUpdate
      parameters:
      - name: clusterId
        in: path
        description: |-
          Required.
          ID of the Dataproc cluster to update subcluster to.
          To get the Dataproc cluster ID, use a [list](/docs/data-proc/api-ref/Cluster/list) request.

          The maximum string length in characters is 50.
        required: true
        schema:
          type: string
      - name: subclusterId
        in: path
        description: |-
          Required.
          ID of the Dataproc subcluster resource.
          To get the subcluster ID use a [list](/docs/data-proc/api-ref/Subcluster/list) request.

          The maximum string length in characters is 50.
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateSubclusterRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      x-y-navtitle: update
      x-y-operation-metadata:
        $ref: '#/components/schemas/UpdateSubclusterMetadata'
      x-y-operation-response: '[Subcluster](/docs/data-proc/api-ref/Subcluster#representation)'
  /dataproc/v1/clusters/{clusterId}/subclusters:
    get:
      tags:
      - Subcluster
      summary: Retrieves a list of Dataproc subcluster.
      operationId: SubclusterList
      parameters:
      - name: clusterId
        in: path
        description: |-
          Required.
          ID of the Dataproc cluster to get subclusters from.

          The maximum string length in characters is 50.
        required: true
        schema:
          type: string
      - name: pageSize
        in: query
        description: |-
          The maximum number of results per page that should be returned. If the number of available
          results is larger than `page_size`, the service returns a `next_page_token` that can be used
          to get the next page of results in subsequent ListSubclusters requests.
          Acceptable values are 0 to 1000, inclusive. Default value: 100.

          The maximum value is 1000.
        schema:
          type: string
          format: int64
      - name: pageToken
        in: query
        description: |-
          Page token. Set `page_token` to the `next_page_token` returned by a previous ListSubclusters
          request to get the next page of results.

          The maximum string length in characters is 100.
        schema:
          type: string
      - name: filter
        in: query
        description: |-
          A filter expression that filters resources listed in the response.
          The expression must specify:
          1. The field name. Currently you can only use filtering with the [Cluster.name](/docs/data-proc/api-ref/Cluster#representation) field.
          2. An operator. Can be either `=` or `!=` for single values, `IN` or `NOT IN` for lists of values.
          3. The value. Мust be 1-63 characters long and match the regular expression `^[a-zA-Z0-9_-]+$`.

          The maximum string length in characters is 1000.
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListSubclustersResponse'
      x-y-navtitle: list
    post:
      tags:
      - Subcluster
      summary: Creates a Dataproc subcluster in the specified cluster.
      operationId: SubclusterCreate
      parameters:
      - name: clusterId
        in: path
        description: |-
          Required.
          ID of the Dataproc cluster to create create subcluster to.
          To get the Dataproc cluster ID, use a [list](/docs/data-proc/api-ref/Cluster/list) request.

          The maximum string length in characters is 50.
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateSubclusterRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Operation'
      x-y-navtitle: create
      x-y-operation-metadata:
        $ref: '#/components/schemas/CreateSubclusterMetadata'
      x-y-operation-response: '[Subcluster](/docs/data-proc/api-ref/Subcluster#representation)'
components:
  schemas:
    Cluster:
      description: |-
        Description of a Dataproc cluster. For more information, see
        the Yandex Dataproc [documentation](/docs/data-proc/concepts/).
      type: object
      properties:
        id:
          description: |-
            ID of the Dataproc cluster.
            This ID is assigned by Dataproc at creation time.
          type: string
        folderId:
          description: ID of the folder that the Dataproc cluster belongs to.
          type: string
        createdAt:
          description: |-
            Creation timestamp in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) text format.

            String in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) text format.
          type: string
          format: date-time
        name:
          description: |-
            Name of the Dataproc cluster.
            The name is unique within the folder. 1-64 characters long.
          type: string
        description:
          description: Description of the Dataproc cluster. 0-256 characters long.
          type: string
        labels:
          description: |-
            Custom labels for the Dataproc cluster as `` key:value `` pairs.
            Maximum 64 per resource.
          type: object
          additionalProperties:
            type: string
        monitoring:
          description: Monitoring systems relevant to the Dataproc cluster.
          type: array
          items:
            $ref: '#/components/schemas/Monitoring'
        config:
          $ref: '#/components/schemas/ClusterConfig_in_Cluster_config'
        health:
          $ref: '#/components/schemas/Health_in_Cluster_health'
        status:
          $ref: '#/components/schemas/ClusterStatus_in_Cluster_status'
        zoneId:
          description: ID of the availability zone.
          type: string
        serviceAccountId:
          description: ID of service account for Dataproc manager agent.
          type: string
        bucket:
          description: Object storage bucket name for Dataproc jobs.
          type: string
    ClusterConfig:
      type: object
      properties:
        versionId:
          description: |-
            Version of image for cluster provisioning.
            All available versions are listed in the [documentation](/docs/managed-hadoop/concepts/image-versions).
          type: string
        hadoop:
          $ref: '#/components/schemas/HadoopConfig_in_ClusterConfig_hadoop'
    ClusterStatus:
      description: |2-
         - STATUS_UNKNOWN: Cluster state is unknown.
         - CREATING: Cluster is being created.
         - RUNNING: Cluster is running normally.
         - ERROR: Cluster encountered a problem and cannot operate.
         - STOPPING: Cluster is stopping.
         - STOPPED: Cluster stopped.
         - STARTING: Cluster is starting.
      type: string
      enum:
      - STATUS_UNKNOWN
      - CREATING
      - RUNNING
      - ERROR
      - STOPPING
      - STOPPED
      - STARTING
      default: STATUS_UNKNOWN
    CreateClusterConfigSpec:
      type: object
      properties:
        versionId:
          description: |-
            Vesion of image for cluster provisioning.
            All available versions are listed in the [documentation](/docs/data-proc/concepts/image-versions).
          type: string
        hadoop:
          $ref: '#/components/schemas/HadoopConfig_in_CreateClusterConfigSpec_hadoop'
        subclustersSpec:
          description: Subclusters configuration.
          type: array
          items:
            $ref: '#/components/schemas/CreateSubclusterConfigSpec'
    CreateClusterMetadata:
      type: object
      properties:
        clusterId:
          description: |-
            ID of the Dataproc cluster.
            This ID is assigned by Dataproc at creation time.
          type: string
    CreateClusterRequest:
      type: object
      properties:
        folderId:
          description: |-
            Required.
            ID of the folder that the Dataproc cluster belongs to.

            The maximum string length in characters is 50.
          type: string
        name:
          description: |-
            Name of the Dataproc cluster. The name must be unique within the folder.
            The name must be 1-63 characters long and match the regular expression `^[a-z]([-a-z0-9]{,61}[a-z0-9])?$`.
            The name can’t be changed after the Dataproc cluster is created.

            Value must match the regular expression `` |[a-z][-a-z0-9]{1,61}[a-z0-9] ``.
          type: string
        description:
          description: |-
            Description of the Dataproc cluster. 0-256 characters long.

            The maximum string length in characters is 256.
          type: string
        labels:
          description: |-
            Custom labels for the Dataproc cluster as `` key:value `` pairs.
            Maximum 64 per resource.

            No more than 64 per resource.
            The string length in characters for each key must be 1-63.
            Each key must match the regular expression `` [a-z][-_0-9a-z]* ``.
            The maximum string length in characters for each value is 63.
            Each value must match the regular expression `` [-_0-9a-z]* ``.
          type: object
          additionalProperties:
            type: string
        configSpec:
          $ref: '#/components/schemas/CreateClusterConfigSpec_in_CreateClusterRequest_configSpec'
        zoneId:
          description: |-
            Required.
            ID of the availability zone.

            The maximum string length in characters is 50.
          type: string
        serviceAccountId:
          description: |-
            Required.
            ID of the service account for Dataproc manager agent
          type: string
        bucket:
          description: Name of object storage bucket for Dataproc jobs.
          type: string
    CreateJobMetadata:
      type: object
      properties:
        clusterId:
          description: |-
            Required.
            ID of the Dataproc cluster.

            The maximum string length in characters is 50.
          type: string
        jobId:
          description: |-
            ID of the Dataproc job.

            The maximum string length in characters is 50.
          type: string
    CreateJobRequest:
      type: object
      allOf:
      - type: object
        properties:
          name:
            description: |-
              Optional. Name of the job.

              Value must match the regular expression `` |[a-z][-a-z0-9]{1,61}[a-z0-9] ``.
            type: string
      - title: job_spec
        type: object
        maxProperties: 1
        properties:
          mapreduceJob:
            $ref: '#/components/schemas/MapreduceJob'
          sparkJob:
            $ref: '#/components/schemas/SparkJob'
          pysparkJob:
            $ref: '#/components/schemas/PysparkJob'
          hiveJob:
            $ref: '#/components/schemas/HiveJob'
    CreateSubclusterConfigSpec:
      type: object
      properties:
        name:
          description: |-
            Name of Dataproc subcluster.

            Value must match the regular expression `` |[a-z][-a-z0-9]{1,61}[a-z0-9] ``.
          type: string
        role:
          $ref: '#/components/schemas/Role_in_CreateSubclusterConfigSpec_role'
        resources:
          $ref: '#/components/schemas/Resources_in_CreateSubclusterConfigSpec_resources'
        subnetId:
          description: |-
            Required.
            ID of using compute subnet for hosts in subcluster.

            The maximum string length in characters is 50.
          type: string
        hostsCount:
          description: |-
            Required.
            Number of hosts in subcluster

            The minimum value is 1.
          type: string
          format: int64
    CreateSubclusterMetadata:
      type: object
      properties:
        clusterId:
          description: |-
            ID of the Dataproc cluster resource to return.

            The maximum string length in characters is 50.
          type: string
        subclusterId:
          description: |-
            ID of the Dataproc subcluster resource.

            The maximum string length in characters is 50.
          type: string
    CreateSubclusterRequest:
      type: object
      properties:
        name:
          description: |-
            Name of the Dataproc subcluster. The name must be unique within the folder.
            The name must be 1-63 characters long and match the regular expression `^[a-z]([-a-z0-9]{,61}[a-z0-9])?$`.
            The name can’t be changed after the Dataproc subcluster is created.

            Value must match the regular expression `` |[a-z][-a-z0-9]{1,61}[a-z0-9] ``.
          type: string
        role:
          $ref: '#/components/schemas/Role_in_CreateSubclusterRequest_role'
        resources:
          $ref: '#/components/schemas/Resources_in_CreateSubclusterRequest_resources'
        subnetId:
          description: |-
            Required.
            ID of using compute subnet for hosts in subcluster.

            The maximum string length in characters is 50.
          type: string
        hostsCount:
          description: |-
            Required.
            Number of hosts in subcluster.

            The minimum value is 1.
          type: string
          format: int64
    DeleteClusterMetadata:
      type: object
      properties:
        clusterId:
          description: |-
            ID of the Dataproc cluster.
            This ID is assigned by Dataproc at creation time.
          type: string
    DeleteSubclusterMetadata:
      type: object
      properties:
        clusterId:
          description: |-
            ID of the Dataproc cluster resource to return.

            The maximum string length in characters is 50.
          type: string
        subclusterId:
          description: |-
            ID of the Dataproc subcluster resource to delete.

            The maximum string length in characters is 50.
          type: string
    Empty:
      description: Empty JSON object `` {} ``.
      type: object
      maxProperties: 0
    FieldMask:
      description: |-
        A comma-separated names off ALL fields to be updated.
        Оnly the specified fields will be changed. The others will be left untouched.
        If the field is specified in `` updateMask `` and no value for that field was sent in the request,
        the field's value will be reset to the default. The default value for most fields is null or 0.

        If `` updateMask `` is not sent in the request, all fields' values will be updated.
        Fields specified in the request will be updated to provided values.
        The rest of the fields will be reset to the default.
      type: string
    HadoopConfig:
      description: |-
        Configuration, that describes application logic of installed services,
        their properties and settings.
      type: object
      properties:
        services:
          description: List of used services in cluster (for default use empty)
          type: array
          items:
            $ref: '#/components/schemas/HadoopConfigService'
        properties:
          description: |-
            Properties passed to all hosts *-site.xml configurations.
            In key you need to use prefix 'hdfs:dfs.replication' for setting
            property 'dfs.replication' in /etc/hadoop/conf/hdfs-site.xml
          type: object
          additionalProperties:
            type: string
        sshPublicKeys:
          description: List of ssh public keys to access to cluster hosts.
          type: array
          items:
            type: string
    HadoopConfigService:
      type: string
      enum:
      - HDFS
      - YARN
      - MAPREDUCE
      - HIVE
      - TEZ
      - ZOOKEEPER
      - HBASE
      - SQOOP
      - FLUME
      - SPARK
      - ZEPPELIN
      - OOZIE
    Health:
      description: |2-
         - HEALTH_UNKNOWN: State of the cluster is unknown ([Host.health] for every host in the cluster is UNKNOWN).
         - ALIVE: Cluster is alive and well ([Host.health] for every host in the cluster is ALIVE).
         - DEAD: Cluster is inoperable ([Host.health] for every host in the cluster is DEAD).
         - DEGRADED: Cluster is working below capacity ([Host.health] for at least one host in the cluster is not ALIVE).
      type: string
      enum:
      - HEALTH_UNKNOWN
      - ALIVE
      - DEAD
      - DEGRADED
      default: HEALTH_UNKNOWN
    HiveJob:
      type: object
      allOf:
      - type: object
        properties:
          properties:
            description: A mapping of property names to values, used to configure
              Hive.
            type: object
            additionalProperties:
              type: string
          continueOnFailure:
            description: Whether to continue executing queries if a query fails.
            type: boolean
            format: boolean
          scriptVariables:
            description: Mapping of query variable names to values.
            type: object
            additionalProperties:
              type: string
          jarFileUris:
            description: Jar file URIs to add to the CLASSPATHs of the Hive driver
              and tasks.
            type: array
            items:
              type: string
      - title: query_type
        type: object
        maxProperties: 1
        properties:
          queryFileUri:
            description: URI of the script that contains Hive queries.
            type: string
          queryList:
            $ref: '#/components/schemas/QueryList'
    Host:
      description: |-
        A Dataproc Host resource. For more information, see
        the [Concepts](/docs/data-proc/concepts) section of the documentation.
      type: object
      properties:
        name:
          description: |-
            Name of the Dataproc host. The host name is assigned by Dataproc at creation time, and cannot be changed.
            1-63 characters long.

            The name is unique across all existing Dataproc hosts in Yandex.Cloud, as it defines the FQDN of the host.
          type: string
        subclusterId:
          description: ID of Dataproc subcluster host. The ID is assigned by Dataproc
            at creation time.
          type: string
        health:
          $ref: '#/components/schemas/Health_in_Host_health'
        computeInstanceId:
          description: ID of compute instance appropriated to the Dataproc host.
          type: string
        role:
          $ref: '#/components/schemas/Role_in_Host_role'
    Job:
      description: Dataproc job.
      type: object
      allOf:
      - type: object
        properties:
          id:
            description: |-
              Required. Unique ID of the Dataproc job.
              This ID is assigned by MDB in the process of creating Dataproc job.
            type: string
          clusterId:
            description: Required. Unique ID of the Dataproc cluster.
            type: string
          createdAt:
            description: |-
              The time when the Dataproc job was created.

              String in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) text format.
            type: string
            format: date-time
          startedAt:
            description: |-
              The time when the Dataproc job was started.

              String in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) text format.
            type: string
            format: date-time
          finishedAt:
            description: |-
              The time when the Dataproc job was finished.

              String in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) text format.
            type: string
            format: date-time
          name:
            description: Name of the Dataproc job.
            type: string
          status:
            $ref: '#/components/schemas/JobStatus'
            description: Status.
      - title: job_spec
        type: object
        maxProperties: 1
        properties:
          mapreduceJob:
            $ref: '#/components/schemas/MapreduceJob'
          sparkJob:
            $ref: '#/components/schemas/SparkJob'
          pysparkJob:
            $ref: '#/components/schemas/PysparkJob'
          hiveJob:
            $ref: '#/components/schemas/HiveJob'
    JobStatus:
      type: string
      enum:
      - PROVISIONING
      - PENDING
      - RUNNING
      - ERROR
      - DONE
    ListClusterHostsResponse:
      type: object
      properties:
        hosts:
          description: Requested list of hosts.
          type: array
          items:
            $ref: '#/components/schemas/Host'
        nextPageToken:
          description: |-
            This token allows you to get the next page of results for ListClusterHosts requests,
            if the number of results is larger than `page_size` specified in the request.
            To get the next page, specify the value of `next_page_token` as a value for
            the `page_token` parameter in the next ListSubclusterHosts request. Subsequent ListClusterHosts
            requests will have their own `next_page_token` to continue paging through the results.
          type: string
    ListClusterOperationsResponse:
      type: object
      properties:
        operations:
          type: array
          items:
            $ref: '#/components/schemas/Operation'
        nextPageToken:
          description: |-
            This token allows you to get the next page of results for ListOperations requests,
            if the number of results is larger than `page_size` specified in the request.
            To get the next page, specify the value of `next_page_token` as a value for
            the `page_token` parameter in the next ListOperations request. Subsequent ListOperations
            requests will have their own `next_page_token` to continue paging through the results.
          type: string
    ListClustersResponse:
      type: object
      properties:
        clusters:
          description: Requested list of Dataproc clusters.
          type: array
          items:
            $ref: '#/components/schemas/Cluster'
        nextPageToken:
          description: |-
            This token allows you to get the next page of results for ListClusters requests,
            if the number of results is larger than `page_size` specified in the request.
            To get the next page, specify the value of `next_page_token` as a value for
            the `page_token` parameter in the next ListClusters request. Subsequent ListClusters
            requests will have their own `next_page_token` to continue paging through the results.
          type: string
    ListJobsResponse:
      type: object
      properties:
        jobs:
          description: Requested list of Dataproc jobs.
          type: array
          items:
            $ref: '#/components/schemas/Job'
        nextPageToken:
          description: "This token allows you to get the next page of results for
            ListJobs requests,\r\nif the number of results is larger than `page_size`
            specified in the request.\r\nTo get the next page, specify the value of
            `next_page_token` as a value for\r\nthe `page_token` parameter in the
            next ListClusters request. Subsequent ListClusters\r\nrequests will have
            their own `next_page_token` to continue paging through the results."
          type: string
    ListSubclustersResponse:
      type: object
      properties:
        subclusters:
          description: List of Dataproc subclusters.
          type: array
          items:
            $ref: '#/components/schemas/Subcluster'
        nextPageToken:
          description: |-
            This token allows you to get the next page of results for ListSubclusters requests,
            if the number of results is larger than `page_size` specified in the request.
            To get the next page, specify the value of `next_page_token` as a value for
            the `page_token` parameter in the next ListClusters request. Subsequent ListClusters
            requests will have their own `next_page_token` to continue paging through the results.
          type: string
    MapreduceJob:
      type: object
      allOf:
      - type: object
        properties:
          args:
            description: Optional arguments to the driver.
            type: array
            items:
              type: string
          jarFileUris:
            description: URIs of file to run.
            type: array
            items:
              type: string
          fileUris:
            description: URIs of files to be copied to the working directory of Dataproc
              drivers and distributed tasks.
            type: array
            items:
              type: string
          archiveUris:
            description: URIs of archives to be extracted in the working directory
              of Dataproc drivers and tasks.
            type: array
            items:
              type: string
          properties:
            description: A mapping of property names to values, used to configure
              Dataproc.
            type: object
            additionalProperties:
              type: string
      - title: driver
        type: object
        maxProperties: 1
        properties:
          mainJarFileUri:
            description: The HCFS URI of the jar file containing the main class.
            type: string
          mainClass:
            description: The name of the driver's main class.
            type: string
    Monitoring:
      description: Monitoring system.
      type: object
      properties:
        name:
          description: Name of the monitoring system.
          type: string
        description:
          description: Description of the monitoring system.
          type: string
        link:
          description: Link to the monitoring system.
          type: string
    Operation:
      description: An Operation resource. For more information, see [Operation](/docs/api-design-guide/concepts/operation).
      type: object
      allOf:
      - type: object
        properties:
          id:
            description: ID of the operation.
            type: string
          description:
            description: Description of the operation. 0-256 characters long.
            type: string
          createdAt:
            description: |-
              Creation timestamp.

              String in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) text format.
            type: string
            format: date-time
          createdBy:
            description: ID of the user or service account who initiated the operation.
            type: string
          modifiedAt:
            description: |-
              The time when the Operation resource was last modified.

              String in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) text format.
            type: string
            format: date-time
          done:
            description: |-
              If the value is `false`, it means the operation is still in progress.
              If `true`, the operation is completed, and either `error` or `response` is available.
            type: boolean
            format: boolean
          metadata:
            description: |-
              Service-specific metadata associated with the operation.
              It typically contains the ID of the target resource that the operation is performed on.
              Any method that returns a long-running operation should document the metadata type, if any.
            type: object
      - title: result
        type: object
        maxProperties: 1
        properties:
          error:
            $ref: '#/components/schemas/rpcStatus'
            description: The error result of the operation in case of failure or cancellation.
          response:
            description: |-
              The normal response of the operation in case of success.
              If the original method returns no data on success, such as Delete,
              the response is [google.protobuf.Empty](https://developers.google.com/protocol-buffers/docs/reference/google.protobuf#empty).
              If the original method is the standard Create/Update,
              the response should be the target resource of the operation.
              Any method that returns a long-running operation should document the response type, if any.
            type: object
    PysparkJob:
      type: object
      properties:
        args:
          description: Optional arguments to the driver.
          type: array
          items:
            type: string
        jarFileUris:
          description: Jar file URIs to add to the CLASSPATHs of the Dataproc driver
            and tasks.
          type: array
          items:
            type: string
        fileUris:
          description: URIs of files to be copied to the working directory of Dataproc
            drivers and distributed tasks.
          type: array
          items:
            type: string
        archiveUris:
          description: URIs of archives to be extracted in the working directory of
            Dataproc drivers and tasks.
          type: array
          items:
            type: string
        properties:
          description: A mapping of property names to values, used to configure Dataproc.
          type: object
          additionalProperties:
            type: string
        mainPythonFileUri:
          description: URI of the main Python file to use as the driver. Must be a
            .py file.
          type: string
        pythonFileUris:
          description: URIs of Python files to pass to the PySpark framework.
          type: array
          items:
            type: string
    QueryList:
      type: object
      properties:
        queries:
          type: array
          items:
            type: string
    Resources:
      type: object
      properties:
        resourcePresetId:
          description: |-
            ID of the resource preset for computational resources available to a host (CPU, memory etc.).
            All available presets are listed in the [documentation](/docs/data-proc/concepts/instance-types).
          type: string
        diskTypeId:
          description: |-
            Type of the storage environment for the host.
            Possible values:
            * network-hdd — network HDD drive,
            * network-ssd — network SSD drive.
          type: string
        diskSize:
          description: Volume of the storage available to a host, in bytes.
          type: string
          format: int64
    Role:
      description: |2-
         - ROLE_UNSPECIFIED: Host have undefined role
         - MASTERNODE: Masternode includes these services (depends on given component list)
        * HDFS Namenode, Secondary Namenode,
        * YARN ResorceManager, Timeline Server,
        * Zookeeper,
        * Hive Server, Hive Metastore, HCatalog
        * HBase Master,
        * Spark History Server,
        * Zeppelin
         - DATANODE: Datanode includes these services (depends on given component list)
        * HDFS Datanode,
        * YARN NodeManager,
        * HBase RegionServer,
        * Spark libraries.
         - COMPUTENODE: Computenodes includes these services (depends on given component list)
        * YARN NodeManager.
        * Spark libraries.
      type: string
      enum:
      - MASTERNODE
      - DATANODE
      - COMPUTENODE
    SparkJob:
      type: object
      properties:
        args:
          description: Optional arguments to the driver.
          type: array
          items:
            type: string
        jarFileUris:
          description: Jar file URIs to add to the CLASSPATHs of the Dataproc driver
            and tasks.
          type: array
          items:
            type: string
        fileUris:
          description: URIs of files to be copied to the working directory of Dataproc
            drivers and distributed tasks.
          type: array
          items:
            type: string
        archiveUris:
          description: URIs of archives to be extracted in the working directory of
            Dataproc drivers and tasks.
          type: array
          items:
            type: string
        properties:
          description: A mapping of property names to values, used to configure Dataproc.
          type: object
          additionalProperties:
            type: string
        mainJarFileUri:
          description: The HCFS URI of the jar file containing the main class.
          type: string
        mainClass:
          description: The name of the driver's main class.
          type: string
    StartClusterMetadata:
      type: object
      properties:
        clusterId:
          description: |-
            ID of the Dataproc cluster.
            This ID is assigned by Dataproc at creation time.
          type: string
    StopClusterMetadata:
      type: object
      properties:
        clusterId:
          description: |-
            ID of the Dataproc cluster.
            This ID is assigned by Dataproc at creation time.
          type: string
    Subcluster:
      description: |-
        A Dataproc Subcluster resource. For more information, see
        the [Concepts](/docs/data-proc/concepts) section of the documentation.
      type: object
      properties:
        id:
          description: |-
            ID of the Dataproc subcluster.
            This ID is assigned by Dataproc in the process of creating Dataproc subcluster.
          type: string
        clusterId:
          description: |-
            ID of the Dataproc cluster.
            This ID is assigned by Dataproc in the process of creating Dataproc cluster.
          type: string
        createdAt:
          description: |-
            Creation timestamp in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) text format.

            String in [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) text format.
          type: string
          format: date-time
        name:
          description: |-
            Name of the Dataproc subcluster.
            The name is unique within the folder. 1-64 characters long.
          type: string
        role:
          $ref: '#/components/schemas/Role_in_Subcluster_role'
        resources:
          $ref: '#/components/schemas/Resources_in_Subcluster_resources'
        subnetId:
          description: ID of using compute subnet for hosts in subcluster.
          type: string
        hostsCount:
          description: Number of hosts in subcluster.
          type: string
          format: int64
    UpdateClusterConfigSpec:
      type: object
      properties:
        subclustersSpec:
          description: Subclusters configuration.
          type: array
          items:
            $ref: '#/components/schemas/UpdateSubclusterConfigSpec'
    UpdateClusterMetadata:
      type: object
      properties:
        clusterId:
          description: |-
            ID of the Dataproc cluster.
            This ID is assigned by Dataproc at creation time.
          type: string
    UpdateClusterRequest:
      type: object
      properties:
        updateMask:
          $ref: '#/components/schemas/FieldMask_in_UpdateClusterRequest_updateMask'
        description:
          description: |-
            Description of the Dataproc cluster. 0-256 characters long.

            The maximum string length in characters is 256.
          type: string
        labels:
          description: |-
            Custom labels for the Dataproc cluster as `` key:value `` pairs.
            Maximum 64 per resource.

            No more than 64 per resource.
            The string length in characters for each key must be 1-63.
            Each key must match the regular expression `` [a-z][-_0-9a-z]* ``.
            The maximum string length in characters for each value is 63.
            Each value must match the regular expression `` [-_0-9a-z]* ``.
          type: object
          additionalProperties:
            type: string
        configSpec:
          $ref: '#/components/schemas/UpdateClusterConfigSpec_in_UpdateClusterRequest_configSpec'
        name:
          description: |-
            Name of the Dataproc cluster. The name must be unique within the folder.
            The name must be 1-63 characters long and match the regular expression `^[a-z]([-a-z0-9]{,61}[a-z0-9])?$`.
            The name can’t be changed after the Dataproc cluster is created.

            Value must match the regular expression `` |[a-z][-a-z0-9]{1,61}[a-z0-9] ``.
          type: string
        serviceAccountId:
          description: Identifier of the new service account for the cluster.
          type: string
        bucket:
          description: Name of the new object storage bucket for Dataproc jobs.
          type: string
    UpdateSubclusterConfigSpec:
      type: object
      properties:
        id:
          description: |-
            ID of the Dataproc subcluster.
            This ID is assigned by Dataproc at creation time.
          type: string
        name:
          description: |-
            Name of Dataproc subcluster.

            Value must match the regular expression `` |[a-z][-a-z0-9]{1,61}[a-z0-9] ``.
          type: string
        resources:
          $ref: '#/components/schemas/Resources_in_UpdateSubclusterConfigSpec_resources'
        hostsCount:
          description: |-
            Number of hosts in subcluster

            The minimum value is 1.
          type: string
          format: int64
    UpdateSubclusterMetadata:
      type: object
      properties:
        clusterId:
          description: |-
            ID of the Dataproc cluster resource to return.

            The maximum string length in characters is 50.
          type: string
        subclusterId:
          description: |-
            ID of the Dataproc subcluster resource to update.

            The maximum string length in characters is 50.
          type: string
    UpdateSubclusterRequest:
      type: object
      properties:
        updateMask:
          $ref: '#/components/schemas/FieldMask_in_UpdateSubclusterRequest_updateMask'
        resources:
          $ref: '#/components/schemas/Resources_in_UpdateSubclusterRequest_resources'
        name:
          description: |-
            Name of the Dataproc subcluster. The name must be unique within the folder.

            Value must match the regular expression `` |[a-z][-a-z0-9]{1,61}[a-z0-9] ``.
          type: string
        hostsCount:
          description: |-
            Required.
            Number of hosts in subcluster.

            The minimum value is 1.
          type: string
          format: int64
    rpcStatus:
      description: The error result of the operation in case of failure or cancellation.
      type: object
      properties:
        code:
          description: Error code. An enum value of [google.rpc.Code](https://github.com/googleapis/googleapis/blob/master/google/rpc/code.proto).
          type: integer
          format: int32
        message:
          description: An error message.
          type: string
        details:
          description: A list of messages that carry the error details.
          type: array
          items:
            type: object
    ClusterConfig_in_Cluster_config:
      description: Configuration of the Dataproc cluster.
      type: object
      properties:
        versionId:
          description: |-
            Version of image for cluster provisioning.
            All available versions are listed in the [documentation](/docs/managed-hadoop/concepts/image-versions).
          type: string
        hadoop:
          $ref: '#/components/schemas/HadoopConfig_in_ClusterConfig_hadoop'
    Health_in_Cluster_health:
      description: |-
        Aggregated cluster health.

         - HEALTH_UNKNOWN: State of the cluster is unknown ([Host.health] for every host in the cluster is UNKNOWN).
         - ALIVE: Cluster is alive and well ([Host.health] for every host in the cluster is ALIVE).
         - DEAD: Cluster is inoperable ([Host.health] for every host in the cluster is DEAD).
         - DEGRADED: Cluster is working below capacity ([Host.health] for at least one host in the cluster is not ALIVE).
      type: string
      enum:
      - HEALTH_UNKNOWN
      - ALIVE
      - DEAD
      - DEGRADED
      default: HEALTH_UNKNOWN
    ClusterStatus_in_Cluster_status:
      description: |-
        Cluster status.

         - STATUS_UNKNOWN: Cluster state is unknown.
         - CREATING: Cluster is being created.
         - RUNNING: Cluster is running normally.
         - ERROR: Cluster encountered a problem and cannot operate.
         - STOPPING: Cluster is stopping.
         - STOPPED: Cluster stopped.
         - STARTING: Cluster is starting.
      type: string
      enum:
      - STATUS_UNKNOWN
      - CREATING
      - RUNNING
      - ERROR
      - STOPPING
      - STOPPED
      - STARTING
      default: STATUS_UNKNOWN
    HadoopConfig_in_ClusterConfig_hadoop:
      description: |-
        Dataproc specific options

        Configuration, that describes application logic of installed services,
        their properties and settings.
      type: object
      properties:
        services:
          description: List of used services in cluster (for default use empty)
          type: array
          items:
            $ref: '#/components/schemas/HadoopConfigService'
        properties:
          description: |-
            Properties passed to all hosts *-site.xml configurations.
            In key you need to use prefix 'hdfs:dfs.replication' for setting
            property 'dfs.replication' in /etc/hadoop/conf/hdfs-site.xml
          type: object
          additionalProperties:
            type: string
        sshPublicKeys:
          description: List of ssh public keys to access to cluster hosts.
          type: array
          items:
            type: string
    HadoopConfig_in_CreateClusterConfigSpec_hadoop:
      description: |-
        Dataproc specific options.

        Configuration, that describes application logic of installed services,
        their properties and settings.
      type: object
      properties:
        services:
          description: List of used services in cluster (for default use empty)
          type: array
          items:
            $ref: '#/components/schemas/HadoopConfigService'
        properties:
          description: |-
            Properties passed to all hosts *-site.xml configurations.
            In key you need to use prefix 'hdfs:dfs.replication' for setting
            property 'dfs.replication' in /etc/hadoop/conf/hdfs-site.xml
          type: object
          additionalProperties:
            type: string
        sshPublicKeys:
          description: List of ssh public keys to access to cluster hosts.
          type: array
          items:
            type: string
    CreateClusterConfigSpec_in_CreateClusterRequest_configSpec:
      description: |-
        Required.
        Configuration and resources for hosts that should be created for the Dataproc cluster.
      type: object
      properties:
        versionId:
          description: |-
            Vesion of image for cluster provisioning.
            All available versions are listed in the [documentation](/docs/data-proc/concepts/image-versions).
          type: string
        hadoop:
          $ref: '#/components/schemas/HadoopConfig_in_CreateClusterConfigSpec_hadoop'
        subclustersSpec:
          description: Subclusters configuration.
          type: array
          items:
            $ref: '#/components/schemas/CreateSubclusterConfigSpec'
    Role_in_CreateSubclusterConfigSpec_role:
      description: |-
        Required.
        Role of hosts in subcluster.

         - ROLE_UNSPECIFIED: Host have undefined role
         - MASTERNODE: Masternode includes these services (depends on given component list)
        * HDFS Namenode, Secondary Namenode,
        * YARN ResorceManager, Timeline Server,
        * Zookeeper,
        * Hive Server, Hive Metastore, HCatalog
        * HBase Master,
        * Spark History Server,
        * Zeppelin
         - DATANODE: Datanode includes these services (depends on given component list)
        * HDFS Datanode,
        * YARN NodeManager,
        * HBase RegionServer,
        * Spark libraries.
         - COMPUTENODE: Computenodes includes these services (depends on given component list)
        * YARN NodeManager.
        * Spark libraries.
      type: string
      enum:
      - MASTERNODE
      - DATANODE
      - COMPUTENODE
    Resources_in_CreateSubclusterConfigSpec_resources:
      description: |-
        Required.
        Resource configuration for hosts in subcluster.
      type: object
      properties:
        resourcePresetId:
          description: |-
            ID of the resource preset for computational resources available to a host (CPU, memory etc.).
            All available presets are listed in the [documentation](/docs/data-proc/concepts/instance-types).
          type: string
        diskTypeId:
          description: |-
            Type of the storage environment for the host.
            Possible values:
            * network-hdd — network HDD drive,
            * network-ssd — network SSD drive.
          type: string
        diskSize:
          description: Volume of the storage available to a host, in bytes.
          type: string
          format: int64
    Role_in_CreateSubclusterRequest_role:
      description: |-
        Required.
        Role of hosts in subcluster.

         - ROLE_UNSPECIFIED: Host have undefined role
         - MASTERNODE: Masternode includes these services (depends on given component list)
        * HDFS Namenode, Secondary Namenode,
        * YARN ResorceManager, Timeline Server,
        * Zookeeper,
        * Hive Server, Hive Metastore, HCatalog
        * HBase Master,
        * Spark History Server,
        * Zeppelin
         - DATANODE: Datanode includes these services (depends on given component list)
        * HDFS Datanode,
        * YARN NodeManager,
        * HBase RegionServer,
        * Spark libraries.
         - COMPUTENODE: Computenodes includes these services (depends on given component list)
        * YARN NodeManager.
        * Spark libraries.
      type: string
      enum:
      - MASTERNODE
      - DATANODE
      - COMPUTENODE
    Resources_in_CreateSubclusterRequest_resources:
      description: |-
        Required.
        Resources allocated to hosts in subcluster.
      type: object
      properties:
        resourcePresetId:
          description: |-
            ID of the resource preset for computational resources available to a host (CPU, memory etc.).
            All available presets are listed in the [documentation](/docs/data-proc/concepts/instance-types).
          type: string
        diskTypeId:
          description: |-
            Type of the storage environment for the host.
            Possible values:
            * network-hdd — network HDD drive,
            * network-ssd — network SSD drive.
          type: string
        diskSize:
          description: Volume of the storage available to a host, in bytes.
          type: string
          format: int64
    Health_in_Host_health:
      description: |-
        Status code of the aggregated health of the host.

         - HEALTH_UNKNOWN: State of the cluster is unknown ([Host.health] for every host in the cluster is UNKNOWN).
         - ALIVE: Cluster is alive and well ([Host.health] for every host in the cluster is ALIVE).
         - DEAD: Cluster is inoperable ([Host.health] for every host in the cluster is DEAD).
         - DEGRADED: Cluster is working below capacity ([Host.health] for at least one host in the cluster is not ALIVE).
      type: string
      enum:
      - HEALTH_UNKNOWN
      - ALIVE
      - DEAD
      - DEGRADED
      default: HEALTH_UNKNOWN
    Role_in_Host_role:
      description: |-
        Role of current host in cluster.

         - ROLE_UNSPECIFIED: Host have undefined role
         - MASTERNODE: Masternode includes these services (depends on given component list)
        * HDFS Namenode, Secondary Namenode,
        * YARN ResorceManager, Timeline Server,
        * Zookeeper,
        * Hive Server, Hive Metastore, HCatalog
        * HBase Master,
        * Spark History Server,
        * Zeppelin
         - DATANODE: Datanode includes these services (depends on given component list)
        * HDFS Datanode,
        * YARN NodeManager,
        * HBase RegionServer,
        * Spark libraries.
         - COMPUTENODE: Computenodes includes these services (depends on given component list)
        * YARN NodeManager.
        * Spark libraries.
      type: string
      enum:
      - MASTERNODE
      - DATANODE
      - COMPUTENODE
    Role_in_Subcluster_role:
      description: |-
        Role of all hosts in subcluster.

         - ROLE_UNSPECIFIED: Host have undefined role
         - MASTERNODE: Masternode includes these services (depends on given component list)
        * HDFS Namenode, Secondary Namenode,
        * YARN ResorceManager, Timeline Server,
        * Zookeeper,
        * Hive Server, Hive Metastore, HCatalog
        * HBase Master,
        * Spark History Server,
        * Zeppelin
         - DATANODE: Datanode includes these services (depends on given component list)
        * HDFS Datanode,
        * YARN NodeManager,
        * HBase RegionServer,
        * Spark libraries.
         - COMPUTENODE: Computenodes includes these services (depends on given component list)
        * YARN NodeManager.
        * Spark libraries.
      type: string
      enum:
      - MASTERNODE
      - DATANODE
      - COMPUTENODE
    Resources_in_Subcluster_resources:
      description: Resource configuration for hosts in subcluster.
      type: object
      properties:
        resourcePresetId:
          description: |-
            ID of the resource preset for computational resources available to a host (CPU, memory etc.).
            All available presets are listed in the [documentation](/docs/data-proc/concepts/instance-types).
          type: string
        diskTypeId:
          description: |-
            Type of the storage environment for the host.
            Possible values:
            * network-hdd — network HDD drive,
            * network-ssd — network SSD drive.
          type: string
        diskSize:
          description: Volume of the storage available to a host, in bytes.
          type: string
          format: int64
    FieldMask_in_UpdateClusterRequest_updateMask:
      description: |-
        Field mask that specifies which fields of the Dataproc Cluster resource should be updated.

        A comma-separated names off ALL fields to be updated.
        Оnly the specified fields will be changed. The others will be left untouched.
        If the field is specified in `` updateMask `` and no value for that field was sent in the request,
        the field's value will be reset to the default. The default value for most fields is null or 0.

        If `` updateMask `` is not sent in the request, all fields' values will be updated.
        Fields specified in the request will be updated to provided values.
        The rest of the fields will be reset to the default.
      type: string
    UpdateClusterConfigSpec_in_UpdateClusterRequest_configSpec:
      description: Configuration and resources for hosts that should be created for
        the Dataproc cluster.
      type: object
      properties:
        subclustersSpec:
          description: Subclusters configuration.
          type: array
          items:
            $ref: '#/components/schemas/UpdateSubclusterConfigSpec'
    Resources_in_UpdateSubclusterConfigSpec_resources:
      description: Resource configuration for hosts in subcluster.
      type: object
      properties:
        resourcePresetId:
          description: |-
            ID of the resource preset for computational resources available to a host (CPU, memory etc.).
            All available presets are listed in the [documentation](/docs/data-proc/concepts/instance-types).
          type: string
        diskTypeId:
          description: |-
            Type of the storage environment for the host.
            Possible values:
            * network-hdd — network HDD drive,
            * network-ssd — network SSD drive.
          type: string
        diskSize:
          description: Volume of the storage available to a host, in bytes.
          type: string
          format: int64
    FieldMask_in_UpdateSubclusterRequest_updateMask:
      description: |-
        A comma-separated names off ALL fields to be updated.
        Оnly the specified fields will be changed. The others will be left untouched.
        If the field is specified in `` updateMask `` and no value for that field was sent in the request,
        the field's value will be reset to the default. The default value for most fields is null or 0.

        If `` updateMask `` is not sent in the request, all fields' values will be updated.
        Fields specified in the request will be updated to provided values.
        The rest of the fields will be reset to the default.
      type: string
    Resources_in_UpdateSubclusterRequest_resources:
      description: Resources allocated to hosts in subcluster.
      type: object
      properties:
        resourcePresetId:
          description: |-
            ID of the resource preset for computational resources available to a host (CPU, memory etc.).
            All available presets are listed in the [documentation](/docs/data-proc/concepts/instance-types).
          type: string
        diskTypeId:
          description: |-
            Type of the storage environment for the host.
            Possible values:
            * network-hdd — network HDD drive,
            * network-ssd — network SSD drive.
          type: string
        diskSize:
          description: Volume of the storage available to a host, in bytes.
          type: string
          format: int64
tags:
- name: Cluster
  description: A set of methods for managing Dataproc clusters.
- name: Job
  description: A set of methods for managing jobs for Dataproc cluster.
- name: Subcluster
  description: A set of methods for managing Dataproc subclusters.
