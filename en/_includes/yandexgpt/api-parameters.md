* `modelUri`: [ID of the model](../../yandexgpt/concepts/models.md) to generate the response. The parameter contains the [ID of a {{ yandex-cloud }} folder](../../resource-manager/operations/folder/get-id.md) or the ID of a model [fine-tuned](../../yandexgpt/tutorials/yagpt-tuning.md) in {{ ml-platform-name }}.
* `completionOptions`: Request configuration options:

   * `stream`: Enables streaming of partially generated text. It may take either the `true` or `false` value.
   * `temperature`: With a higher temperature, you get more creative and randomized response from the model. This parameter accepts values between `0` and `1`, inclusive. The default value is `0.6`.
   * `maxTokens`: Sets a limit on the model's output in [tokens](../../yandexgpt/concepts/tokens.md). The maximum number of tokens per generation depends on the model. For more information, see [{#T}](../../yandexgpt/concepts/limits.md).

* `messages`: List of messages that set the context for the model:

   * `role`: Message sender's role:

      * `user`: Used to send user messages to the model.
      * `system`: Used to set the request's context and define the model's behavior.
      * `assistant`: Used to deliver responses generated by the model. In chat mode, model responses with the `assistant` role are included in the message to log the conversation context. Do not send user messages with this role.

   * `text`: Message text.