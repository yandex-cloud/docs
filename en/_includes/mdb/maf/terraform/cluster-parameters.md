Here is an example of the configuration file structure:

```hcl
resource "yandex_airflow_cluster" "<cluster_name>" {
  name        = "<cluster_name>"
  description = "<cluster_description>"

  labels = { <label_list> }

  admin_password     = "<administrator_password>"
  service_account_id = "<service_account_ID>"
  subnet_ids         = ["<list_of_subnet_IDs>"]
  security_group_ids = ["<list_of_security_group_IDs>"]

  webserver = {
    count              = <number_of_instances>
    resource_preset_id = "<resource_ID>"
  }

  scheduler = {
    count              = <number_of_instances>
    resource_preset_id = "<resource_ID>"
  }

  worker = {
    min_count          = <minimum_number_of_instances>
    max_count          = <maximum_number_of_instances>
    resource_preset_id = "<resource_ID>"
  }

  triggerer = {
    count              = <number_of_instances>
    resource_preset_id = "<resource_ID>"
  }

  pip_packages = ["list_of_pip_packages"]
  deb_packages = ["list_of_deb_packages"]

  code_sync = {
    s3 = {
      bucket = "<bucket_name>"
    }
  }

  deletion_protection = <deletion_protection>

  lockbox_secrets_backend = {
    enabled = <usage_of_secrets>
  }

  airflow_config = {
    <configuration_section> = {
      <key> = "<value>"
    }
  }

  logging = {
    enabled   = <use_of_logging>
    folder_id = "<folder_ID>"
    min_level = "<logging_level>"
  }
}

resource "yandex_vpc_network" "<network_name>" { name = "<network_name>" }

resource "yandex_vpc_subnet" "<subnet_name>" {
  name           = "<subnet_name>"
  zone           = "<availability_zone>"
  network_id     = "<network_ID>"
  v4_cidr_blocks = ["<range>"]
}
```

Where:

* `name`: Cluster name.
* `description`: Cluster description.
* `labels`: List of labels. Provide labels in `<key> = "<value>"` format.
* `admin_password`: Admin user password. The password must be not less than 8 characters long and contain at least:

    * One uppercase letter
    * One lowercase letter
    * One digit
    * One special character

* `service_account_id`: Service account ID.
* `subnet_ids`: List of subnet IDs.
* `security_group_ids`: List of security group IDs.
* `webserver`, `scheduler`, `worker`, `triggerer`: {{ maf-name }} [component](../../../../managed-airflow/concepts/index.md#components) configuration:

    * `count`: Number of instances in the cluster for the web server, scheduler, and Triggerer.
    * `min_count`, `max_count`: Minimum and maximum number of instances in the cluster for the worker.
    * `resource_preset_id`: ID of the computing resources of the web server, scheduler, worker, and Triggerer. The possible values are:

        * `c1-m2`: 1 vCPU, 2 GB RAM
        * `c1-m4`: 1 vCPU, 4 GB RAM
        * `c2-m4`: 2 vCPUs, 4 GB RAM
        * `c2-m8`: 2 vCPUs, 8 GB RAM
        * `c4-m8`: 4 vCPUs, 8 GB RAM
        * `c4-m16`: 4 vCPUs, 16 GB RAM
        * `c8-m16`: 8 vCPUs, 16 GB RAM
        * `c8-m32`: 8 vCPUs, 32 GB RAM

* `deb_packages`, `pip_packages`: Lists of deb and pip packages enabling you to install additional libraries and applications in the cluster for running DAG files:

    If required, you can set version restrictions for the installed packages, for example:

    ```hcl
    pip_packages = ["pandas==2.0.2","scikit-learn>=1.0.0","clickhouse-driver~=0.2.0"]
    ```

    The package name format and version are defined by the install command: `pip install` for pip packages and `apt install` for deb packages.

* `code_sync.s3.bucket`: Name of the bucket to store DAG files in.
* `deletion_protection`: Enables cluster protection against accidental deletion. The possible values are `true` or `false`.

    With deletion protection enabled, you will still be able to manually connect to the cluster and delete it.

* `lockbox_secrets_backend.enabled`: Enables using secrets in [{{ lockbox-full-name }}](../../../../lockbox/concepts/index.md) to [store {{ AF }} configuration data, variables, and connection parameters](../../../../managed-airflow/concepts/impersonation.md#lockbox-integration). The possible values are `true` or `false`.
* `airflow_config`: [{{ AF }} additional properties](https://airflow.apache.org/docs/apache-airflow/2.2.4/configurations-ref.html), e.g., `core` for configuration section, `load_examples` for key, and `False` for value.
* `logging`: Logging parameters:

    * `enabled`: Enables logging. Logs generated by {{ AF }} components will be sent to {{ cloud-logging-full-name }}. The possible values are `true` or `false`.
    * `folder_id`: Folder ID. Logs will be written to the default [log group](../../../../logging/concepts/log-group.md) for this folder.
    * `log_group_id`: Custom log group ID. Logs will be written to this group.

      Specify one of the two parameters: `folder_id` or `log_group_id`.

    * `min_level`: Minimum logging level. Possible values: `TRACE`, `DEBUG`, `INFO` (default), `WARN`, `ERROR`, and `FATAL`.

    You can specify only one of the parameters: `folder_id` or `log_group_id`.
